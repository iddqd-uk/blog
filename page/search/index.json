[{"content":" Ниже сообщение от HR яндекса с материалами для подготовки к собеседованию, сохраняю для себя.\n  Общий процесс собеседований Описание технических собеседований Статья на хабре про интервью Яндекс.Контест - здесь можно потренироваться решать задачи и потаймить себя. Могут подойти и другие ресурсы, такие как hackerrank.com, leetcode.com Видео-разбор алгоритмических задач:   Часть 1 - в этом видео разбирается задача \u0026ldquo;Последовательно идущие единицы\u0026rdquo;, она простая и на её примере мы показываем, что ожидаем от кандидата, как и по какому пути рекомендуем двигаться в решении задачи Часть 2 - здесь разбор двух более сложных задач: \u0026ldquo;Анаграммы\u0026rdquo; и \u0026ldquo;Генерация скобочных последовательностей\u0026rdquo;  linked lists:\n https://leetcode.com/problems/merge-k-sorted-lists/ https://leetcode.com/problems/linked-list-cycle/ https://leetcode.com/problems/add-two-numbers/ https://leetcode.com/problems/reverse-linked-list/  binary search:\n https://leetcode.com/problems/binary-search/ https://leetcode.com/problems/guess-number-higher-or-lower/ https://leetcode.com/problems/search-a-2d-matrix/ https://leetcode.com/problems/search-in-rotated-sorted-array/ https://leetcode.com/problems/find-minimum-in-rotated-sorted-array/ https://leetcode.com/problems/search-in-rotated-sorted-array-ii/  hash table:\n https://leetcode.com/problems/single-number/ (решить за O(1) по памяти) https://leetcode.com/problems/two-sum/ https://leetcode.com/problems/4sum/ https://leetcode.com/problems/group-anagrams/ https://leetcode.com/problems/valid-anagram/ https://leetcode.com/problems/find-all-anagrams-in-a-string/  queue/stack:\n https://leetcode.com/problems/valid-parentheses/  dfs/bfs:\n https://leetcode.com/problems/number-of-islands/ https://leetcode.com/problems/remove-invalid-parentheses/  sort:\n https://leetcode.com/problems/merge-intervals/  heap/hash:\n https://leetcode.com/problems/top-k-frequent-words/ https://leetcode.com/problems/top-k-frequent-elements/  two pointers:\n https://leetcode.com/problems/container-with-most-water/ https://leetcode.com/problems/partition-labels/  sliding window:\n https://leetcode.com/problems/sliding-window-median/ https://leetcode.com/problems/sliding-window-maximum/ https://leetcode.com/problems/longest-repeating-character-replacement/  tree:\n https://leetcode.com/problems/same-tree/ https://leetcode.com/problems/symmetric-tree/ https://leetcode.com/problems/balanced-binary-tree/ https://leetcode.com/problems/path-sum-ii/  greedy problems:\n https://leetcode.com/problems/best-time-to-buy-and-sell-stock/ https://leetcode.com/problems/best-time-to-buy-and-sell-stock-ii/ https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/ https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/  Для подготовки к архитектуре:\n Как проходят архитектурные секции В этом видео есть полезная информация про архитектурную секцию Гайд про архитектуру На секции не обязательны инструменты для рисования, но если вам понадобятся, то вот примеры:   Digital whiteboard app Online whiteboard app webwhiteboard.com ","date":"2023-12-22T07:02:21Z","image":"https://blog.iddqd.uk/yandex-interview-questions/cover_hu189ac99d92bfe66fb9120bb88310aa74_36894_120x120_fill_q75_box_smart1.jpg","permalink":"https://blog.iddqd.uk/yandex-interview-questions/","title":"Yandex Interview Questions"},{"content":"Однажды я был маленьким, и задавался вопросом - вот если Unix way это (упрощенно) небольшие, довольно простые утилиты и библиотеки, которые делают одну вещь, но делают её хорошо (Peter H. Salus: \u0026ldquo;\u0026hellip;that do one thing and do it well\u0026rdquo;), то\u0026hellip; Где тогда утилита, которая занимается шаблонизацией и не хватает звёзд с неба? Вот есть у тебя некоторый шаблон, и есть некоторые данные, которые ты имеешь желание в этот шаблон подставить. Брать для этого Jinja2? Писать что-то своё используя sed + awk? Или тащить %tool_name% на несколько мегабайт ради столь тривиальной задачи?\nСпустя некоторое время, вновь столкнувшись с подобной задачей, и поняв что попытка найти что-то подходящее вновь претерпела фиаско, было принято волевое решение - да-да, написать свой прекрасный проект велосипед шаблонизатор для использования в CLI. Ограничения были выбраны следующие:\n Статическая линковка - один бинарный файл без каких-либо зависимостей (он мне понадобится в docker scratch) Итоговый размер должен быть минимально возможным (постараться уместиться в 100Кб без upx)  На чем писать, если хочется боли компактного результата и быстрого выполнения - естественно, берём C. Какой шаблонизатор использовать, если хочется минимализма? Под такую задачу хорошо подойдет mustache. И вот, спустя некоторое время появляется mustpl (must - mustache, tpl - template).\nКак его использовать? Предельно просто - дай на вход путь до файла с шаблоном, файла с данными для этого шаблона (или передай их в виде JSON-строки используя флаг -d), и опционально передай нужные переменные окружения. Для примера давай представим, что у нас есть следующий шаблон для Nginx (nginx.tpl):\nserver { listen 8080; server_name{{#names}}{{ . }}{{/names}}; location / { root /var/www/data; index index.html index.htm; } } И мы имеем желание сгенерировать из него настоящий конфиг, подставив в качестве server_name значения example.com и example.com. Для этого достаточно выполнить:\n$ export SERVER_NAME_1=example.com $ mustpl -d \u0026#39;{\u0026#34;names\u0026#34;: [\u0026#34;${SERVER_NAME_1:-fallback.com}\u0026#34;, \u0026#34;google.com\u0026#34;]}\u0026#39; ./nginx.tpl server { listen 8080; server_name example.com google.com; location / { root /var/www/data; index index.html index.htm; } } Или другой пример, с циклом, но тем же конфигом для Nginx. Берём данные (data.json):\n{ \u0026#34;servers\u0026#34;: [ { \u0026#34;listen\u0026#34;: 8080, \u0026#34;names\u0026#34;: [ \u0026#34;example.com\u0026#34; ], \u0026#34;is_default\u0026#34;: true, \u0026#34;home\u0026#34;: \u0026#34;/www/example.com\u0026#34; }, { \u0026#34;listen\u0026#34;: 1088, \u0026#34;names\u0026#34;: [ \u0026#34;127-0-0-1.nip.io\u0026#34;, \u0026#34;127-0-0-2.nip.io\u0026#34; ], \u0026#34;home\u0026#34;: \u0026#34;/www/local\u0026#34; } ] } Берём шаблон (nginx.tpl):\n{{#servers}}server { listen {{ listen }}; server_name{{#names}}{{ . }}{{/names}}{{#is_default}}default_server{{/is_default}}; location / { root {{ home }}; index index.html index.htm; } } {{/servers}}И рендерим:\n$ mustpl -f ./data.json ./nginx.tpl server { listen 8080; server_name example.com default_server; location / { root /www/example.com; index index.html index.htm; } } server { listen 1088; server_name 127-0-0-1.nip.io 127-0-0-2.nip.io; location / { root /www/local; index index.html index.htm; } } Красота - она в простоте. Кроме всего прочего, шаблонизатором поддерживаются и условия, и подключение других файлов-шаблонов, и escaping значений - все детали и нужные ссылки сможешь найти в readme файле репозитория с приложением.\nА как установить? На данный момент есть 3 пути по установке - это скачивание уже готового бинарного файла под необходимую архитектуру со страницы релизов, собственная сборка из исходников и установка силами docker.\nДля сборки потребуется только gcc (и musl-dev, если собираешь, скажем, в alpine linux), а docker-образ уже собран под наиболее популярные платформы, так что всё, что потребуется тебе сделать в твоём Dockerfile, это лишь:\nCOPY --from=ghcr.io/tarampampam/mustpl:latest /bin/mustpl /bin/mustpl Крайне рекомендую не использовать тег latest из-за того, что при мажорных изменениях есть риск получить обратно-несовместимые изменения. Лучше всего использовать версионирование в формате X.Y.Z в связке с настроенным (dependa|renovate)bot.\n Но почему ты просто не взял %tool_name%? Кроме того, что целью был минимальный размер итогового бинарного файла, отсутствие зависимостей и скорость работы, есть ещё как минимум одна очень важная причина - это комфортное использование в docker, а именно - навык парсить переменные окружения (aka envsubst) и возможность использования в качестве точки входа (entrypoint).\nСкорее всего ты знаешь, что основной процесс, запускаемый в контейнере - должен иметь PID равный 1 (в неймспейсе контейнера). Нужно это для того, чтоб демон докера мог корректно общаться (отправляя сигналы) с приложением, что у тебя в этом самом контейнере крутится.\nКак использовать в качестве docker entrypoint  Именно необходимость сохранить PID 1 является причиной тому что, как правило, в entrypoint-скриптах используется конструкции вида:\n#!/bin/sh set -e if [ -n \u0026#34;$MY_OPTION\u0026#34; ]; then # если переменная окружения имеется sed -i \u0026#34;s~foo~bar ${MY_OPTION}~\u0026#34; /etc/app.cfg # то подставляем её в конфиг fi; exec \u0026#34;$@\u0026#34; # \u0026lt;-- а вот это самое интересное Которая в паре со следующими entrypoint/cmd в dockerfile:\nENTRYPOINT [\u0026#34;/docker-entrypoint.sh\u0026#34;]CMD [\u0026#34;/bin/app\u0026#34;, \u0026#34;--another\u0026#34;, \u0026#34;flags\u0026#34;]Работает следующим образом:\n Запускается процесс sh c PID 1, который выполняет скрипт /docker-entrypoint.sh Скрипт выполняет все необходимые модификации конфига некоторого приложения (если это необходимо), и вызывает exec (который заменяет текущий процесс новым, не изменяя при этом свой PID, детали в man exec) Запускается процесс app с аргументами --another flags и его PID становится 1  И мне очень хотелось иметь возможность отказаться от этих самых entrypoint скриптов, так как они тянут массу зависимостей (а distroless же наше всё), да и писать их утомляет очень быстро. И было принято решение научить mustpl выполнять этот самый exec самостоятельно. Т.е. чтоб алгоритм запуска был следующий:\n Запускается mustpl с PID 1, который читая файл шаблона и данные для него генерирует необходимый конфиг для некоторого приложения Выполняет exec, запуская нужное приложение, не меняя PID (т.е. оставляя его равным 1)  Как это выглядит? Тоже очень просто, давай создадим файлы с шаблоном (template.ini):\n[config] value = {{ my_option }} Данными для него (data.json):\n{ \u0026#34;my_option\u0026#34;: \u0026#34;${MY_OPTION:-default value}\u0026#34; } И следующий Dockerfile:\nFROMalpine:latestCOPY --from=ghcr.io/tarampampam/mustpl /bin/mustpl /bin/mustplCOPY ./data.json /data.jsonCOPY ./template.ini /template.iniENTRYPOINT [\u0026#34;mustpl\u0026#34;, \u0026#34;-f\u0026#34;, \u0026#34;/data.json\u0026#34;, \u0026#34;-o\u0026#34;, \u0026#34;/rendered.txt\u0026#34;, \u0026#34;/template.ini\u0026#34;, \u0026#34;--\u0026#34;]CMD [\u0026#34;sleep\u0026#34;, \u0026#34;infinity\u0026#34;]Теперь давай соберем образ и запустим его:\n$ docker build --tag test:local . $ docker run --rm --name mustpl_example -e \u0026#34;MY_OPTION=foobar\u0026#34; test:local В этот момент происходит следующее:\n Запускается mustpl (т.к. он указан в entrypoint), который читает файлы /data.json и /template.ini В данных шаблона значение для my_option заменяется на foobar, так как переменная окружения MY_OPTION установлена (мы же указали -e \u0026quot;MY_OPTION=foobar\u0026quot;; в противном случае там бы оказалось значение default value) Шаблон рендерится, и сохраняется в /rendered.txt mustpl сохраняет все аргументы, что были указаны после пути до файла с шаблоном (это единственный обязательный параметр), трактуя их как имя и параметры запускаемого приложения (в нашем случае это sleep с аргументом infinity), двойное тире -- необходимо чтоб любые последующие флаги не парсились mustpl а читались \u0026ldquo;как есть\u0026rdquo; Запускается процесс sleep и PID равный 1 сохраняется уже за ним, а mustpl просто завершает свою работу (фактически происходит замена образа, но это сейчас не так важно)  Давай проверим, так ли это на самом деле (выполним в отдельном терминале):\n$ docker exec mustpl_example ps aux PID USER TIME COMMAND 1 root 0:00 sleep infinity # \u0026lt;-- PID как видим на самом деле == 1 7 root 0:00 ps aux $ docker exec mustpl_example cat /rendered.txt [config] value = foobar # \u0026lt;-- а вот и наше значение! $ docker kill mustpl_example    Таким образом, если тебе понадобиться запустить приложение в контейнере, которое для своей конфигурации требует именно файл (а не флаги запуска или переменные окружения), и у тебя есть желание не хардкодить значения кофигурации, а сделать возможность их менять с помощью переменных окружения - то однозначно присмотреть к этой тулзовине.\nВместо заключения Область применения этой утилиты, естественно, довольно ограничена. Да, она не умеет Jinja-like модификаторов, кастомных функций (хотя, они описаны в спецификации mustache), да много ещё чего. Но она умеет просто шаблонизировать, и если сделает кому-то жизнь чуточку проще - я буду счастлив. Инструкции по установке, готовые бинарники, документация - всё это найдете в репозитории этой тулы. Отдельное спасибо @jetexe и @alexndr-novikov за ревью и режим \u0026ldquo;желтой уточки\u0026rdquo;.\n","date":"2022-08-26T13:19:03Z","image":"https://blog.iddqd.uk/mustpl/cover_hu905bf7997fa62c11dfde3aa08d117e40_34086_120x120_fill_q75_box_smart1.jpg","permalink":"https://blog.iddqd.uk/mustpl/","title":"Шаблонизация в CLI может быть простой"},{"content":"Часто на интервью задают вопросы связанные не только с основным/дополнительным ЯП или СУБД, но и с тем, как приложения взаимодействуют между собой используя сетевую коммуникацию. Для понимания того, как эти шестерёнки вращаются и что нужно иметь в виду отвечая на вопросы из этой серии и была написана эта заметка.\n Что происходит после ввода адреса в браузер?  DNS Отправка пакета TLS Handshake HTTP запрос   Перечисли все уровни модели OSI? Что такое IP адрес? Какие режимы передачи данных бывают? Что такое NAT? Расскажи про DHCP? Что такое ICMP? Что такое TCP/IP?  IP (Internet Protocol) TCP (Transmission Control Protocol) UDP (User Datagram Protocol)   Какие бывают версии HTTP?  HTTP/0.9 HTTP/1.0 HTTP/1.1 HTTP/2 HTTP/3   Как работает HTTPS?  SSL TLS Шифрование      Что происходит после ввода адреса в браузер? Адрес (по-другому URL), который был введён в строку адреса состоит из:\n Протокола, который используется для доступа к ресурсу (http, https, ftp и т.д.)  Если протокол введён не был, то браузер смотрит - есть ли он у него в списке HSTS (HTTP Strict Transport Security, механизм принудительно активирующий защищенное соединение через протокол https), и если домен есть у него в списке - запрос будет отправлен используя протокол https, иначе - http (включается он с помощью HTTP заголовка на сервере домена Strict-Transport-Security: max-age=31536000; includeSubDomains; preload;)   Хоста или домена (example.com, linux.org) Номера порта (опционально)  Для общения с веб-сервером на запрашиваемом домене, нам нужно установить TCP соединение с определенным портом. В случае, если он указан явно (http://1.1.1.1:8080) - то используется он, а иначе - используется стандартный порт для запрошенного протокола (80 для http, 443 для https, и так далее)   И запроса (query, ресурс, URN) - строки адреса ресурса (например - адрес страницы)  DNS После разбора адреса мы должны установить соединение с сервером, и сделать это по IP адресу (а не доменному имени, TCP/IP же), для чего нам нужно преобразовать имя домена в IP адрес (другими словами - разрезолвить адрес; вообще, домены используются в первую очередь для удобства, и для возможности размещать несколько сайтов на одном IP адресе). Для этого:\n Сперва браузер смотрит в свой кэш (браузера) Если там не обнаружено - то смотрит в файл hosts (в котором можно захардкодить любой IP для любого домена) Если и там нет, но смотрит в кэше операционной системы (systemd-resolve) Если нигде нет, то отправляется за адресом в сеть:  Отправляется запрос на сетевой DNS сервер (который был получен по DHCP или прописан ручками)  Если и у него нет, то он (сервер) идёт в корневой сервер, тот - в DNS сервер ответственный за зону (например - .com) - и так до тех пор, пока целевой NS (где хранятся записи) не будет найден Когда целевой NS сервер достигнут (тот, где и содержится искомая запись для домена; обычно это A или CNAME) - то IP адрес сервера (A запись содержит IP, а вот с CNAME история резолвинга повторяется по кругу, так как она просто перенаправляет на другое доменное имя) возвращается по цепочке обратно (до запросившей её стороны), попутно кэшируясь на промежуточных серверах (если это необходимо и возможно)      Отправка пакета Далее, когда нам известен IP адрес сервера, мы можем сформировать и отправить запрос. Вспоминая устройство стека протоколов TCP/IP происходит следующее:\n На прикладном уровне (application layer) браузером формируется запрос к серверу (будь то DNS, HTTP, HTTPS и тому подобное) Далее, на транспортном уровне (transport layer, TCP или UDP протокол) в заголовки пакета добавляется порт, по которому нужно стучаться На сетевом уровне (network layer, IP протокол) добавляется IP адрес к нашему пакету На канальном уровне (data link layer) с помощью ARP (Address Resolution Protocol, протокол предназначенный для определения MAC-адреса другого компьютера по известному IP-адресу) определяется \u0026ldquo;есть ли такой адрес в сети?\u0026rdquo;  Если адрес есть в сети - то к нему передаётся пакет В противном случае пакет передаётся на шлюз, который, поднимаясь по уровням выше (смотря на то, какой IP адрес и смотря свою таблицу маршрутизации) - направляет пакет в нужном направлении (пока не закончится TTL протокола IP, либо пакет не достигнет пункта своего назначения)    TLS Handshake Если запрос был отправлен по протоколу https, то наступает пора установить защищенное соединение (TLS Handshake), для этого:\n Браузер отправляет Client hello серверу со своей версией протокола TLS (например - TLSv1.3) Сервер отвечает клиенту сообщением Server hello, содержащим версию TLS, выбранным методом шифрования, методом компрессии и публичным сертификатом сервиса (подписанный центром сертификации; сертификат содержит публичный ключ, который будет использоваться клиентом для шифрования) Клиент подтверждает сертификат сервера с помощью своего списка центров сертификации (если сертификат сервера подписан центром из списка - то ему можно доверять) Клиент отправляет серверу некоторые данные, зашифрованные с помощью публичного ключа сервера Сервер расшифровывает сообщение с помощью своего приватного ключа и генерирует симметричный мастер-ключ Клиент отправляет серверу сообщение Finished, шифруя хэш передачи с помощью симметричного ключа Сервер генерирует собственный хэш, а затем расшифровывает полученный от клиента хэш что бы проверить совпадает ли он с собственным; если совпадение обнаружено - сервер отправляет клиенту Finished, а так же зашифрованный собственный симметричный ключ Далее клиент и сервер отправляют сообщения с помощью этого симметричного ключа  HTTP запрос На прикладном уровне браузер формирует запрос к серверу по http протоколу:\n В запрос вставляется используемый HTTP-метод (в нашем случае это будет GET) Далее указывается URN (запрос, или query-строка) Версия используемого протокола (например - HTTP/1.1) И на новой строке указывается заголовок Host с именем запрашиваемого домена (так как на одном IP может быть несколько виртуальных серверов) и другие заголовки, формируемые самим браузером или иным ПО  После формирования запроса на прикладном уровне он передаётся на транспортный уровень (и ниже) и по установленному ранее (в случае с http) TCP соединению доставляется на сервер. Сервер же:\n По номеру запрошенного порта определяет какому приложению он адресован Смотрит в HTTP-заголовок Host для определения какому сайту (виртуальному серверу) он был адресован Определяет, может ли виртуальный хост обработать запрошенный метод и куда его отдавать на обработку по запрошенному URN (строке запроса)  После обработки запроса сервер вернёт клиенту ответ на его запрос, содержащий версию HTTP протокола (в случае с HTTP/2), код ответа, и заголовки/тело запроса, если они имеются. Далее браузер уже принимает ответы от сервера и отображает страницу (рендерит её, HTML парсится во много проходов, для чего создаётся DOM и CSSOM).\n  Перечисли все уровни модели OSI?  L7 - Приложений или Прикладной (Application layer), например HTTP, FTP, WebSocket L6 - Представления (Presentation layer), например ASCII, JPEG L5 - Сеансовый (Session layer), например RPC, L2TP, gRPC L4 - Транспортный (Transport layer), например TCP, UDP, порты L3 - Сетевой (Network layer), например IPv4, IPsec, ICMP L2 - Канальный (Data Link layer), например PPP, IEEE, Ethernet, сетевая карта L1 - Физический (Physical layer), например USB, RJ (витая пара), радиоканал     Что можно почитать:\n Wiki: Сетевая модель OSI   Что такое IP адрес? Это уникальный внутри подсети идентификатор устройства сетевого уровня модели OSI (протокола IP), который состоит из 4 байт (32 бита; в IPv6 используется 128 бит для кодирования адреса). Всего может существовать 4_294_967_296 адресов.\nIP адрес у устройства может быть статический (не меняется и всегда остается одним и тем же) и динамический (назначается на определенное время, затем заменяется другим).\nКакие режимы передачи данных бывают? Механизм передачи данных или информации между двумя связанными устройствами, соединенными по сети, называется режимом передачи.\n Симплексный - связь является однонаправленной, то есть данные могут передаваться только в одном направлении (как на улице с односторонним движением; пример - клавиатура, телевизионное вещание) Полудуплексный - данные могут передаваться в обе стороны, но не одновременно (пример - рация) Полнодуплексный - данные могут одновременно передаваться в обе стороны (как на улице с двухсторонним движением)  Что такое NAT? Сети обычно проектируются с использованием частных IP адресов. Частные адреса используются внутри организации или площадки, чтобы позволить устройствам общаться локально, и они не маршрутизируются в интернете:\n 10.0.0.0/8 (10.0.0.0 – 10.255.255.255/8, 16_777_216 хостов) 172.16.0.0/12 (172.16.0.0 – 172.31.255.255/12, 1_048_576 хостов) 192.168.0.0/16 (192.168.0.0 – 192.168.255.255/16, 65_536 хостов)  Чтобы позволить устройству с приватным IPv4-адресом обращаться к устройствам и ресурсам за пределами локальной сети, приватный адрес сначала должен быть переведен на общедоступный (публичный) адрес, чем NAT (Network Address Translation) и занимается (переводит приватные адреса, в общедоступные).\nNAT позволяет устройству с частным адресом IPv4 обращаться к ресурсам за пределами его частной сети. NAT в сочетании с частными адресами IPv4 оказался полезным методом сохранения общедоступных IPv4-адресов. Один общедоступный IPv4-адрес может быть использован сотнями, даже тысячами устройств, каждый из которых имеет частный IPv4-адрес. NAT имеет дополнительное преимущество, заключающееся в добавлении степени конфиденциальности и безопасности в сеть, поскольку он скрывает внутренние IPv4-адреса из внешних сетей.\nЧаще всего для трансляции IP адресов NAT использует тип трансляции PAT (Port Address Translation) - транслирует несколько частных адресов на один или несколько общедоступных адресов. Фактически, PAT \u0026ldquo;привязывает\u0026rdquo; каждый сеанс выхода клиента из внутренней сети во внешнюю к своему случайному порту (из диапазона 0-511, 512-1023 или 1024-65535), тем самым \u0026ldquo;запоминая\u0026rdquo; куда (какому именно клиенту) отправить полученные в ответе пакеты обратно.\n Что можно почитать:\n NAT на пальцах - что это?   Расскажи про DHCP? Dynamic Host Configuration Protocol (DHCP) - это прикладной протокол (L7 по модели OS, передача данных производится при помощи протокола UDP), позволяющий сетевым устройствам автоматически получать IP-адрес и другие параметры (сетевую маску, адреса DNS серверов), необходимые для работы в сети TCP/IP. Доступен как для IPv4 (DHCPv4), так и для IPv6 (DHCPv6).\nDHCPv4 включает три разных механизма распределения адресов:\n Ручное распределение (Manual Allocation) - администратор назначает предварительно установленный IPv4-адрес клиенту, а DHCP сервер передает IPv4-адрес на устройство Автоматическое распределение(Automatic Allocation) - DHCPv4 автоматически назначает статический IPv4-адрес на устройство, выбирая его из пула доступных адресов. Нет аренды (lease), и адрес постоянно назначается устройству Динамическое распределение (Dynamic Allocation) - DHCPv4 динамически назначает или дает в аренду IPv4-адрес из пула адресов в течение ограниченного периода времени, выбранного сервером, или пока клиент больше не нуждается в адресе  DHCPv4 работает в режиме клиент (порт 67) - сервер (порт 68). Когда клиент взаимодействует с сервером DHCPv4, сервер назначает или арендует IPv4-адрес этому клиенту. Он подключается к сети с этим арендованным IP-адресом до истечения срока аренды и должен периодически связываться с сервером DHCP, чтобы продлить аренду. Этот механизм аренды гарантирует, что клиенты, которые перемещаются или выходят из строя - не сохраняют за собой адреса, которые им больше не нужны. По истечении срока аренды сервер DHCP возвращает адрес в пул, где он может быть перераспределен по мере необходимости.\nРассмотрим процесс получения адреса:\n Когда клиент хочет присоединиться к сети, он начинает четырех-этапный процесс для получения аренды. Он запускает процесс с широковещательным (broadcast) сообщением DHCPDISCOVER со своим собственным MAC-адресом для обнаружения доступных DHCP-серверов. Поскольку у клиента нет способа узнать подсеть, к которой он принадлежит, у сообщения DHCPDISCOVER адрес назначения IPv4 адреса - широковещательный адрес 255.255.255.255 (т.е. отправляется всем устройствам в его сети на сетевом L3 уровне) и целевой MAC-адрес FF:FF:FF:FF:FF:FF (тоже является широковещательным для канального L2 уровня). А поскольку у клиента еще нет настроенного адреса IPv4, то исходный IPv4-адрес - 0.0.0.0 Когда DHCPv4-сервер получает сообщение DHCPDISCOVER, он резервирует доступный IPv4-адрес для аренды клиенту. Сервер также создает запись ARP, состоящую из MAC-адреса клиента и арендованного IPv4-адреса DHCP сервер отправляет связанное сообщение DHCPOFFER запрашивающему клиенту, как одноадресная передача (unicast), используя MAC-адрес сервера в качестве исходного адреса и MAC-адрес клиента в качестве адреса доставки Когда клиент получает DHCPOFFER с сервера, он отправляет обратно сообщение DHCPREQUEST. Это сообщение используется как для получения, так и для продления аренды При получении сообщения DHCPREQUEST сервер проверяет информацию об аренде с помощью ICMP-запроса на этот адрес, чтобы убедиться, что он уже не используется и создает новую ARP запись для аренды клиента, а затем отвечает одноадресным DHCPACK-сообщением. Это сообщение является дубликатом DHCPOFFER, за исключением изменения поля типа сообщения. Когда клиент получает сообщение DHCPACK, он регистрирует информацию и выполняет поиск ARP для назначенного адреса. Если ответа на ARP нет, клиент знает, что адрес IPv4 действителен и начинает использовать его как свой собственный   Что можно почитать:\n Wiki: DHCP   Что такое ICMP? Internet Control Message Protocol (ICMP) - это сетевой протокол (L3 по модели OSI) который чаще всего используется для передачи сообщений об ошибках и других исключительных ситуациях, возникших при передаче данных. Хотя формально протокол использует IP (ICMP-пакеты инкапсулируются в IP пакеты), он является неотъемлемой частью IP-протокола и обязателен при реализации стека TCP/IP.\nICMP основан на протоколе IP. Каждое ICMP-сообщение инкапсулируется непосредственно в пределах одного IP-пакета, и, таким образом, как и UDP и в отличие от TCP, ICMP является т. н. «ненадежным» (не контролирующим доставку и её правильность).\nНапример, каждая машина, которая перенаправляет IP-пакеты (например маршрутизатор), уменьшает значение поля Time to live (TTL) заголовка IP-пакета на единицу; если TTL достигает 0, на источник пакета отправляется ICMP-сообщение о превышении TTL.\n Что можно почитать:\n Wiki: ICMP   Что такое TCP/IP? Изначально стек протоколов TCP/IP разработан в 1972 году на основе Network Control Protocol, но только спустя 4 года создана передача данных с применением протокола TCP. К концу 80-х было выделено две отдельные функции – TCP и IP. И уже к 1983 году удалось полностью перейти на современный протокол, что и считается отправной точкой развития Интернета.\nСтек модели TCP/IP контролирует взаимодействие различных уровней системы (стек делится на отдельные уровни, каждый из которых направлен на решение определенной задачи). Ключевыми в нем являются сами протоколы, которые встраиваются друг в друга (работают одновременно, без конфликтов, сбоев и незавершенных операций) и обеспечивают передачу данных.\nIP (Internet Protocol) Маршрутизируемый протокол сетевого уровня модели стека протоколов TCP/IP, нужен для логической адресации устройств в компьютерной сети или сети передачи данных. Ключевые понятия о протоколе IP:\n Каждый узел на сетевом уровне в модели TCP/IP должен иметь IP-адрес, который состоит из 4 байт (254.254.254.254) Минимальной единицей измерения данных здесь является IP-пакет (который чаще всего инкапсулируется в Ethernet кадр) При доставке IP-пакета возможна его фрагментация (дробление) на более мелкие (получатель должен будет его собрать обратно). Так же возможен и запрет на фрагментацию (отправителю будет отправлен ICMP-сообщение об ошибке) Функция IP протокола заключается в том, чтобы доставить пакет из точки А в точку Б через множество промежуточных сетей (при этом IP-пакеты при передаче данных могут быть изменены, потеряны, повреждены, пакеты могут прийти получателю не в той последовательности, в которой они были отправлены - обо всем этом протокол IP не заботится, его задачей является организовать маршрут) Протокол использует передачу данных без установки соединения  Размер заголовка IP-пакета составляет от 20 (обычный заголовок без дополнительных опций) до 60 байт.\nTCP (Transmission Control Protocol) Протокол транспортного уровня, управляющий передачей данных. Фактически, если IP протокол связывает между собой машины в сети, то TCP связывает конкретные приложения используя порты (которых одновременно на машине может быть до 65535, т.к. номер порта занимает 2 байта). Ключевые характеристики:\n Требует установки соединения (для этого сервер делает passive open - ждёт входящие запросы, а клиент active open - отправляет серверу SYN, на что сервер должен ответить ACK + SYN, клиент в ответ на это должен ответить ACK, и после этого соединение считается установленным) Нумерует пакеты, посылает подтверждения о получении данных (ACK) и запрашивает повторную передачу, если данные не получены или искажены (или истёк таймаут для ответа), т.е. обеспечивает гарантию доставки Любое установленное TCP-соединение симметрично, и пакеты с данными по нему всегда идут в обе стороны (двунаправленная взаимосвязь) Когда один из узлов решает, что пора заканчивать соединение, он посылает специальный пакет FIN, после этого узлы прощаются и разрывают соединение Использование принципа \u0026ldquo;скользящего окна\u0026rdquo; для увеличения скорости передачи (ACK не каждого сообщения, а определенной \u0026ldquo;пачки\u0026rdquo;; причём размер окна может меняться динамически) Контролирует загруженность соединения  UDP (User Datagram Protocol) Протокол транспортного уровня, передающий сообщения-датаграммы без необходимости установки соединения в IP-сети. UDP допускает потери пакетов, их дублирование, перемешивание, но контролирует целостность полученных датаграмм. Так же UDP не контролирует загруженность канала (более жадный).\nБлагодаря такой не избирательности и бесконтрольности, UDP доставляет пакеты данных (датаграммы) гораздо быстрее, потому для приложений, которые рассчитаны на широкую пропускную способность и быстрый обмен, UDP можно считать оптимальным протоколом. К таковым относятся сетевые и браузерные игры, а также программы просмотра потокового видео и приложения для видео (или голосовой) связи - от потери пакета, полной или частичной, ничего не меняется, повторять запрос не обязательно, зато загрузка происходит намного быстрее.\nЯ бы рассказал отличную шутку про UDP, но боюсь, не до всех она дойдёт 😄\n   Что можно почитать:\n Wiki: IP IP-пакет в протоколе IPv4. Структура, заголовок и поля в IP-пакете Протоколы TCP и UDP   Какие бывают версии HTTP? HTTP (HyperText Transfer Protocol) - это клиент-серверный протокол прикладного уровня, реализованный поверх протокола TCP/IP (третья версия протокола работает используя UDP). Сам HTTP зависит от протокола TCP/IP (UDP), позволяющего посылать и отправлять запросы между клиентом и сервером. По умолчанию используется 80 порт TCP, но могут использоваться и другие (HTTPS, например, использует 443 порт).\nВыполнить простейший HTTP запрос можно с помощью telnet:\n$ telnet google.com 80 Trying 142.251.1.113... Connected to google.com. Escape character is \u0026#39;^]\u0026#39;. GET /robots.txt HTTP/1.1 Host: google.com # просто 2 пустые строки (2 раза нажми enter) HTTP/1.1 301 Moved Permanently (headers) (content) HTTP/0.9 Появился в конце 1990 года (разработан Тимом Бернерсом-Ли) и был экстремально простым - запрос состоял из одной строки и умел только метод GET (GET /mypage.html), а ответ в свою очередь только контент ответа (обычно HTML; без заголовков) и даже без кода ответа.\nGET /mypage.html \u0026lt;HTML\u0026gt; A very simple HTML page \u0026lt;/HTML\u0026gt; HTTP/1.0 Спецификация (RFC 1945) была опубликована в ноябре 1996 года. Информация о версии протокола теперь отправляется с каждым запросом (GET /mypage.html HTTP/1.0). Код ответа отправляется в самом начале ответа (200 OK). Добавлена поддержка заголовков (как запросов, так и ответов) для передачи мета-информации. К методу GET добавились HEAD, POST, PUT, DELETE, LINK, UNLINK. Кроме того, с помощью заголовка Content-Type стало возможным передавать разные типы контента:\nGET /mypage.html HTTP/1.0 User-Agent: NCSA_Mosaic/2.0 (Windows 3.1) 200 OK Date: Tue, 15 Nov 1996 08:12:31 GMT Server: CERN/3.0 libwww/2.17 Content-Type: text/html \u0026lt;HTML\u0026gt; A page with an image \u0026lt;IMG SRC=\u0026#34;/myimage.gif\u0026#34;\u0026gt; \u0026lt;/HTML\u0026gt; Для каждого запроса и ответа между клиентом и сервером создаётся новое TCP-соединение (пожалуй, главный недостаток, поскольку каждое новое TCP-соединение требует \u0026ldquo;тройного рукопожатия\u0026rdquo;, за которым следует медленный старт).\nHTTP/1.1 Появился всего через несколько месяцев после версии 1.1 (в январе 1997 года, RFC 2068, и по 2014 год выходили \u0026ldquo;дополнительные\u0026rdquo; RFC для этой версии протокола), и изменения были следующие:\n Соединение могло быть пере-использовано (не требуется постоянно поднимать новое TCP соединение для запроса, управляется с помощью заголовка Connection: close или Connection: keep-alive) Добавлена поддержка заголовка Host содержащего имя домена, для которого предназначен запрос (опционально и номер порта), что позволило держать на одном IP множество доменов (сайтов) Добавлены методы OPTIONS, TRACE, PATCH, CONNECT (последний добавлен в 2014 году) Добавлено согласование контента (включающее в себя язык Accept-Language: \u0026lt;lang\u0026gt;, кодировку Accept-Encoding: \u0026lt;directives\u0026gt;, тип данных - Accept: \u0026lt;mime_type\u0026gt;/* и другие) Добавлены заголовки управления кэшированием контента (Cache-Control: \u0026lt;directives\u0026gt;, Expires: \u0026lt;http-date\u0026gt;, Last-Modified: \u0026lt;when\u0026gt;, ETag: \u0026lt;hash\u0026gt; и другие) Добавлена возможность доставки контента частями (или чанками, chunks), управляется заголовком Transfer-Encoding: \u0026lt;directives\u0026gt; и другими (в этом случае нет необходимости заранее знать точный размер всего тела HTTP-сообщения); HTTP/2 не поддерживает эту фичу, но имеет другие, более эффективные механизмы для потовой передачи данных Добавлена конвейерная обработка, позволяющая передавать сразу несколько запросов в одном соединении, не ожидая соответствующих ответов (но нужно помнить, что сервер должен отдавать ответы в строго той же последовательности, как получались запросы, и один затормозивший запрос тормозит все последующие в \u0026ldquo;пачке\u0026rdquo;); в HTTP/2 эта фича была заменена на мульти-плексирование Добавлена возможность использования заголовка Upgrade: \u0026lt;protocol\u0026gt;[/\u0026lt;version\u0026gt;] для переключения на другой протокол, например HTTP/2.0 или WebSockets, и эта функциональность присуща только версии HTTP/1.1  GET /en-US/docs/Glossary/Simple_header HTTP/1.1 Host: developer.mozilla.org User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 Accept-Language: en-US,en;q=0.5 Accept-Encoding: gzip, deflate, br Referer: https://developer.mozilla.org/en-US/docs/Glossary/Simple_header 200 OK Connection: Keep-Alive Content-Encoding: gzip Content-Type: text/html; charset=utf-8 Date: Wed, 20 Jul 2016 10:55:30 GMT Etag: \u0026#34;547fa7e369ef56031dd3bff2ace9fc0832eb251a\u0026#34; Keep-Alive: timeout=5, max=1000 Last-Modified: Tue, 19 Jul 2016 00:59:33 GMT Server: Apache Transfer-Encoding: chunked Vary: Cookie, Accept-Encoding (content) HTTP/2 Спецификация (RFC 7540) была опубликована в мае 2015 года, основан на протоколе SPDY (a.k.a \u0026ldquo;speedy\u0026rdquo;, разработан Google в 2012 году, поддержка которого прекратилась в феврале 2015 в пользу HTTP/2; при его использовании время загрузки страниц уменьшалось на ~36%). В 2021 году порядка 50,2% самых популярных сайтов поддерживают этот протокол.\nВ отличии от HTTP/1.1:\n Протокол стал бинарным (сообщения быстрее разбираются автоматически, но неудобны для чтения человеком), основные составляющие HTTP/2 — фреймы (Frames) и потоки (Streams):  HTTP-сообщения состоят из одного или более фреймов (HEADERS для мета-данных, DATA для данных, RST_STREAM для прерывания потоков - при этом соединение останется открытым что позволяет работать остальным потокам, SETTINGS, PRIORITY и другие) Каждый запрос и ответ HTTP/2 получает уникальный ID потока и разделяется на фреймы Фреймы представляют собой просто бинарные части данных; коллекция фреймов называется потоком (Stream) Каждый фрейм содержит ID потока, показывающий, к какому потоку он принадлежит; а также каждый фрейм содержит общий заголовок (идентификатор потока уникален; каждый клиентский запрос использует нечётные id, а ответ от сервера — чётные)   Добавлено мультиплексирование - передача нескольких асинхронных HTTP-запросов по одному TCP-соединению  Ответ сервера не имеет порядка, и клиент использует ID потока, чтобы понять, к какому потоку принадлежит тот или иной пакет Клиенту не придётся простаивать, ожидая обработки длинного запроса, ведь во время ожидания могут обрабатываться остальные запросы   Реализовано сжатие передаваемых заголовков (методом HPACK)  Клиент и сервер поддерживают единую таблицу заголовков Повторяющиеся заголовки (например, user-agent) опускаются при повторных запросах и ссылаются на их позицию в таблице заголовков Сами заголовки ничем не отличаются от HTTP/1.1, но добавились псевдо-заголовки вида :method, :scheme, :host, :path   Появился Server Push - несколько ответов на один запрос  Сервер имеет право послать то содержимое, которое ещё не было запрошено клиентом, используя специальный фрейм PUSH_PROMISE   Добавлена явная приоритизация запросов (используя фрейм HEADERS которым открывается поток, или в любое другое время используя фрейм PRIORITY) Повышена безопасность (хотя спецификация не требует шифрования для HTTP/2, оно всё равно станет обязательным по умолчанию, так как браузеры без шифрования не работают с этим протоколом)  Так же стоит знать, что мультиплексирование ведёт к проблеме доставки контента при ошибках на сетевом уровне. Представьте, что мы асинхронно выполняем 5 запросов к одному серверу. При использовании HTTP/2 все эти запросы будут выполняться в рамках одного TCP-соединения, а значит, если один из сегментов любого запроса потеряется или придёт неверно, передача всех запросов и ответов остановится, пока не будет восстановлен потерявшийся сегмент (у этой проблемы есть и название - \u0026ldquo;head-of-line blocking\u0026rdquo;). Очевидно, что чем хуже качество соединения, тем медленнее работает HTTP/2 (когда потерянные пакеты составляют всего 2% от всех, HTTP/1.1 в браузере показывает себя лучше, чем HTTP/2 за счёт того, что открывает 6 соединений, а не одно).\nHTTP/3 Проектируется для решения проблем HTTP/2 и сейчас проходит тестирование с опубликованной спецификацией. Новый протокол должен решать текущие проблемы скорости, надёжности и безопасности для широкого сектора устройств. HTTP/3 строится на основе нового протокола QUIC, разрабатываемого в Google с 2012 года. Основные отличия от предшественника:\n Вместо TCP будет использоваться UDP QUIC сам обеспечивает мультплексирование, и потеря одного пакета повлияет только на имеющий к этому пакету поток, другие потоки в рамках соединения продолжат свою работу Заголовки запросов и ответов сжимаются QPACK вместо HPACK Для шифрования используется TLS 1.3 (эффективно использующийся в HTTPS) - оно включено в протокол  Это позволяет устанавливать соединение и обмениваться публичными ключами за одно рукопожатие, а также позволяет использовать хитрый механизм 0-RTT handshake и вообще избежать задержек при рукопожатии Кроме того, теперь можно шифровать отдельные пакеты данных (это позволяет не ждать завершения приёма данных из стрима, а расшифровывать полученные пакеты независимо)   Концепция лёгких стримов позволяет отвязать соединение от IP-адреса клиента (например, когда клиент переключается с одной Wi-Fi точки доступа на другую, изменяя свой IP - при использовании TCP происходит длительный процесс, в ходе которого существующие TCP-соединения отваливаются по таймауту; в случае с QUIC, клиент просто продолжает посылать серверу пакеты с нового IP со старым ID стрима) QUIC реализуется на уровне приложения, а не операционной системы (позволяет быстрее вносить изменения в протокол, т.к. чтобы получить обновление достаточно просто обновить библиотеку, а не ждать новую версию ОС)  Последние версии браузеров Chrome, Firefox, Edge, Opera и некоторые мобильные браузеры уже поддерживают работу по HTTP/3, но для работы должна быть и поддержка со стороны сервера. На данный момент HTTP/3 активно используется в Google и Cloudflare.\nПо статистике на июль 2021 года только 20% вебсайтов доступны по HTTP/3. По отчетам Google через gQUIC страницы загружаются примерно на 5% быстрее, а в потоковом видео на 30% меньше подвисаний по сравнению с TCP.\nК слабым сторонам протокола пока что можно отнести высокое потребление CPU, жадность (unfairness) к пропускной способности канала и более медленная передача небольших (до 10 кб) объектов. А так же неготовность интернета к полному переходу на UDP.\n Что можно почитать:\n Evolution of HTTP Путь к HTTP/2 HTTP/3: прошлое, настоящее и будущее Введение в HTTP/2   Как работает HTTPS? Проблема протокола HTTP в том, что данные передаются по сети в открытом незашифрованном виде. Это позволяет злоумышленнику слушать передаваемые пакеты и извлекать любую информацию из параметров, заголовков и тела сообщения. Для устранения уязвимости был разработан HTTPS (S в конце значит Secure) - он, хоть не является отдельным протоколом, всего лишь HTTP поверх SSL (а позже TLS), позволяет безопасно обмениваться данными. В отличие от HTTP со стандартным TCP/IP портом 80, для HTTPS используется порт 443.\nДля того, чтоб ваш сервер был доступен по https необходимо выпустить сертификат, подписанный центром сертификации (который является доверенным), и сконфигурировать используемое ПО на его использование.\nSSL Secure Sockets Layer (SSL) - это криптографический протокол, обеспечивающий безопасное общение пользователя и сервера по небезопасной сети. Располагается между транспортным уровнем и уровнем программы-клиента (FTP, HTTP и т.п.). С 2015 года признан полностью устаревшим.\nTLS Transport Layer Security - это развитие идей, заложенных в протоколе SSL. На данный момент актуальной является версия TLSv1.3. Протокол обеспечивает услуги: приватности (сокрытие передаваемой информации), целостности (обнаружение изменений), аутентификации (проверка авторства). Достигаются они за счет гибридного шифрования, то есть совместного использования ассиметричного и симметричного шифрования.\nШифрование Симметричное шифрование предполагает наличие общего ключа одновременно у отправителя и получателя, с помощью которого происходит шифровка и дешифровка данных.\nПри использовании ассиметричного шифрования существует открытый ключ, который можно свободно распространять, и закрытый ключ, который держится в секрете у одной из сторон. Этот тип работает медленно, относительно симметричного шифрования, однако скомпрометировать закрытый ключ сложнее.\nЧтобы решить проблему производительности (шифровать ассиметрично абсолютно все - сложно), в TLS используется гибридное шифрование - общий ключ для симметричного шифрования данных передается от клиента серверу зашифрованным открытым ключом сервера, после этого сервер может его расшифровать своим закрытым ключом и использовать для обмена данными с клиентом.\nДля установки безопасного соединения происходит TLS Handshake, который схематично выглядит следующим образом:\n Что можно почитать:\n Основы HTTPS, TLS, SSL  ","date":"2022-02-14T12:37:08Z","image":"https://blog.iddqd.uk/interview-section-network/cover_hu21de3eef183cf18e204d3e54b899aa35_31715_120x120_fill_box_smart1_3.png","permalink":"https://blog.iddqd.uk/interview-section-network/","title":"Вопросы и ответы по сетям и протоколам"},{"content":"В этой заметки содержатся (и, возможно, будут периодически добавляться) задачи на лайв-кодинг для Go разработчиков, что встречаются на интервью, либо являются хорошими кандидатами для этого.\nЛучше всего чтоб ты самостоятельно попытался решить эти задачи, и только для проверки результата смотрел код готовых решений.\n Найти пересечение двух неупорядоченных слайсов любой длины Развернуть односвязный список Написать генератор случайных чисел Слить N каналов в один Сделать конвейер чисел Сделать кастомную WaitGroup на семафоре Алгоритм бинарного (двоичного) поиска Обход ссылок из файла    Найти пересечение двух неупорядоченных слайсов любой длины Перечесение - это те элементы, что присутствуют в обоих слайсах, то есть:\n f([]int{1, 2, 2, 1}, []int{2, 2}) == []int{2, 2} f([]int{4, 9, 5}, []int{9, 4, 9, 8, 4}) == []int{4, 9} or []int{9, 4}  Можно решить сортировкой, за более долгое время, но без выделения дополнительной памяти. А можно выделить дополнительную память и решить за линейное время:\nРешение  package main import \u0026#34;fmt\u0026#34; func intersection(one, two []int) []int { var m = make(map[int]uint) // не делаем пре-аллокацию, так как не знаем количество дублей  for i := range one { // пробегаясь по первому слайсу \u0026#34;прогреваем\u0026#34; карту  m[one[i]]++ // так как нулевое значение для uint это 0 - то просто увеличиваем \t} var result = make([]int, 0) // тоже без пре-аллокации, т.к. не знаем сколько пересечений  for i := range two { // пробегаясь по второму - ищем пересечение \tif value, ok := m[two[i]]; ok { if value \u0026gt; 0 { m[two[i]]-- result = append(result, two[i]) } else { delete(m, two[i]) // прибираемся, так как ключ уже не нужен (== 0) \t} } } return result } func main() { fmt.Printf(\u0026#34;%v\\n\u0026#34;, intersection([]int{23, 3, 1, 2}, []int{6, 2, 4, 23})) // [2, 23]  fmt.Printf(\u0026#34;%v\\n\u0026#34;, intersection([]int{1, 1, 1}, []int{1, 1, 1, 1})) // [1, 1, 1] }    Сложность этого решения получается O(n+m) где n - это длина первого слайса и m второго (сложность вставки в мапу O(1); поиска тоже, чаще всего).\nИли вот универсальный вариант, что ищет пересечение в неограниченном количестве слайсов на входе:\nУниверсальное решение  package main import \u0026#34;fmt\u0026#34; func intersection(in ...[]int) []int { var result = make([]int, 0) if len(in) \u0026lt; 2 { return result } var longestSliceIdx = 0 for i := 0; i \u0026lt; len(in); i++ { // находим самый длинный слайс  if len(in[i]) \u0026gt; len(in[longestSliceIdx]) { longestSliceIdx = i } } var m = make([]map[int]uint, len(in)-1) // слайс из мап для счётчиков значений  for i, j := 0, 0; i \u0026lt; len(in); i++ { // \u0026#34;прогреваем\u0026#34; мапы по каждому полученному слайсу  if i == longestSliceIdx { // кроме самого длинного  continue } m[j] = make(map[int]uint) for _, k := range in[i] { m[j][k]++ } j++ } valuesLoop: for _, value := range in[longestSliceIdx] { // проходимся по всем значениям из самого длинного слайса  for _, mmap := range m { // пробегаемся по всем мапам, что хранят количество вхождений  if count, ok := mmap[value]; ok { // и если в карте найдено значение из самого длинного слайса  if count \u0026gt; 0 { // и его счётчик больше нуля  mmap[value]-- // то уменьшаем его счётчик и НЕ прерываем цикл  } else { // если значения есть и оно == 0  delete(mmap, value) // то удаляем его (прибираемся)  continue valuesLoop // и переходим к следующему значению (не ищем во всех мапах)  } } else { continue valuesLoop // если значения в мапе нет, то и в других мапах искать нет смысла  } result = append(result, value) } } return result } func main() { fmt.Printf(\u0026#34;%v\\n\u0026#34;, intersection([]int{23, 3, 1, 2}, []int{6, 2, 4, 23})) // [23, 2]  fmt.Printf(\u0026#34;%v\\n\u0026#34;, intersection([]int{1, 1, 1}, []int{1, 1, 1, 1})) // [1, 1, 1]  fmt.Printf(\u0026#34;%v\\n\u0026#34;, intersection([]int{1, 2, 2, 1}, []int{2, 2})) // [2, 2]  fmt.Printf(\u0026#34;%v\\n\u0026#34;, intersection([]int{4, 9, 5}, []int{9, 4, 9, 8, 4})) // [9, 4] }    Развернуть односвязный список Односвязный список (single linked list) может быть представлен структурой:\ntype LinkNode struct { next *LinkNode value int } Нужно создать три элемента, и связать их последовательно. А после развернуть этот список в обратную сторону.\nРешение  package main type LinkNode struct { next *LinkNode value int } func (l *LinkNode) Print() { // ставим current указателем на первый элемент, на каждой итерации заменяя его на next \t// до тех пор, пока current не станет nil \tfor current := l; current != nil; current = current.next { print(current.value) if current.next != nil { println(\u0026#34; -\u0026gt;\u0026#34;, current.next.value) } } println() } func main() { // инициализируем элементы списка \tvar n1, n2, n3 = LinkNode{value: 1}, LinkNode{value: 2}, LinkNode{value: 3} n1.next, n2.next = \u0026amp;n2, \u0026amp;n3 // и связываем их  n1.Print() // 1 -\u0026gt; 2 \t// 2 -\u0026gt; 3 \t// 3  // и теперь обратим список в зад \tvar prev, next *LinkNode // крутим цикл до тех пор, пока current не станет nil \tfor current := \u0026amp;n1; current != nil; { next, current.next = current.next, prev prev, current = current, next } n3.Print() // 3 -\u0026gt; 2 \t// 2 -\u0026gt; 1 \t// 1 }    Написать генератор случайных чисел Легкая задача, на базовые знания по асинхронному взаимодействию в Go. Главная особенность - не выделять память заранее под случайные числа, так как их могут быть миллионы (в этом же и есть весть смысл генератора). Функция RandomGen возвращает канал, в который пишутся случайные сислы и функцию, которая генератор останавливает, освобождая все необходимые ресурсы:\nРешение  package main import ( \u0026#34;math/rand\u0026#34; \u0026#34;sync/atomic\u0026#34; \u0026#34;time\u0026#34; ) func RandomGen() (\u0026lt;-chan int, func()) { var ( rnd = rand.New(rand.NewSource(time.Now().UnixNano())) out, exit = make(chan int), make(chan struct{}) exited uint32 // atomic usage only  ) go func() { defer close(out) // уходя гасим за собой свет (закрываем канал)  for { select { case \u0026lt;-exit: // закрытие канала exit вызовет этот case  return case out \u0026lt;- rnd.Int(): // пока канал exit не закрыт - отправляем  // do nothing  } } }() return out, func() { // вызов функции закроет канал exit  if atomic.CompareAndSwapUint32(\u0026amp;exited, 0, 1) { // защита от повторного вызова  close(exit) } } } func main() { rnd, stop := RandomGen() defer stop() // можно вызвать несколько раз - ничего страшного  for i := 0; i \u0026lt; 3; i++ { println(\u0026lt;-rnd) // выведет 3 случайных числа  } stop() // останавливаем генератор  println(\u0026lt;-rnd, \u0026lt;-rnd) // вернёт дважды 0 }    Слить N каналов в один Даны n каналов типа chan int. Надо написать функцию, которая смерджит все данные из этих каналов в один и вернет его. Мы хотим, чтобы результат работы функции выглядел примерно так:\npackage main func main() { var a, b, c = make(chan int), make(chan int), make(chan int) // ...  for num := range joinChannels(a, b, c) { println(num) } } Для этого создаём канал для смердженных данных, запускаем N горутин для чтения из каналов (по количеству каналов), и используем дополнительный канал для того, чтоб определить когда у нас работа будет завершена (эдакий аналог sync.WaitGroup):\nРешение  package main func joinChannels(in ...\u0026lt;-chan int) \u0026lt;-chan int { var ( out = make(chan int, len(in)) done = make(chan struct{}) // канал для пустых сообщений, аналог sync.WaitGroup  ) for i := 0; i \u0026lt; len(in); i++ { // запускаем горутины по кол-ву каналов на входе  go func(c \u0026lt;-chan int) { defer func() { done \u0026lt;- struct{}{} }() // по завершению работы пишем в канал \u0026#34;done\u0026#34;  for { value, isOpened := \u0026lt;-c if !isOpened { // если канал закрылся - то выходим  return } out \u0026lt;- value // иначе пишем в результирующий канал  } }(in[i]) } go func() { // запускаем отдельную горутину, которая ожидает завершения работы  for i := 0; i \u0026lt; len(in); i++ { // с помощью этого счётчика  \u0026lt;-done // который N раз просто читает пустую структуру и блокируется  } close(done) close(out) }() return out } func main() { var a, b, c = make(chan int), make(chan int), make(chan int) go func() { for _, num := range []int{1, 2, 3} { a \u0026lt;- num } close(a) }() go func() { for _, num := range []int{20, 10, 30} { b \u0026lt;- num } close(b) }() go func() { for _, num := range []int{300, 200, 100} { c \u0026lt;- num } close(c) }() for num := range joinChannels(a, b, c) { println(num) // 1, 2, 3, 20, 10, 300, 200, 30, 100  } }    Сделать конвейер чисел Даны два канала. В первый пишутся числа. Нужно, чтобы числа читались из первого по мере поступления, что-то с ними происходило (допустим, возводились в квадрат) и результат записывался во второй канал. Задача пердельно простая.\nРешение  package main func main() { var in, out = make(chan int), make(chan int) go func() { for i := 0; i \u0026lt; 10; i++ { in \u0026lt;- i } close(in) }() go func() { defer close(out) for { num, isOpened := \u0026lt;-in if !isOpened { return } out \u0026lt;- num * num } }() for num := range out { println(num) } }    Сделать кастомную WaitGroup на семафоре  Семафо́р (англ. semaphore) — примитив синхронизации работы процессов и потоков, в основе которого лежит счётчик, над которым можно производить две атомарные операции: увеличение и уменьшение значения на единицу, при этом операция уменьшения для нулевого значения счётчика является блокирующейся.\n Семафор можно легко получить из канала. Чтоб не аллоцировать лишние данные, будем складывать туда пустые структуры.\nРешение  package main type Semaphore chan struct{} func (s Semaphore) Increment(n int) { for i := 0; i \u0026lt; n; i++ { s \u0026lt;- struct{}{} } } func (s Semaphore) Decrement(n int) { for i := 0; i \u0026lt; n; i++ { \u0026lt;-s } } func main() { const count = 5 var s = make(Semaphore, count) for i := 0; i \u0026lt; count; i++ { go func(n int) { defer s.Increment(1) print(n, \u0026#34; \u0026#34;) }(i) } s.Decrement(count) // 1 4 3 2 0 (порядок будет произвольный) }    Решение с использованием atomic и каналов, полностью повторяет API sync.WaitGroup  package main import ( \u0026#34;sync\u0026#34; \u0026#34;sync/atomic\u0026#34; ) type WaitGroup struct { state int32 // atomic usage only  subsMu sync.Mutex subs []chan struct{} } func NewWaitGroup() WaitGroup { return WaitGroup{subs: make([]chan struct{}, 0)} } func (wg *WaitGroup) Add(n uint) { atomic.AddInt32(\u0026amp;wg.state, int32(n)) } func (wg *WaitGroup) Done() { if atomic.AddInt32(\u0026amp;wg.state, -1); atomic.LoadInt32(\u0026amp;wg.state) \u0026lt;= 0 { wg.subsMu.Lock() if wg.subs != nil { for i := 0; i \u0026lt; len(wg.subs); i++ { close(wg.subs[i]) // закрытие \u0026#34;стриггерит\u0026#34; все каналы  } wg.subs = nil } wg.subsMu.Unlock() } } func (wg *WaitGroup) Wait() { if atomic.LoadInt32(\u0026amp;wg.state) \u0026gt; 0 { var c = make(chan struct{}) wg.subsMu.Lock() wg.subs = append(wg.subs, c) wg.subsMu.Unlock() \u0026lt;-c // ожидаем закрытия канала (блокируемся)  } return } func main() { var wg = NewWaitGroup() wg.Wait() // пролетает сразу же, так как не было вызовов Add()  wg.Add(2) wg.Add(0) // ничего не делает  wg.Done() wg.Done() wg.Wait() // тоже пролетает сразу же  for i := 0; i \u0026lt; 5; i++ { wg.Add(1) go func(n int) { defer wg.Done() print(n, \u0026#34; \u0026#34;) }(i) } wg.Wait() // 1 4 3 2 0 (порядок будет произвольный) }    Алгоритм бинарного (двоичного) поиска Также известен как метод деления пополам или дихотомия - классический алгоритм поиска элемента в отсортированном массиве (слайсе), использующий дробление массива (слайса) на половины. У нас на входе может быть слайс вида []int{1, 3, 4, 6, 8, 10, 55, 56, 59, 70, 79, 81, 91, 10001}, и нужно вернуть индекс числа 55 (результат будет 6 true):\nРешение  package main func BinarySearch(in []int, searchFor int) (int, bool) { if len(in) == 0 { return 0, false } var first, last = 0, len(in) - 1 for first \u0026lt;= last { var mid = ((last - first) / 2) + first if in[mid] == searchFor { return mid, true } else if in[mid] \u0026gt; searchFor { // нужно искать в \u0026#34;левой\u0026#34; части слайса \tlast = mid - 1 } else if in[mid] \u0026lt; searchFor { // нужно искать в \u0026#34;правой\u0026#34; части слайса \tfirst = mid + 1 } } return 0, false }    Обход ссылок из файла Дан некоторый файл, в котором содержатся HTTP ссылки на различные ресурсы. Нужно реализовать обход всех этих ссылок, и вывести в терминал OK в случае 200-го кода ответа, и Not OK в противном случае. Засучаем рукава и в бой, пишем наивный вариант (читаем файл в память, и итерируем слайс ссылок):\nПервая итерация  package main import ( \u0026#34;bufio\u0026#34; \u0026#34;context\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; ) func main() { if err := run(); err != nil { println(err.Error()) os.Exit(1) } } func run() error { var ctx = context.Background() // открываем файл  f, err := os.Open(\u0026#34;links_list.txt\u0026#34;) if err != nil { return err } defer func() { _ = f.Close() }() // читаем файл построчно  var scan = bufio.NewScanner(f) for scan.Scan() { var url = strings.TrimSpace(scan.Text()) if ok, fetchErr := fetchLink(ctx, http.MethodGet, url); fetchErr != nil { return fetchErr } else { if ok { println(\u0026#34;OK\u0026#34;, url) } else { println(\u0026#34;Not OK\u0026#34;, url) } } } // проверяем сканер на наличие ошибок  if err = scan.Err(); err != nil { return err } return nil } // объявляем HTTP клиент для переиспользования var httpClient = http.Client{Timeout: time.Second * 5} func fetchLink(ctx context.Context, method, url string) (bool, error) { // создаём объект запроса  var req, err = http.NewRequestWithContext(ctx, method, url, http.NoBody) if err != nil { return false, err } // выполняем его  resp, err := httpClient.Do(req) if err != nil { return false, err } // валидируем статус код  if resp.StatusCode == http.StatusOK { return true, nil } return false, nil }    Файл со списком ссылок (links_list.txt):\nhttps://www.yahoo.com/foobar https://stackoverflow.com/foobar https://blog.iddqd.uk/ https://google.com/404error https://ya.ru/ https://github.com/foo/bar https://stackoverflow.com/ Запускаем код (go run .), видим результат:\nNot OK https://www.yahoo.com/foobar Not OK https://stackoverflow.com/foobar OK https://blog.iddqd.uk/ Not OK https://google.com/404error OK https://ya.ru/ Not OK https://github.com/foo/bar OK https://stackoverflow.com/ И тут интервьювер обновляет постановку задачи - нужно выполнять работу асинхронно. И сделать так, чтоб после получения двух OK останавливать всю работу, отменяя уже отправленные запросы. Приводим свой код в соответствие, используя каналы по-максимуму:\nВторая итерация  package main import ( \u0026#34;bufio\u0026#34; \u0026#34;context\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; ) func main() { if err := run(); err != nil { println(\u0026#34;Fatal error:\u0026#34;, err.Error()) os.Exit(1) } } type result struct { // объявляем структуру для описания результата опроса URL  url string ok bool } func run() error { var ctx, cancel = context.WithCancel(context.Background()) // заменяем контекст на контекст с отменой  defer cancel() f, err := os.Open(\u0026#34;links_list.txt\u0026#34;) if err != nil { return err } defer func() { _ = f.Close() }() var urlsCh, errCh, resultsCh = make(chan string), make(chan error), make(chan result) // объявляем каналы для работы  defer func() { close(errCh); close(resultsCh) }() go func() { // читаем файл построчно в отдельной горутине и пишем в каналы (запускаем \u0026#34;планировщик\u0026#34;)  defer close(urlsCh) // не забываем закрыть канал (когда список кончится или контекст отменится)  var scan = bufio.NewScanner(f) for scan.Scan() { select { case \u0026lt;-ctx.Done(): // проверяем контекст на факт его отмены  return default: if url := strings.TrimSpace(scan.Text()); url != \u0026#34;\u0026#34; { urlsCh \u0026lt;- url // и пишем в канал для ссылок по одной  } } } if err = scan.Err(); err != nil { errCh \u0026lt;- err } }() const workersCount uint8 = 4 // объявляем константу с количеством \u0026#34;воркеров\u0026#34;  var progress, done = make(chan struct{}), make(chan struct{}) // каналы для сообщений о ходе работы и её завершении  defer close(done) go func() { // запускаем горутину, что будет N раз ничего не делать, а по завершении запишет в канал done  for i := uint8(0); i \u0026lt; workersCount; i++ { \u0026lt;-progress } close(progress) done \u0026lt;- struct{}{} }() for i := uint8(0); i \u0026lt; workersCount; i++ { // запускаем горутины для выполнения HTTP запросов  go func() { defer func() { progress \u0026lt;- struct{}{} }() // когда она завершится, то запишет в канал progress  for { select { case \u0026lt;-ctx.Done(): // так же проверяем контекст на факт его отмены  return case url, isOpened := \u0026lt;-urlsCh: // и читаем из канала для ссылок  if !isOpened { // если он закрыт нашим \u0026#34;планировщиком\u0026#34;  return // то выходим  } if ok, fetchErr := fetchLink(ctx, http.MethodGet, url); fetchErr != nil { errCh \u0026lt;- fetchErr } else if ctx.Err() == nil { // дополнительно проверяем контекст  resultsCh \u0026lt;- result{url: url, ok: ok} // результаты пишем в канал для ответов  } } } }() } var ( okCounter uint // счётчик успешных запросов  lastError error // переменная для последней \u0026#34;пойманной\u0026#34; ошибки  ) loop: for { select { case workingErr, isOpened := \u0026lt;-errCh: // если пришла ошибка (при чтении файла или HTTP)  if isOpened \u0026amp;\u0026amp; !errors.Is(workingErr, context.Canceled) { // игнорируем ошибку \u0026#34;отмены контекста\u0026#34;  lastError = workingErr // то сохраняем её в lastError  cancel() // и отменяем контекст (чтоб горутины завершились) но не прерываем цикл  } case res := \u0026lt;-resultsCh: // если пришел результат от воркера  if res.ok { okCounter++ println(\u0026#34;OK\u0026#34;, res.url) } else { println(\u0026#34;Not OK\u0026#34;, res.url) } if okCounter \u0026gt;= 2 { // а вот как раз и наше условие для отмены  cancel() } case \u0026lt;-done: // и выход из цикла обязательно должен осуществится после сообщения в done  println(\u0026#34;work is done\u0026#34;) break loop // только тут прерываем цикл, так как горутины все вышли и никто не напишет в закрытые каналы  } } return lastError } // объявляем HTTP клиент для переиспользования var httpClient = http.Client{Timeout: time.Second * 5} func fetchLink(ctx context.Context, method, url string) (bool, error) { // создаём объект запроса  var req, err = http.NewRequestWithContext(ctx, method, url, http.NoBody) if err != nil { return false, err } // выполняем его  resp, err := httpClient.Do(req) if err != nil { return false, err } // валидируем статус код  if resp.StatusCode == http.StatusOK { return true, nil } return false, nil }   ","date":"2022-02-08T06:47:03Z","image":"https://blog.iddqd.uk/interview-section-golang-coding/cover_hu6c745680144d0a85df5a67b80461116c_57776_120x120_fill_box_smart1_3.png","permalink":"https://blog.iddqd.uk/interview-section-golang-coding/","title":"Задачи и решения для лайв-кодинга на Go"},{"content":"Структурирование информации - очень полезный навык. И дабы привнести некоторый порядок в этап подготовки к интервью на должность Golang разработчика (и немножко техлида) решил записывать в этой заметке в формате FAQ те вопросы, которые я задавал, задавали мне или просто были мной найдены на просторах сети вместе с ответами на них. Стоит относиться к ним как к шпаргалке (если затупишь на реальном интервью - будет где подсмотреть) и просто набору тем, которым тебе стоит уделить внимание.\n Расскажи о себе? Расскажи о своем самом интересном проекте? Кем был создан язык, какие его особенности?  Go - императивный или декларативный? А в чем разница?   Что такое ООП? Как это сделано в Golang?  Как устроено инвертирование зависимостей? Как сделать свои методы для стороннего пакета?   Типы данных и синтаксис  Как устроены строки в Go? В чём ключевое отличие слайса (среза) от массива?  Как вы отсортируете массив структур по алфавиту по полю Name?   Как работает append в слайсе?  Задача про слайсы #1 Задача про слайсы #2   Какое у слайса zero value? Какие операции над ним возможны? Что можешь рассказать про map?  Как растет map? Что там про поиск? Есть ли у map такие же методы как у слайса: len, cap? Какие типы ключей разрешены для ключа в map? Может ли ключом быть структура? Если может, то всегда ли? Что будет в map, если не делать make или short assign? Race condition. Потокобезопасна ли мапа?   Что такое интерфейс?  Как устроен Duck-typing в Go? Интерфейсный тип Пустой interface{} На какой стороне описывать интерфейс - на передающей или принимающей?   Что такое замыкание? Что такое сериализация? Зачем она нужна? Что такое type switch? Какие битовые операции знаешь? Дополнительный блок фигурных скобок в функции Что такое захват переменной? Как работает defer? Как работает init? Прерывание for/switch или for/select Сколько можно возвращать значений из функции? Дженерики - это про что?  Параметризованные функции Параметризованные типы     Память и управление ей  Что такое heap и stack? Где выделяется память под переменную? Можно ли этим управлять? Как работает Garbage Collection (GC) в Go? Какое поведение по умолчанию используется в Go при передаче в функцию? Что можешь рассказать про escape analysis?   Сoncurrency (конкурентность)  Как устроен мьютекс?  В чем отличие sync.Mutex от sync.RWMutex?   Что такое synс.Map? Какие ещё примитивы синхронизации знаешь?  sync.WaitGroup sync.Cond sync.Once sync.Pool   Какие типы каналов существуют?  Что можно делать с закрытым каналом?   Расскажи про планировщик (горутин) Что такое горутина?  В чем отличия горутин от потов ОС? Где аллоцируется память для горутин? Как завершить много горутин?   Кейсы использования контекста  context.WithCancel() context.WithDeadline() context.WithTimeout() context.WithValue()   Как задетектить гонку?   Тестирование  TDT, Table-driven tests (табличное тестирование) Имя пакета с тестами Статические анализаторы (линтеры) Ошибка в бенчмарке Что про функциональное тестирование?   Профилирование (pprof)  Пример использования pprof Так как же профилировщик работает в принципе?   Компилятор  Из каких этапов состоит компиляция? Статическая компиляция/линковка - что это, и в чем особенности? Какие директивы компилятора знаешь?  //go:linkname //go:nosplit //go:norace //go:noinline //go:noescape //go:build //go:generate //go:embed        Расскажи о себе? Чаще всего этот вопрос идёт первым и даёт возможность интервьюверу задать вопросы связанные с твоим резюме, познакомиться с тобой, попытаться понять твой характер для построения последующих вопросов. Следует иметь в виду, что интервьюверу не всегда удается подготовиться к интервью, или он банально не имеет перед глазами твоего резюме. Тут есть смысл ещё раз представиться (часто в мессенджерах используются никнеймы, а твоё реальное имя он мог забыть), назвать свой возраст, образование, рассказать о предыдущих местах работы и должностях, сколько лет в индустрии, какие ЯП и технологии использовал - только \u0026ldquo;по верхам\u0026rdquo;, для того чтоб твой собеседник просто понял с кем он \u0026ldquo;имеет дело\u0026rdquo;.\nРасскажи о своем самом интересном проекте? К этому вопросу есть смысл подготовиться заранее и не спустя рукава. Дело в том, что это тот момент, когда тебе надо подобно павлину распустить хвост и создать правильное первое впечатление о себе, так как этот вопрос тоже очень часто идёт впереди всех остальных. Возьми и выпиши для себя где-нибудь на листочке основные тезисы о том, что это был за проект/сервис/задача, уделяя основное внимание тому какой профит это принесло для компании/команды в целом. Например:\n Я со своей командой гоферов из N человек в течении трех месяцев создали аналог сервиса у которого компания покупала данные за $4000 в месяц, а после перехода на наш сервис - расходы сократились до $1500 в месяц и значительно повысилось их качество и uptime; Внедренные мной практики в CI/CD пайплайны позволили сократить время на ревью изменений в проектах на 25..40%, а зная сколько стоит время работы разработчиков - вы сами всё понимаете; Разработанный мной сервис состоял из такого-то набора микросервисов, такие-то службы и протоколы использовал, были такие-то ключевые проблемы которые мы так-то зарешали; основной ценностью было то-то.  Кем был создан язык, какие его особенности? Go (часто также golang) - компилируемый многопоточный язык программирования, разработанный внутри компании Google. Разработка началась в 2007 году, его непосредственным проектированием занимались Роберт Гризмер, Роб Пайк и Кен Томпсон. Официально язык был представлен в ноябре 2009 года.\nВ качестве ключевых особенностей можно выделить:\n Простая грамматика (минимум ключевых слов - язык создавался по принципу \u0026ldquo;что ещё можно выкинуть\u0026rdquo; вместо \u0026ldquo;что бы ещё в него добавить\u0026rdquo;) Строгая типизация и отказ от иерархии типов (но с сохранением объектно-ориентированных возможностей) Сборка мусора (GC) Простые и эффективные средства для распараллеливания вычислений Чёткое разделение интерфейса и реализации Наличие системы пакетов и возможность импортирования внешних зависимостей (пакетов) Богатый тулинг \u0026ldquo;из корочки\u0026rdquo; (бенчмарки, тесты, генерация кода и документации), быстрая компиляция  Для того, чтоб вспомнить историю создания Go и о его особенностях можно посмотреть:\n  Go - императивный или декларативный? А в чем разница? Go является императивным языком.\nИмперативное программирование - это описание того, как ты делаешь что-то (т.е. конкретно описываем необходимые действия для достижения определенного результата), а декларативное — того, что ты делаешь (например, декларативным ЯП является SQL - мы описываем что мы хотим получить от СУБД, но не описываем как именно она должна это сделать).\nЧто такое ООП? Как это сделано в Golang? ООП это методология (подход) программирования, основанная на том, что программа представляет собой некоторую совокупность объектов-классов, которые образую иерархию наследования. Ключевые фишки - минимализация повторяемости кода (принцип DRY) и удобство понимания/управления. Фундаментом ООП можно считать идею описания объектов в программировании подобно объектам из реального мира - у них есть свойства, поведение, они могут взаимодействовать. Мы (люди) так понимаем мир, и нам (людям) так проще описывать всякие штуки в коде. Основные принципы в ООП:\n  Абстракция вообще присуща для любого программирования, а не только для ООП. По большому счету (топорный, но понятный пример) это про выделение общего и объединение этого в какие-то сущности но без реализации, про контракты. Например - экземпляры абстрактных классов не могут быть созданы (new AbstractClass), но могут содержать абстрактные методы, чтоб разработчик решив наследоваться от этого абстрактного класса их реализовал так, как ему нужно для своих целей (например - ходить в SQL СУБД или файл). Другой пример - это интерфейсы, они же контракты чистой воды - содержат только сигнатуры методов и ни капельки реализации. Но абстракция не ограничивается ими и должна быть умеренной, так как усложняет архитектуру приложения в общем и целом. Опираться следует на интуицию и опыт. Слишком много слоев абстракции (ещё раз - тут дело не ограничивается интерфейсами и абстрактными классами) приводит к переусложнению и головной боли последующего сопровождения продукта. Недостаточная - к сложности внесения изменений и расширению функционала.\n  Инкапсуляция про контроль доступа к свойствам объекта и их динамическая валидация/преобразования. Если метод/свойство должно быть доступно \u0026ldquo;из вне\u0026rdquo; объекта - объявляем публичным, иначе - приватным. Если есть необходимость переопределять его из потомков класса - то защищенным (protected). Python, например, реализуют инкапсуляцию, но не предусматривает возможности сокрытия в принципе; в то время как С++ и Java она просто всюду.\n  Наследование это возможность (барабанная дробь!) наследоваться одним объектам от других, \u0026ldquo;перенимая\u0026rdquo; все методы родительских объектов. Своеобразный вариант Матрешки. Т.е. выделяя в родительских объектах \u0026ldquo;всё общее\u0026rdquo; мы можем не повторяться в реализации частных, а просто \u0026ldquo;наследоваться\u0026rdquo;.\n  Полиморфизм - \u0026ldquo;поли\u0026rdquo; - много, \u0026ldquo;морф\u0026rdquo; - вид. Везде, где есть интерфейсы - подразумевается полиморфизм. Суть - это контракты (интерфейсы), мы можем объявить \u0026ldquo;что-то умеет закрывать себя методом Close()\u0026rdquo;, и нам не важно что именно это будет. Реализаций может быть много, и если это что-то умеет делать то, что нам надо - нам удобнее с этим работать.\n  Тут же можно упомянуть про знание SOLID, а именно:\n  S (single responsibility principle, принцип единственной ответственности) - определенный класс/модуль должен решать только определенную задачу, максимально узко но максимально хорошо (своеобразные UNIX-way). Если для выполнения своей задачи ему требуются какие-то другие ресурсы - они в него должны быть инкапсулированы (это отсылка к принципу инверсии зависимостей).\n  O (open-closed principle, принцип открытости/закрытости) - классы/модули должны быть открыты для расширения, но закрыты для модификации. Должна быть возможность расширить поведение, наделить новым функционалом, но при этом исходный код/логика модуля должна быть неизменной.\n  L (Liskov substitution principle, принцип подстановки Лисков) - поведение наследующих классов не должно противоречить поведению, заданному базовым классом, то есть поведение наследующих классов должно быть ожидаемым для кода.\n  I (interface segregation principle, принцип разделения интерфейса) - много тонких интерфейсов лучше, чем один толстый.\n  D (dependency inversion principle, принцип инверсии зависимостей) - \u0026ldquo;завязываться\u0026rdquo; на абстракциях (интерфейсах), а не конкретных реализациях. Так же (это уже про IoC, но всё же) можно рассказать что если какому-то классу для своей работы требуется функциональность другого - то есть смысл \u0026ldquo;запрашивать\u0026rdquo; её в конструкторе нашего класса используя интерфейс, под который подходит наша зависимость. Таким образом целевая реализация опирается только на интерфейсы (не зависит от реализаций) и соответствует принципу под буквой S.\n  А теперь о том, как это реализовано в Go (наконец-то!).\nВ Go нет классов, объектов, исключений и шаблонов. Нет иерархии типов, но есть сами типы (т.е. возможность описывать свои типы/структуры). Структурные типы (с методами) служат тем же целям, что и классы в других языках. Так же следует упомянуть что структура определяет состояние.\nВ Go нет наследования. Совсем. Но есть встраивание (называемое \u0026ldquo;анонимным\u0026rdquo;, так как Foo в Bar встраивается не под каким-то именем, а без него) при этом встраиваются и свойства, и функции:\nimport \u0026#34;fmt\u0026#34; type Foo struct { name string Surname string } func (f Foo) SayName() string { return f.name } type Bar struct { Foo } func main() { bar := Bar{Foo{name: \u0026#34;one\u0026#34;, Surname: \u0026#34;baz\u0026#34;}} fmt.Println(bar.SayName()) // one \tfmt.Println(bar.Surname) // baz  bar.name = \u0026#34;two\u0026#34; fmt.Println(bar.SayName()) // two } Есть интерфейсы (это типы, которые объявляют наборы методов). Подобно интерфейсам в других языках, они не имеют реализации. Объекты, которые реализуют все методы интерфейса, автоматически реализуют интерфейс (так называемый Duck-typing). Не существует наследования или подклассов или ключевого слова Implements:\nimport \u0026#34;fmt\u0026#34; type Speaker interface { Speak() string } type Foo struct{} func (Foo) Speak() string { return \u0026#34;foo\u0026#34; } type Bar struct{} func (Bar) Speak() string { return \u0026#34;bar\u0026#34; } func main() { var foo, bar Speaker = new(Foo), \u0026amp;Bar{} fmt.Println(foo.Speak()) // foo \tfmt.Println(bar.Speak()) // bar } В примере выше мы объявили переменные foo и bar с явным указанием интерфейсного типа, а так интерфейс это \u0026ldquo;ссылочный\u0026rdquo; тип (на самом деле в Go нет ссылок, но есть указатели) - то и структуры мы инициализировали указателями на них с использованием new() (что аллоцирует структуру и возвращает указатель на неё) и (или) \u0026amp;.\nИнкапсуляция реализована на уровне пакетов. Имена, начинающиеся со строчной буквы, видны только внутри этого пакета (не являются экспортируемыми). И наоборот - всё, что начинается с заглавной буквы - доступно из-вне пакета. Дешево и сердито.\nПолиморфизм - это основа объектно-ориентированного программирования: способность обрабатывать объекты разных типов одинаково, если они придерживаются одного и того же интерфейса. Интерфейсы Go предоставляют эту возможность очень прямым и интуитивно понятным способом. Пример использования интерфайса был описан выше.\n Что можно почитать:\n ООП в картинках Golang и ООП   Как устроено инвертирование зависимостей? Инвертирование зависимостей позволяет в нашем коде не \u0026ldquo;завязываться\u0026rdquo; на конкретную реализацию (используя, например, интерфейсы), тем самым понижая связанность кода и повышая его тестируемость. Так же сужается зона ответственности конечной структуры/пакета, что повышает его переиспользуемость.\nПринцип инверсии зависимостей (dependency inversion principle) в Go который можно реализовывать следующим образом:\nimport ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; ) type speaker interface { Speak() string } type Foo struct { s speaker // s *Foo - было бы плохо } func NewFoo(s speaker) (*Foo, error) { if s == nil { return nil, errors.New(\u0026#34;speaker is nil\u0026#34;) } return \u0026amp;Foo{s: s}, nil } func (f Foo) SaySomething() string { return f.s.Speak() } func main() { var foo, err = NewFoo(someSpeaker) if err != nil { panic(err) } fmt.Println(foo.SaySomething()) // depends on the speaker implementation } Мы объявляем интерфейс speaker не экспортируемым на нашей, принимающей стороне, и используя псевдо-конструктор NewFoo гарантируем что свойство s будет проинициализировано верным типом (дополнительно проверяя его на nil).\nКак сделать свои методы для стороннего пакета? Например, если мы используем логгер Zap в нашем проекте, и хотим к этому Zap-у прикрутить наши методы - то для этого нам нужно будет создать свою структуру, внутри в неё встраивать логгер Zap-а, и к этой структуре уже прикручивать требуемые методы. Просто \u0026ldquo;навесить сверху\u0026rdquo; функции на сторонний пакет мы не можем.\nТипы данных и синтаксис К фундаментальным типам данных можно отнести:\n Целочисленные - int{8,16,32,64}, int, uint{8,16,32,64}, uint, byte как синоним uint8 и rune как синоним int32. Типы int и uint имеют наиболее эффективный размер для определенной платформы (32 или 64 бита), причем различные компиляторы могут предоставлять различный размер для этих типов даже для одной и той же платформы Числа с плавающей запятой - float32 (занимает 4 байта/32 бита) и float64 (занимает 8 байт/64 бита) Комплексные числа - complex64 (вещественная и мнимая части представляют числа float32) и complex128 (вещественная и мнимая части представляют числа float64) Логические aka bool Строки string  Как устроены строки в Go? В Go строка в действительности является слайсом (срезом) байт, доступным только для чтения. Строка содержит произвольные байты, и у неё нет ёмкости (cap). При преобразовании слайса байт в строку (str := string(slice)) или обратно (slice := []byte(str)) - происходит копирование массива (со всеми следствиями).\nСоздание подстрок работает очень эффективно. Поскольку строка предназначена только для чтения, исходная строка и строка, полученная в результате операции среза, могут безопасно совместно использовать один и тот же массив:\nvar ( str = \u0026#34;hello world\u0026#34; sub = str[0:5] usr = \u0026#34;/usr/kot\u0026#34;[5:] ) print(sub, \u0026#34; \u0026#34;, usr) // hello kot Go использует тип rune (алиас int32) для представления Unicode. Конструкция for ... range итерирует строку посимвольно (а не побайтово, как можно было бы предположить):\nvar str = \u0026#34;привет\u0026#34; println(str, len(str)) // привет 12  for i, c := range str { println(i, c, string(c)) } // 0 1087 п // 2 1088 р // 4 1080 и // 6 1074 в // 8 1077 е // 10 1090 т И мы видим, что для кодирования каждого символа кириллицы используются по 2 байта.\nЭффективным способом работы со строками (когда есть необходимость часто выполнять конкатенацию, например) является использование слайса байт или strings.Builder:\nimport \u0026#34;strings\u0026#34; func main() { // происходит только 1 аллокация при вызове `Grow()` \tvar str strings.Builder str.Grow(12) // сразу выделяем память  str.WriteString(\u0026#34;hello\u0026#34;) str.WriteRune(\u0026#39; \u0026#39;) str.WriteString(\u0026#34;мир\u0026#34;) println(str.String()) // hello мир } И ещё одну важную особенность стоит иметь в виду - это подсчет длины строки (например - для какой-нибудь валидации). Если считать по количеству байт, и строка содержит не только ASCII символы - то количество байт и фактическое количество символов будут расходиться:\nconst str = \u0026#34;hello мир!\u0026#34; println(len(str), utf8.RuneCountInString(str)) // 13 10 Тут дело в том, что для кодирования символов м, и и р используются 2 байта вместо одного. Поэтому len == 13, а фактически в строке лишь 10 символов (пакет utf8, к примеру, нам в помощь).\n Что можно почитать:\n Строка, байт, руна, символ в Golang   В чём ключевое отличие слайса (среза) от массива?  Срез - всегда указатель на массив, массив - значение Срез может менять свой размер и динамически аллоцировать память   В Go не бывает ссылок - но есть указатели. Где говорится про \u0026ldquo;по ссылке\u0026rdquo; имеется в виду \u0026ldquo;по указателю\u0026rdquo;\n Слайсы и массивы в Go это проиндексированные упорядоченные структуры данных последовательностей элементов. Ёмкость массива объявляется в момент его создания, и после изменить её уже нельзя (его длина это часть его типа). Память, необходимая для хранения элементов массива выделяется соответственно сразу при его объявлении, и по умолчанию инициализируется в соответствии с нулевыми значением для типа (fasle для bool, 0 для int, nil для интерфейсов и т.д.). На стеке можно разместить массив объемом 10 MB. В качестве размера можно использовать константы (компилятор должен знать это значение на этапе компиляции, т.е. что-то вида var a [getSize()]int или i := 3; var a [i]int недопустимо):\nconst mySize uint8 = 8 type myArray [mySize]byte var constSized = [...]int{1, 2, 3} // размер сам посчитается исходя из кол-ва эл-ов Кстати, массивы с элементами одного типа но с разными размерами являются разными типами. Массивы не нужно инициализировать явно; нулевой массив - это готовый к использованию массив, элементы которого являются нулями:\nvar a [4]int // [0 0 0 0]  a[0] = 1 // [1 0 0 0] i := a[0] // i == 1 Представление [4]int в памяти - это просто четыре целых значения, расположенных последовательно. Так же следует помнить что в Go массивы передаются по значению, т.е. передавая массив в какую-либо функцию она получает копию массива (для передачи его указателя нужно явно это указывать, т.е. foo(\u0026amp;a)).\nА слайс же это своего рода версия массива но с вариативным размером (структура данных, которая строится поверх массива и предоставляет доступ к элементами базового массива). Слайсы до 64 KB могут быть размещены на стеке. Если посмотреть исходники Go (src/runtime/slice.go), то увидим:\ntype slice struct { array unsafe.Pointer // указатель на массив \tlen int // длина (length) \tcap int // вместимость (capacity) } Для аллокации слайса можно воспользоваться одной из команд ниже:\nvar ( a = []int{} // [] len=0 cap=0 \tb = []int{1, 2} // [1 2] len=2 cap=2 \tc = []int{5: 1} // [0 0 0 0 0 123] len=6 cap=6 \td = make([]int, 5, 10) // [0 0 0 0 0] len=5 cap=10 ) В последнем случае рантайм Go создаст массив из 10 элементов (выделит память и заполнит их нулями) но доступны прямо сейчас нам будут только 5, и установит значения len в 5, а cap в 10. Cap означает ёмкость и помогает зарезервировать место в памяти на будущее, чтобы избежать лишних операций выделения памяти при росте слайса (это ключевой параметр для аллокации памяти, влияет на производительность вставки в срез). При добавлении новых элементов в слайс новый массив для него не будет создаваться до тех пор, пока cap меньше len.\nСлайсы передаются \u0026ldquo;по ссылке\u0026rdquo; (фактически будет передана копия структуры slice со своими len и cap, но указатель на массив array будет тот-же самый). Для защиты слайса от изменений следует передавать его копию:\nvar ( a = []int{1, 2, 0, 0, 1} b = make([]int, len(a)) ) copy(b, a) fmt.Println(a, b) // [1 2 0 0 1] [1 2 0 0 1] Важной особенностью является то, так как \u0026ldquo;под капотом\u0026rdquo; у слайса лежит указатель на массив - при изменении значений слайса они будут изменяться везде, где слайс используется (будь то присвоение в переменную, передача в функцию и т.д.) до момента, пока размер слайса не будет переполнен и не будет выделен новый массив для его значений (т.е. в момент изменения cap слайса всегда происходит копирование данных массива):\nvar ( one = []int{1, 2} // [1 2] \ttwo = one // [1 2] ) two[0] = 123 fmt.Println(one, two) // [123 2] [123 2]  one = append(one, 666) fmt.Println(one, two) // [123 2 666] [123 2]  Что можно почитать:\n Как не наступать на грабли в Go Слайсы в Go: использование и особенности Принцип работы типа slice в GO   Как вы отсортируете массив структур по алфавиту по полю Name? Например, преобразую массив в слайс и воспользуюсь функцией sort.SliceStable:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sort\u0026#34; ) func main() { var arr = [...]struct{ Name string }{{Name: \u0026#34;b\u0026#34;}, {Name: \u0026#34;c\u0026#34;}, {Name: \u0026#34;a\u0026#34;}} // ^^^^^^^^^^^^^^^^^^^^^ анонимная структура с нужным нам полем  fmt.Println(arr) // [{b} {c} {a}]  sort.SliceStable(arr[:], func(i, j int) bool { return arr[i].Name \u0026lt; arr[j].Name }) // ^^^ вот тут вся \u0026#34;магия\u0026#34; - из массива сделали слайс  fmt.Println(arr) // [{a} {b} {c}] } Вся магия в том, что при создании слайса из массива \u0026ldquo;под капотом\u0026rdquo; у слайса начинает лежать исходный массив, и функции из пакета sort нам становятся доступны над ними. Т.е. изменяя порядок элементов в слайсе функцией sort.SliceStable мы будем менять их в нашем исходном массиве.\nКак работает append в слайсе? append() делает простую операцию - добавляет элементы в слайс и возвращает новый. Но под капотом там делаются довольно сложные манипуляции, чтобы выделять память только при необходимости и делать это эффективно.\nСперва append сравнивает значения len и cap у слайса. Если len меньше чем cap, то значение len увеличивается, а само добавляемое значение помещается в конец слайса. В противном случае происходит выделение памяти под новый массив для элементов слайса, в него копируются значения из старого, и значение помещается уже в новый массив.\nУвеличении размера слайса (метод growslice) происходит по следующему алгоритму - если его размер менее 1024 элементов, то его размер будет увеличиваться вдвое; иначе же слайс увеличивается на ~12.5% от своего текущего размера.\nЧто важно помнить - если на основании слайса one выделить подслайс two, а затем увеличим слайс one (и его вместимость будет превышена) - то one и two будут уже ссылаться на разные участки памяти!\nvar ( one = make([]int, 4) // [0 0 0 0] \ttwo = one[1:3] // [0 0] ) one[2] = 11 fmt.Println(one, two) // [0 0 11 0] [0 11] fmt.Printf(\u0026#34;%p %p\\n\u0026#34;, one, two) // 0xc0000161c0 0xc0000161c8  one = append(one, 1) fmt.Printf(\u0026#34;%p %p\\n\u0026#34;, one, two) // 0xc00001c1c0 0xc0000161c8  one[2] = 22 fmt.Println(one, two) // [0 0 22 0 1] [0 11] fmt.Printf(\u0026#34;%p %p\\n\u0026#34;, one, two) // 0xc00001c1c0 0xc0000161c8 Есть еще много примеров добавления, копирования и других способов использования слайсов тут - Slice Tricks.\n Что можно почитать:\n Как не наступать на грабли в Go   Задача про слайсы #1 Вопрос: У нас есть 2 функции - одна делает append() чего-то в слайс, а другая просто сортирует слайс, используя пакет sort. Модифицируют ли слайс первая и (или) вторая функции?\nОтвет: append() не модифицирует а возвращает новый слайс, а sort модифицирует порядок элементов, если он изначально был не отсортирован.\nЗадача про слайсы #2 Вопрос: Что выведет следующая программа?\npackage main import \u0026#34;fmt\u0026#34; func main() { a := [5]int{1, 2, 3, 4, 5} t := a[3:4:4] fmt.Println(t[0]) } Ответ  Выведет 4   Объяснение: Такой синтаксис позволяет задать capacity (вместимость) для полученного под-слайса, который будет равен \u0026ldquo;последний элемент минус первый элемент из выражения в квадратных скобках\u0026rdquo;, т.е. из примера выше он будет равен 1 (т.к. от четырёх, т.е. третьего сегмента вычитаем первый, т.е. тройку). Если бы выражение имело вид a[3:4:5], то cap была бы равна 2 (5 - 3 = 2). Но при этом на сами данные он не влияет.\nПоявилась эта штука в Go 1.2.\n Что можно почитать:\n Slicing a slice with slice [a : b : c] Full slice expressions   Какое у слайса zero value? Какие операции над ним возможны? Zero value у слайса всегда nil, а len и cap равны нулю, так как \u0026ldquo;под ним\u0026rdquo; нет инициализированного массива:\nvar a []int println(a == nil, len(a), cap(a)) // true 0 0 a = append(a, 1) println(a == nil, len(a), cap(a)) // false 1 1 Как видно из примера выше - несмотря на то, что a == nil (слайс \u0026ldquo;не инициализирован\u0026rdquo;), с этим слайсом возможна операция append - в этом случае Go самостоятельно создаёт нижележащий массив и всё работает так, как и ожидается. Более того - для полной очистки слайса рекомендуется его присваивать к nil.\nТак же важно помнить, что не делая make для слайса - не получится сделать пре-аллокацию, что часто очень болезненно для производительности.\nЧто можешь рассказать про map? Карта (map или hashmap) - это неупорядоченная коллекция пар вида ключ-значение. Пример:\ntype myMap map[string]int Подобно массивам и слайсам, к элементам мапы можно обратиться с помощью скобок:\nvar m = make(map[string]int) // инициализация  m[\u0026#34;one\u0026#34;] = 1 // запись в мапу  fmt.Println(m[\u0026#34;one\u0026#34;], m[\u0026#34;two\u0026#34;]) // 1 0  Лучше выделить память заранее (передавая вторым аргументом функции make), если известно количество элементов - избежим эвакуаций\n В случае с m[\u0026quot;two\u0026quot;] вернулся 0 так как это является нулевым значением для типа int. Для проверки существования ключа используем конструкцию вида (доступ к элементу карты может вернуть два значения вместо одного) называемую \u0026ldquo;multiple assignment\u0026rdquo;:\nvar m = map[string]int{\u0026#34;one\u0026#34;: 1} v1, ok1 := m[\u0026#34;one\u0026#34;] // чтение v2, ok2 := m[\u0026#34;two\u0026#34;] fmt.Println(v1, ok1) // 1 true fmt.Println(v2, ok2) // 0 false  for k, v := range m { // итерация всех эл-ов мапы \tfmt.Println(k, v) } delete(m, \u0026#34;one\u0026#34;) // удаление  v1, ok1 = m[\u0026#34;one\u0026#34;] fmt.Println(v1, ok1) // 0 false Мапы всегда передаются по ссылке (вообще-то Go не бывает ссылок, невозможно создать 2 переменные с 1 адресом, как в С++ например; но зато можно создать 2 переменные, указывающие на один адрес - но это уже указатели). Если же быть точнее, то мапа в Go - это просто указатель на структуру hmap:\ntype hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/reflectdata/reflect.go. \t// Make sure this stays in sync with the compiler\u0026#39;s definition. \tcount int // # live cells == size of map. Must be first (used by len() builtin) \tflags uint8 B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) \tnoverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details \thash0 uint32 // hash seed  buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. \toldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing \tnevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated)  extra *mapextra // optional fields } Так же структура hmap содержит в себе следующее:\n Количество элементов Количество \u0026ldquo;ведер\u0026rdquo; (представлено в виде логарифма для ускорения вычислений) Seed для рандомизации хэшей (чтобы было сложнее заddosить - попытаться подобрать ключи так, что будут сплошные коллизии) Всякие служебные поля и главное указатель на buckets, где хранятся значения  На картинке схематичное изображение структуры в памяти - есть хэдер hmap, указатель на который и есть map в Go (именно он создается при объявлении с помощью var, но не инициализируется, из-за чего падает программа при попытке вставки). Поле buckets - хранилище пар ключ-значение, таких \u0026ldquo;ведер\u0026rdquo; несколько, в каждом лежит 8 пар. Сначала в \u0026ldquo;ведре\u0026rdquo; лежат слоты для дополнительных битов хэшей (e0..e7 названо e - потому что extra hash bits). Далее лежат ключи и значения как сначала список всех ключей, потом список всех значений.\nПо хэш функции определяется в какое \u0026ldquo;ведро\u0026rdquo; мы кладем значение, внутри каждого \u0026ldquo;ведра\u0026rdquo; может лежать до 8 коллизий, в конце каждого \u0026ldquo;ведра\u0026rdquo; есть указатель на дополнительное, если вдруг предыдущее переполнилось.\nКак растет map? В исходном коде можно найти строчку Maximum average load of a bucket that triggers growth is 6.5. То есть, если в каждом \u0026ldquo;ведре\u0026rdquo; в среднем более 6,5 элементов, происходит увеличение массива buckets. При этом выделяется массив в 2 раза больше, а старые данные копируются в него маленькими порциями каждые вставку или удаление, чтобы не создавать очень крупные задержки. Поэтому все операции будут чуть медленнее в процессе эвакуации данных (при поиске тоже, нам же приходится искать в двух местах). После успешной эвакуации начинают использоваться новые данные.\nИз-за эвакуации данных нельзя и взять адрес мапы - представьте, что мы взяли адрес значения, а потом мапа выросла, выделилась новая память, данные эвакуировались, старые удалились, указатель стал неправильным, поэтому такие операции запрещены.\nЧто там про поиск? Поиск, если разобраться, устроен не так уж и сложно: проходимся по цепочкам \u0026ldquo;ведер\u0026rdquo;, переходя в следующее, если в этом не нашли. Поиск в \u0026ldquo;ведре\u0026rdquo; начинается с быстрого сравнения дополнительного хэша, для которого используется всего 8 бит (вот для чего эти e0...e7 в начале каждого - это \u0026ldquo;мини\u0026rdquo; хэш пары для быстрого сравнения). Если не совпало, идем дальше, если совпало, то проверяем тщательнее - определяем где лежит в памяти ключ, подозреваемый как искомый, сравниваем равен ли он тому, что запросили. Если равен, определяем положение значения в памяти и возвращаем.\nК сожалению, мир не совершенен. Когда имя хешируется, то некоторые данные теряются, так как хеш, как правило, короче исходной строки. Таким образом, в любой реализации хеш таблицы неизбежны коллизии когда по двум ключам получаются одинаковые хеши. Как следствие, поиск может быть дороже чем O(1) (возможно это связано с кешем процессора и коллизиями коротких хэшей), так что иногда выгоднее использовать бинарный поиск по слайсу данных нежели чем поиск в мапе (пишите бенчмарки).\n Что можно почитать:\n Хэш таблицы в Go. Детали реализации Кажется, поиск в map дороже чем O(1)   Есть ли у map такие же методы как у слайса: len, cap? У мапы есть len но нет cap. У нас есть только overflow который указывает \u0026ldquo;куда-то\u0026rdquo; когда мапа переполняется, и поэтому у нас не может быть capacity.\nКакие типы ключей разрешены для ключа в map? Любым сравнимым (comparable) типом, т.е. булевы, числовые, строковые, указатели, канальные и интерфейсные типы, а также структуры или массивы, содержащие только эти типы. Слайсы, мапы и функции использовать нельзя, так как эти типы не сравнить с помощью оператора == или !=.\nМожет ли ключом быть структура? Если может, то всегда ли? Как было сказано выше - структура может быть ключом до тех пор, пока мы в поля структуры не поместим какой-либо слайс, мапу или любой другой non-comparable тип данных (например - функцию).\nЧто будет в map, если не делать make или short assign? Будет паника (например - при попытке что-нибудь в неё поместить), так как любые \u0026ldquo;структурные\u0026rdquo; типы (а мапа как мы знаем таковой является) должны быть инициализированы для работы с ними.\nRace condition. Потокобезопасна ли мапа? Нет, потокобезопасной является sync.Map. Для обеспечения безопасности вокруг мапы обычно строится структура вида:\ntype ProtectedIntMap struct { mx sync.RWMutex m map[string]int } func (m *ProtectedIntMap) Load(key string) (val int, ok bool) { m.mx.RLock() val, ok = m.m[key] m.mx.RUnlock() return } func (m *ProtectedIntMap) Store(key string, value int) { m.mx.Lock() m.m[key] = value m.mx.Unlock() } Что такое интерфейс? Интерфейсы - это инструменты для определения наборов действий и поведения. Интерфейсы - это в первую очередь контракты. Они позволяют объектам опираться на абстракции, а не фактические реализации других объектов. При этом для компоновки различных поведений можно группировать несколько интерфейсов. В общем смысле - это набор методов, представляющих стандартное поведение для различных типов данных.\nКак устроен Duck-typing в Go?  Если это выглядит как утка, плавает как утка и крякает как утка, то это, вероятно, утка и есть.\n Если структура содержит в себе все методы, что объявлены в интерфейсе, и их сигнатуры совпадают - она автоматически удовлетворяет интерфейс.\nТакой подход позволяет полиморфно (полиморфизм - способность функции обрабатывать данные разных типов) работать с объектами, которые не связаны в иерархии наследования. Достаточно, чтобы все эти объекты поддерживали необходимый набор методов.\nИнтерфейсный тип В Go интерфейсный тип выглядит вот так:\ntype iface struct { tab *itab data unsafe.Pointer } Где tab - это указатель на Interface Table или itable - структуру, которая хранит некоторые метаданные о типе и список методов, используемых для удовлетворения интерфейса, а data указывает на реальную область памяти, в которой лежат данные изначального объекта (статическим типом).\nКомпилятор генерирует метаданные для каждого статического типа, в которых, помимо прочего, хранится список методов, реализованных для данного типа. Аналогично генерируются метаданные со списком методов для каждого интерфейса. Теперь, во время исполнения программы, runtime Go может вычислить itable на лету (late binding) для каждой конкретной пары. Этот itable кешируется, поэтому просчёт происходит только один раз.\nЗная это, становится очевидно, почему Go ловит несоответствия типов на этапе компиляции, но кастинг к интерфейсу - во время исполнения.\nЧто важно помнить - переменная интерфейсного типа может принимать nil. Но так как объект интерфейса в Go содержит два поля: tab и data - по правилам Go, интерфейс может быть равен nil только если оба этих поля не определены (faq):\nvar ( builder *strings.Builder stringer fmt.Stringer ) fmt.Println(builder, stringer) // nil nil fmt.Println(stringer == nil) // true fmt.Println(builder == nil) // true  stringer = builder fmt.Println(builder, stringer) // nil nil fmt.Println(stringer == nil) // false (!!!) fmt.Println(builder == nil) // true Пустой interface{} Ему удовлетворяет вообще любой тип. Пустой интерфейс ничего не означает, никакой абстракции. Поэтому использовать пустые интерфейсы нужно в самых крайних случаях.\n Что можно почитать:\n Краш-курс по интерфейсам в Go Реализация интерфейсов в Golang Интерфейсы в Go - как красиво выстрелить себе в ногу   На какой стороне описывать интерфейс - на передающей или принимающей? Многое зависит от конкретного случая, но по умолчанию описывать интерфейсы следует на принимающей стороне - таким образом, ваш код будет меньше зависеть от какого-то другого кода/пакета/реализации.\nДругими словами, если нам в каком-то месте требуется \u0026ldquo;что-то что умеет себя закрывать\u0026rdquo;, или - умеет метод Close() error, или (другими словами) удовлетворят интерфейсу:\ntype something interface { Close() error } То он (интерфейс) должен быть описан на принимающей стороне. Так принимающая сторона не будет ничего знать о том, что именно в неё может \u0026ldquo;прилететь\u0026rdquo;, но точно знает поведение этого \u0026ldquo;чего-то\u0026rdquo;. Таким образом реализуется инверсия зависимости, и код становится проще переиспользовать/тестировать.\nЧто такое замыкание? Замыкания - это такие функции, которые вы можете создавать в рантайме и им будет доступно текущее окружение, в рамках которого они были созданы.\nФункции, у которых есть имя - это именованные функции. Функции, которые могут быть созданы без указания имени - это анонимные функции.\nfunc main() { var text = \u0026#34;some string\u0026#34; var ourFunc = func() { // именованное замыкание \tprintln(text) } ourFunc() // some string \tgetFunc()() // another string } func getFunc() func() { return func() { // анонимное \tprintln(\u0026#34;another string\u0026#34;) } } Замыкания сохраняют состояние. Это означает, что состояние переменных содержится в замыкании в момент декларации. Одна из самых очевидных ловушек - это создание замыканий в цикле:\nvar funcs = make([]func(), 0, 5) for i := 0; i \u0026lt; 5; i++ { funcs = append(funcs, func() { println(\u0026#34;counter =\u0026#34;, i) }) // исправляется так: \t//var value = i \t//funcs = append(funcs, func() { println(\u0026#34;counter =\u0026#34;, value) }) } for _, f := range funcs { f() } // counter = 5 (так все 5 раз)  Что можно почитать:\n Замыкания   Что такое сериализация? Зачем она нужна? Сериализация - это процесс преобразования объекта в поток байтов для сохранения или передачи. Обратной операцией является десериализация (т.е. восстановление объекта/структуры из последовательности байтов). Синонимом можно считать термин \u0026ldquo;маршалинг\u0026rdquo; (от англ. marshal - упорядочивать).\nИз минусов сериализации можно выделить нарушение инкапсуляции, т.е. после сериализации \u0026ldquo;приватные\u0026rdquo; свойства структур могут быть доступны для изменения.\nТипичными примерами сериализации в Go являются преобразование структур в json-объекты. Кроме json существуют различные кодеки типа MessagePack, CBOR и т.д.\nЧто такое type switch? Проверка типа переменной, а не её значения. Может быть в виде одного switch и множеством case:\npackage main func checkType(i interface{}) { switch i.(type) { case int: println(\u0026#34;is integer\u0026#34;) case string: println(\u0026#34;is string\u0026#34;) default: println(\u0026#34;has unknown type\u0026#34;) } } А может в виде if-конструкции:\npackage main func main() { var any interface{} any = \u0026#34;foobar\u0026#34; if s, ok := any.(string); ok { println(\u0026#34;this is a string:\u0026#34;, s) } // а так можно проверить наличие функций у структуры  if closable, ok := any.(interface{ Close() }); ok { closable.Close() } } Какие битовые операции знаешь? Побитовые операторы проводят операции непосредственно на битах числа.\n// Побитовое И/AND (разряд результата равен 1 только тогда, когда оба соответствующих бита операндов равны 1) println(0b111_000 /* 56 */ \u0026amp; 0b011_110 /* 30 */ == 0b011_000 /* 24 */) // Побитовое ИЛИ/OR (разряд результата равен 0 только тогда, когда оба соответствующих бита в равны 0) println(0b111_000 /* 56 */ | 0b011_110 /* 30 */ == 0b111_110 /* 62 */) // Исключающее ИЛИ/XOR (разряд результата равен 1 только тогда, когда только один бит равен 1) println(0b111_000 /* 56 */ ^ 0b011_110 /* 30 */ == 0b100_110 /* 38 */) // Сброс бита AND NOT println(0b111_001 /* 57 */ \u0026amp;^ 0b011_110 /* 30 */ == 0b100_001 /* 33 */) // Сдвиг бита влево println(0b000_001 /* 1 */ \u0026lt;\u0026lt; 3 == 0b001_000 /* 8 */) // Сдвиг бита вправо println(0b000_111 /* 7 */ \u0026gt;\u0026gt; 1 == 0b000_011 /* 3 */) Пример использования простой битовой маски:\ntype Bits uint8 const ( F0 Bits = 1 \u0026lt;\u0026lt; iota // 0b00_000_001 == 1 \tF1 // 0b00_000_010 == 2 \tF2 // 0b00_000_100 == 4 ) func Set(b, flag Bits) Bits { return b | flag } func Clear(b, flag Bits) Bits { return b \u0026amp;^ flag } func Toggle(b, flag Bits) Bits { return b ^ flag } func Has(b, flag Bits) bool { return b\u0026amp;flag != 0 } func main() { var b Bits b = Set(b, F0) b = Toggle(b, F2) for i, flag := range [...]Bits{F0, F1, F2} { println(i, Has(b, flag)) } // 0 true \t// 1 false \t// 2 true }  Что можно почитать:\n О битовых операциях Поразрядные операции   Дополнительный блок фигурных скобок в функции Его можно использовать, и он означает отдельный скоуп для всех переменных, объявленных в нём (возможен и \u0026ldquo;захват переменных\u0026rdquo; объявленных вне скоупа ранее, естественно). Иногда используется для декомпозиции какого-то отдельного куска функции, к примеру.\nvar i, s1 = 1, \u0026#34;foo\u0026#34; { var j, s2 = 2, \u0026#34;bar\u0026#34; println(i, s1) // 1 foo \tprintln(j, s2) // 2 bar  s1 = \u0026#34;baz\u0026#34; } println(i, s1) // 1 baz //println(j, s2) // ERROR: undefined: j and s2 Так же это может быть связано с AST (Abstract Syntax Tree) - когда оно строится и происходят SSA (Static Single Assignment) оптимизации, к сожалению SSA не работает на всю длину дерева. Как следствие, если у нас слишком длинная функция (примерно дохулион строк) и мы по каким-то причинам не можем её декомпозировать, но можем изолировать какие-то скоупы то, таким образом, мы помогаем SSA произвести оптимизации (если они возможно).\nЧто такое захват переменной? Во вложенном скоупе есть возможность обращаться к переменным, объявленных в скоупе выше (но не наоборот). Обращение к переменным из вышестоящего скоупа и есть их захват. Типичной ошибкой является использование значение итератора в цикле:\nvar out []*int for i := 0; i \u0026lt; 3; i++ { out = append(out, \u0026amp;i) } println(*out[0], *out[1], *out[2]) // 3 3 3 Испраляется путём создания локальной (для скоупа цикла) переменной с копией знаяения итератора:\nvar out []*int for i := 0; i \u0026lt; 3; i++ { i := i // Copy i into a new variable. \tout = append(out, \u0026amp;i) } println(*out[0], *out[1], *out[2]) // 0 1 2  Что можно почитать:\n Using reference to loop iterator variable   Как работает defer? Defer является функцией отложенного вызова. Выполняется всегда (даже в случае паники внутри функции вызываемой) после того, как функция завершила своё выполнение но до того, как управление вернётся вызывающей стороне (более того - внутри defer возможен захват переменных, и даже возвращаемого результата). Часто используется для освобождения ресурсов/снятия блокировок. Пример использования:\nfunc main() { println(\u0026#34;result =\u0026#34;, f()) // f started \t// defer \t// defer in defer \t// result = 25 } func f() (i int) { println(\u0026#34;f started\u0026#34;) defer func() { recover() defer func() { println(\u0026#34;defer in defer\u0026#34;); i += 5 }() println(\u0026#34;defer\u0026#34;) i = i * 2 }() i = 10 panic(\u0026#34;panic is here\u0026#34;) } Когда выполняется ключевое слово defer, оно помещает следующий за ним оператор в список, который будет вызван до возврата функции.\nКак работает init? В Go есть предопределенная функция init(). Она выделяет фрагмент кода, который должен выполняться перед всеми другими частями пакета. Этот код будет выполняться сразу после импорта пакета.\nТакже функция init() используется для автоматической регистрации одного пакета в другом (например, так работает подавляющее большинство \u0026ldquo;драйверов\u0026rdquo; для различных СУБД, например - go-sql-driver/mysql/driver.go).\nФункцию init() можно использовать неоднократно в рамках даже одного файла, выполняться они будут в этом случае в порядке, как их встречает компилятор.\nХотя использование init() и является довольно полезным, но часто оно затрудняет чтение/понимание кода, и (почти) всегда можно обойтись без неё, поэтому необходимость её использования - всегда очень большой вопрос.\nПрерывание for/switch или for/select Что произойдёт в следующем примере, если f() вернёт true?\nfor { switch f() { case true: break case false: // Do something  } } Очевидно, будет вызван break. Вот только прерван будет switch, а не цикл for. Простое решение проблемы – использовать именованный (labeled) цикл и вызывать break c этой меткой, как в примере ниже:\nloop: for { switch f() { case true: break loop case false: // Do something  } } Сколько можно возвращать значений из функции? Теоретически, неограниченное количество значений. Так же хочется отметить, что есть правила \u0026ldquo;де-факто\u0026rdquo;, которых следует придерживаться:\n Последним значением возвращать ошибку, если её возврат подразумевается Первым значением возвращать контекст, если он подразумевается Хорошим тоном является не возвращать более четырёх значений Если функция что-то проверяет и возвращает значение + булевый результат проверки - то результат проверки возвращать последним (пример - os.LookupEnv(key string) (string, bool)) Если возвращается ошибка, то остальные значения возвращать нулевыми или nil  Дженерики - это про что? Дженерики, или обобщения - это средства языка, позволяющего работать с различными типами данных без изменения их описания.\nВ версии 1.18 появились дженерики (вообще-то они были и ранее, но мы не могли их использовать в своём коде - вспомни функцию make(T type)), и они позволяют объявлять (описывать) универсальные методы, т.е. в качестве параметров и возвращаемых значений указывать не один тип, а их наборы.\nПоявились новые ключевые слова:\n any - аналог interface{}, можно использовать в любом месте (func do(v any) any, var v any, type foo interface { Do() any }) comparable - интерфейс, который определяет типы, которые могут быть сравнены с помощью == и != (переменные такого типа создать нельзя - var j comparable будет вызывать ошибку)  И появилась возможность определять интерфейсы, которые можно будет использовать в параметризованных функциях и типах (переменные такого типа создать нельзя - var j Int будет вызывать ошибку):\ntype Int interface { int | int32 | int64 } Если добавить знак ~ перед типами то интерфейсу будут соответствовать и производные типы, например myInt из примера ниже:\ntype Int interface { ~int | ~int32 | ~int64 } type myInt int Разработчики golang создали для нас уже готовый набор интерфейсов (пакет constraints), который очень удобно использовать.\nПараметризованные функции Рассмотрим пример функции, что возвращает максимум из двух переданных значений, причём тип может быть любым:\nimport \u0026#34;constraints\u0026#34; func Max[T constraints.Ordered](a T, b T) T { if a \u0026gt; b { return a } return b } Ограничения на используемые типы описываются в квадратных скобочках. В качестве ограничения для типов можно использовать любой интерфейс и особые интерфейсы описанные выше.\nДля слайсов и мап был создан набор готовых полезных функций.\nПараметризованные типы import \u0026#34;reflect\u0026#34; type myMap[K comparable, V any] map[K]V func main() { m := myMap[int, string]{5: \u0026#34;foo\u0026#34;} println(m[5]) // foo \tprintln(reflect.TypeOf(m)) // main.myMap[int,string] }  Что можно почитать:\n Зачем нужны дженерики в Go? Golang пощупаем дженерики   Память и управление ей Что такое heap и stack? Стек (stack) - это область оперативной памяти, которая создаётся для каждого потока. Он работает в порядке LIFO (Last In, First Out), то есть последний добавленный в стек кусок памяти будет первым в очереди на вывод из стека. Каждый раз, когда функция объявляет новую переменную, она добавляется в стек, а когда эта переменная пропадает из области видимости (например, когда функция заканчивается), она автоматически удаляется из стека. Когда стековая переменная освобождается, эта область памяти становится доступной для других стековых переменных.\nСтек быстрый, так как часто привязан к кэшу процессора. Размер стека ограничен, и задаётся при создании потока.\nКуча (heap) - это хранилище памяти, также расположенное в ОЗУ, которое допускает динамическое выделение памяти и не работает по принципу стека: это просто склад для ваших переменных. Когда вы выделяете в куче участок памяти для хранения переменной, к ней можно обратиться не только в потоке, но и во всем приложении. Именно так определяются глобальные переменные. По завершении приложения все выделенные участки памяти освобождаются. Размер кучи задаётся при запуске приложения, но, в отличие от стека, он ограничен лишь физически, и это позволяет создавать динамические переменные.\nВ сравнении со стеком, куча работает медленнее, поскольку переменные разбросаны по памяти, а не сидят на верхушке стека. То что попадает в кучу, живёт там пока не придёт GC.\nНо почему стек так быстр? Основных причин две:\n Стеку не нужно иметь сборщик мусора (garbage collector). Как мы уже упоминали, переменные просто создаются и затем вытесняются, когда функция завершается. Не нужно запускать сложный процесс освобождения памяти от неиспользуемых переменных и т.п. Стек принадлежит одной горутине, переменные не нужно синхронизировать в сравнении с теми, что находятся в куче. Что также повышает производительность  Где выделяется память под переменную? Можно ли этим управлять? Прямых инструментов для управления местом, где будет выделена память у нас, к сожалению - нет. Но есть некоторые практики, которые позволяют это понять и использовать эффективно.\nПамять под переменную может быть выделена в куче (heap) или стеке (stack). Очень приблизительно:\n Стек содержит последовательность переменных для заданной горутины (как только функция завершила работу, переменные вытесняются из стека) Куча содержит общие (shared) переменные (глобальные и т.п.)  Давайте рассмотрим простой пример, в котором вы возвращаем значение:\nfunc getFooValue() foo { var result foo // Do something \treturn result } Здесь переменная result создаётся в текущей горутине. И эта переменная помещается в стек. Как только функция завершает работу, клиент получает копию этой переменной. Исходная переменная вытесняется из стека. Эта переменная всё ещё существует в памяти, до тех пор, пока не будет затёрта другой переменной, но к этой переменной уже нельзя получить доступ.\nТеперь тот же пример, но с указателем:\nfunc getFooPointer() *foo { var result foo // Do something \treturn \u0026amp;result } Переменная result также создаётся текущей горутиной, но клиент получает указатель (копию адреса переменной). Если result вытеснена из стека, клиент функции не сможет получить доступ к переменной.\nВ подобном сценарии компилятор Go вынужден переместить переменную result туда, где она может быть доступна (shared) – в кучу (heap).\nХотя есть и исключение. Для примера:\nfunc main() { p := \u0026amp;foo{} f(p) } Поскольку мы вызываем функцию f() в той же горутине, что и функцию main(), переменную p не нужно перемещать. Она просто находится в стеке и вложенная функция f() будет иметь к ней доступ.\nВ качестве заключения, когда мы создаём функцию - поведением по умолчанию должно быть использование передачи по значению, а не по указателю. Указатель должен быть использован только когда мы действительно хотим переиспользовать данные.\nКак работает Garbage Collection (GC) в Go? Garbage Collection - это процесс освобождения места в памяти, которая больше не используется. Стек освобождается быстро и просто (условно-самостоятельно), а вот с кучей имеются некоторые сложности.\nВ основе работы GC в Go лежит:\n \u0026ldquo;Трехцветный алгоритм пометки и очистки\u0026rdquo; (выполняется параллельно с основной программой) - все данные в куче представляются в виде связанного графа, каждая вершина которого (каждый объект, данные) может быть помечена как \u0026ldquo;белая\u0026rdquo;, \u0026ldquo;серая\u0026rdquo;, или \u0026ldquo;чёрная\u0026rdquo;; данный граф обходится в несколько проходов, все вершины размечаются своими цветами, и \u0026ldquo;белые\u0026rdquo; (мусорные) объекты могут быть удалены (\u0026ldquo;чёрные\u0026rdquo; - точно нельзя удалять; \u0026ldquo;серые\u0026rdquo; - под вопросом, пока не трогать) Write Barrier, следящий за тем, чтоб черные объекты не указывали на белые; и \u0026ldquo;останавливать мир\u0026rdquo; (Stop The World, STW) для включения или отключения Write Barrier  GC можно вызвать ручками - runtime.GC(), но пользоваться этим нужно с осторожностью (есть риск блокировки вызывающей стороны или всего приложения целиком).\nПо умолчанию, GC запускается самостоятельно когда размер кучи становится в 2 раза больше (за это отвечает Pacer; данный коэффициент можно регулировать при сборке с помощью env GOGC).\nПолный цикл работы GC:\n Sweep termination - фаза завершения очистки:  Stop the World Ожидаем пока все горутины достигнут safe-point Завершаем очистку ресурсов   Mark phase - фаза разметки (выполняется конкурентно с основной программой, выделяется на неё ~25% CPU):  Включаем Write Barrier Start the World Запускаем сканирование глобальных переменных и стеков При сканировании работа горутины приостанавливается (но не происходит полная остановка всей программы) Выполняем 3-х цветный алгоритм поиска мусора   Mark termination - фаза завершения разметки  Stop the World (не является обязательной, но с ней проце было реализовать) Дожидаемся завершения обработки последних задач из очереди Очистка кэшей Завершаем разметку   Sweep phase - фаза очистки  Отключаем Write Barrier Start The World Очистка ресурсов происходит в фоне    👎 Недостатки:\n Не реализован алгоритм поколений (GC Generations) Не реализовано уплотнение Stop the World (STW), вызываемый аж дважды Нет возможности тонкой настройки  Для оптимизации можно:\n Уменьшить частоту вызова GC с помощью GOGC Использовать балласт (выделять большое количество памяти при запуске приложения make([]byte, 10 \u0026lt;\u0026lt; 30) // 10 GiB), который увеличивает базовый размер кучи, не будет выделен как мусор, помечается за O(1), и выделяется в виртуальном пространстве не используя физическую память Использовать sync.Pool (он хорошо дружит с GC)    Какое поведение по умолчанию используется в Go при передаче в функцию? По умолчанию всегда используется копирование, т.е. передача по значению. Для передачи по указателю необходимо это явно указывать:\nfunc main() { var i = 5 byValue(i) // 5 \tbyPointer(\u0026amp;i) // 5 } func byValue(i int) { println(i) } // передача по значению (копии переменной) func byPointer(i *int) { println(*i) } // передача по указателю Что можешь рассказать про escape analysis? Escape analysis - это процесс, который компилятор использует для определения размещения значений, созданных вашей программой.\nВ частности, компилятор выполняет статический анализ кода, чтобы определить, может ли значение быть помещено в стековый фрейм для функции, которая его строит, или значение должно \u0026ldquo;сбежать\u0026rdquo; в кучу. Используется разработчиками для оптимизации кода и аналитики причин возможного замедления.\nКоманда для запуска escape-анализа: go build -gcflags=\u0026quot;-m\u0026quot; (так же можно использовать флаги -N для отключени оптимизаций, -l для отключения \u0026ldquo;инлайнинга\u0026rdquo;).\n Что можно почитать:\n Языковая механика escape analysis Escape Analysis in Golang   Сoncurrency (конкурентность) В данном разделе будут вопросы, относящиеся к параллелизму и конкурентной работе.\nКак устроен мьютекс? Mutex означает MUTual EXclusion (взаимное исключение), и обеспечивает безопасный доступ к общим ресурсам.\nПод капотом мьютекса используются функции из пакета atomic (atomic.CompareAndSwapInt32 и atomic.AddInt32), так что можно считать мьютекс надстройкой над atomic. Мьютекс медленнее чем atomic, потому что он блокирует другие горутины на всё время действия блокировки. А в свою очередь atomic быстрее потому как использует атомарные инструкции процессора.\nВ момент, когда нужно обеспечить защиту доступа - вызываем метод Lock(), а по завершению операции изменения/чтения данных - метод Unlock().\nВ чем отличие sync.Mutex от sync.RWMutex? Помимо Lock() и Unlock() (у sync.Mutex), у sync.RWMutex есть отдельные аналогичные методы только для чтения - RLock() и RUnlock(). Если участок в памяти нуждается только в чтении - он использует RLock(), который не заблокирует другие операции чтения, но заблокирует операцию записи и наоборот.\nПо большому счёту, RWMutex это комбинация из двух мьютексов.\nЧто такое synс.Map? Коротко - предоставляет атомарный доступ к элементам map.\nGo, как известно, является языком созданным для написания concurrent программ - программ, который эффективно работают на мультипроцессорных системах. Но тип map не безопасен для параллельного доступа. То есть для чтения, конечно, безопасен - 1000 горутин могут читать из map без опасений, но вот параллельно в неё ещё и писать - уже нет.\nДля обеспечения потоко-безопасного доступа к map можно использовать sync.RWMutex, но он имеет проблему производительности при работе на большом количестве ядер процессора (в RWMutex при блокировке на чтение каждая горутина должна обновить поле readerCount - простой счётчик, с помощью atomic.AddInt32(), что проиводит к сбросу кэша для этого адреса памяти для всех ядер, и каждое ядро становится в очередь и ждёт этот сброс и вычитывание из кэша - эта проблема называется cache contention).\nsync.Map решает совершенно конкретную проблему cache contention в стандартной библиотеке для таких случаев, когда ключи в map стабильны (не обновляются часто) и происходит намного больше чтений, чем записей.\nПример работы с sync.Map:\nvar m sync.Map m.Store(\u0026#34;one\u0026#34;, 1) // запись one, ok := m.Load(\u0026#34;one\u0026#34;) // чтение  fmt.Println(one, ok) // 1 true  m.Range(func(k, v interface{}) bool { // итерация эл-ов мапы \tfmt.Println(k, v) // one 1  return true }) m.Delete(\u0026#34;one\u0026#34;) // удаление  Что можно почитать:\n Разбираемся с новым sync.Map в Go 1.9   Какие ещё примитивы синхронизации знаешь? Как было сказано выше - для синхронизации можно использовать мьютексы. Кроме того из стандартной библиотеки нам доступны:\nsync.WaitGroup Используется для координации в случае, когда программе приходится ждать окончания работы нескольких горутин (эта конструкция похожа на CountDownLatch в Java). Отличный способ дождаться завершения набора одновременных операций. Принцип работы следующий:\nvar wg sync.WaitGroup wg.Add(1) // увеличиваем счётчик на 1 go func() { fmt.Println(\u0026#34;task 1\u0026#34;) \u0026lt;-time.After(time.Second) fmt.Println(\u0026#34;task 1 done\u0026#34;) wg.Done() // уменьшаем счётчик на 1 }() wg.Add(1) // увеличиваем счётчик на 1 go func() { fmt.Println(\u0026#34;task 2\u0026#34;) \u0026lt;-time.After(time.Second) fmt.Println(\u0026#34;task 2 done\u0026#34;) wg.Done() // уменьшаем счётчик на 1 }() wg.Wait() // блокируемся, пока счётчик не будет == 0 // task 2 // task 1 // task 2 done // task 1 done // Total time: 1.00s sync.Cond Условная переменная (CONDition variable) полезна, например, если мы хотим разблокировать сразу несколько горутин (Broadcast), что не получится сделать с помощью канала. Метод Signal отправляет сообщение самой долго-ожидающей горутине. Пример использования:\nvar ( c = sync.NewCond(\u0026amp;sync.Mutex{}) wg sync.WaitGroup // нужна только для примера  free = true ) wg.Add(1) go func() { defer wg.Done() c.L.Lock() for !free { // проверяем, что ресурс свободен \tc.Wait() } fmt.Println(\u0026#34;work\u0026#34;) c.L.Unlock() }() free = false // забрали ресурс, чтобы выполнить с ним работу \u0026lt;-time.After(1 * time.Second) // эмуляция работы free = true // освободили ресурс c.Signal() // оповестили горутину  wg.Wait() sync.Once Позволяет определить задачу для однократного выполнения за всё время работы программы. Содержит одну-единственную функцию Do, позволяющую передавать другую функцию для однократного применения.\nvar once sync.Once for i := 0; i \u0026lt; 10; i++ { once.Do(func() { fmt.Println(\u0026#34;Hell yeah!\u0026#34;) }) } // Hell yeah! (выводится 1 раз вместо 10) sync.Pool Используется для уменьшения давления на GC путём повторного использования выделенной памяти (потоко-безопасно). Пул необязательно освободит данные при первом пробуждении GC, но он может освободить их в любой момент. У пула нет возможности определить и установить размер и нет необходимости заботиться о его переполнении.\n Что можно почитать:\n Go sync.Pool   Какие типы каналов существуют? Если которотко, то синхронные (небуферизированным) и асинхронные (буферизированные), оба работают по принципу FIFO (first in, first out) очереди.\nКанал - это объект связи, с помощью которого (чаще всего) горутины обмениваются данными. Потокобезопасен, передаётся \u0026ldquo;по указателю\u0026rdquo;. Технически это можно представить как конвейер (или трубу), откуда можно считывать и помещать данные. Для создания канала предоставляет ключевое слово chan - создание не буферизированного канала c := make(chan int), для чтения из канала - data := \u0026lt;-c, для записи - c \u0026lt;- 123, и закрытие close(c).\nЗапись данных в закрытый канал вызовет панику.\nЧтение или запись данных в небуферизированный канал блокирует горутину и контроль передается свободной горутине. Через закрытый канал невозможно будет передать или принять данные (проверить открытость канала можно используя val, isOpened := \u0026lt;- channel, где isOpened == true в том случае, если канал открыт; в противном случае вернётся false и нулевое значение val исходя из типа данных для канала; isOpened == false если канал закрыт и отсутствуют данные для чтения из него).\nБуферизированный канал создается указанием второго аргумента для make - c := make(chan int, 5), в этом случае горутина не блокируется до тех пор, пока буфер не будет заполнен. Подобно слайсам, буферизированный канал имеет длину (len, количество сообщений в очереди, не считанных) и емкость (cap, размер самого буфера канала):\nc := make(chan string, 5) c \u0026lt;- \u0026#34;foo\u0026#34; c \u0026lt;- \u0026#34;bar\u0026#34; close(c) println(len(c), cap(c)) // 2 5  for { val, ok := \u0026lt;-c // обрати внимание - читаем из уже закрытого канала  if !ok { break } println(val) } // \u0026#34;foo\u0026#34; // \u0026#34;bar\u0026#34; Используя буферизованный канал и цикл for val := range c { ... } мы можем читать с закрытых каналов (поскольку у закрытых каналов данные все еще живут в буфере).\nКроме того, сужествует синтаксический сахар однонаправленных каналов (улучшает безопасность типов в программe, что, как следствие, порождает меньше ошибок):\n c := make(\u0026lt;-chan int) - только для чтения c := make(chan\u0026lt;- int) - только для записи  Так же можно в сигнатуре принимаемой функции указать однонаправленность канала (func write(c chan\u0026lt;- string) { ... }) - в этом случае функция не сможет из него читать, а сможет только писать или закрыть его.\nЧитать \u0026ldquo;одновременно\u0026rdquo; из нескольких каналов возможно с помощью select (оператор select является блокируемым, за исключением использования default):\nc1, c2 := make(chan string), make(chan string) defer func() { close(c1); close(c2) }() // не забываем прибраться  go func(c chan\u0026lt;- string) { \u0026lt;-time.After(time.Second); c \u0026lt;- \u0026#34;foo\u0026#34; }(c1) go func(c chan\u0026lt;- string) { \u0026lt;-time.After(time.Second); c \u0026lt;- \u0026#34;bar\u0026#34; }(c2) for i := 1; ; i++ { select { // блокируемся, пока в один из каналов не попадёт сообщение \tcase val := \u0026lt;-c1: println(\u0026#34;channel 1\u0026#34;, val) case val := \u0026lt;-c2: println(\u0026#34;channel 2\u0026#34;, val) } if i \u0026gt;= 2 { // через 2 итерации выходим (иначе будет deadlock) \tbreak } } // channel 1 foo // channel 2 bar // Total execution time: 1.00s В случае, если в оба канала одновременно придут сообщения (или они уже там были), то case будет выбран случайно (а не по порядку их объявления, как могло бы показаться).\nЕсли ни один из каналов недоступен для взаимодействия, и секция default отсутствует, то текущая горутина переходит в состояние waiting до тех пор, пока какой-то из каналов не станет доступен.\nЕсли в select указан default, то он будет выбран в том случае, если все каналы не имеют сообщений (таким образом select становится не блокируемым).\nПод капотом (src/runtime/chan.go) канал представлен структурой:\ntype hchan struct { qcount uint // количество элементов в буфере \tdataqsiz uint // размерность буфера \tbuf unsafe.Pointer // указатель на буфер для элементов канала \telemsize uint16 // размер одного элемента в канале \tclosed uint32 // флаг, указывающий, закрыт канал или нет \telemtype *_type // содержит указатель на тип данных в канале \tsendx uint // индекс (смещение) в буфере по которому должна производиться запись \trecvx uint // индекс (смещение) в буфере по которому должно производиться чтение \trecvq waitq // указатель на связанный список горутин, ожидающих чтения из канала \tsendq waitq // указатель на связанный список горутин, ожидающих запись в канал \tlock mutex // мьютекс для безопасного доступа к каналу } В общем случае, горутина захватывает мьютекс, когда совершает какое-либо действие с каналом, кроме случаев lock-free проверок при неблокирующих вызовах.\nGo не выделяет буфер для синхронных (небуферизированных) каналов, поэтому указатель на буфер равен nil и dataqsiz равен нулю. При чтении из канала горутина произведёт некоторые проверки, такие как: закрыт ли канал, буферизирован он или нет, содержит ли гоуртины в send-очереди. Если ожидающих отправки горутин нет - горутина добавит сама себя в recvq и заблокируется. При записи другой горутиной все проверки повторяются снова, и когда она проверяет recvq очередь, она находит ожидающую чтение горутину, удаляет её из очереди, записывает данные в её стек и снимает блокировку. Это единственное место во всём рантайме Go, когда одна горутина пишет напрямую в стек другой горутины.\nПри создании асинхронного (буферизированного) канала make(chan bool, 1) Go выделяет буфер и устанавливает значение dataqsiz в единицу. Чтобы горутине отправить отправить значение в канал, сперва производятся несколько проверок: пуста ли очередь recvq, пуст ли буфер, достаточно ли места в буфере. Если всё ок, то она просто записывает элемент в буфер, увеличивает значение qcount и продолжает исполнение далее. Когда буфер полон, буферизированный канал будет вести себя точно так же, как синхронный (небуферизированный), тоесть горутина добавит себя в очередь ожидания и заблокируется.\nПроверки буфера и очереди реализованы как атомарные операции, и не требуют блокировки мьютекса.\nПри закрытии канала Go проходит по всем ожидающим на чтение или запись горутинам и разблокирует их. Все получатели получают дефолтные значение переменных того типа данных канала, а все отправители паникуют.\n Что можно почитать:\n Анатомия каналов в Go Как устроены каналы в Go Под капотом Golang - как работают каналы. Часть 1 Строение каналов в Golang. Часть 2   Что можно делать с закрытым каналом? Из закрытого канала можно читать с помощью for val := range c { ... } - вычитает все сообщения что в нём есть, или с помощью:\nfor { if val, ok := \u0026lt;-c; ok { println(val) } else { break } } Расскажи про планировщик (горутин) Goroutine scheduler является перехватывающим задачи (work-stealing) планировщиком, который был введен еще в Go 1.1 Дмитрием Вьюковым вместе с командой Go. Основная его суть заключается в том, что он управляет:\n G (горутинами) - просто горутины Go M (машинами aka потоками или тредами) - потоки ОС, которые могут выполнять что-либо или же бездействовать P (процессорами) - можно рассматривать как ЦП (физическое ядро); представляет ресурсы, необходимые для выполнения нашего Go кода, такие как планировщик или состояние распределителя памяти  Основная задача планировщика состоит в том, чтобы сопоставить каждую G (код, который мы хотим выполнить) с M (где его выполнять) и P (права и ресурсы для выполнения).\nКогда M (поток ОС) прекращает выполнение нашего кода, он возвращает свой P (ЦП) в пул свободных P. Чтобы возобновить выполнение Go кода, он должен повторно заполучить его. Точно так же, когда горутина завершается, объект G (горутина) возвращается в пул свободных G и позже может быть повторно использован для какой-либо другой горутины.\nGo запускает столько тредов, сколько доступно процессорных ядер (если вы специально это не перенастраиваете) и распределяет на эти треды сколько угодно горутин которые уже запускает программист. В один момент на одном ядре ЦП может находиться в исполнении только одна грутина, а в очереди исполнения их может быть неограниченное количество.\nТреды M во время выполнения могут переходить от одного процессора P к другому. Например, когда тред делает системный вызов, в ответ на который ОС блокирует этот тред (например - чтение какого-то большого файла с диска) - мало того что заблокируется сама горутина, что спровоцировала этот вызов, но и все остальные, что стоят в очереди для этого процессора P. Чтоб этого не происходило - Go отвязывает горутины стоящие в очереди от этого процессора P и переназначает на другие.\nОсновные типы многозадачности что используются в большинстве ОС это \u0026ldquo;вытесняющая\u0026rdquo; (все ресурсы делятся между всеми программами одинаково, всем выделяется одинаковое время выполнения) и \u0026ldquo;кооперативная\u0026rdquo; (программы выполняются столько, сколько им нужно, и сами уступают друг-другу место). В Go используется неявная кооперативность:\n Горутина уступает место другис при обращении к вводу-выводу, каналам, вызовам ОС и т.д. Может уступить место при вызове любой функции (с некоторой вероятностью произойдет переключение между горутинами) Есть явный способ переключить планировщик на другую горутину - вызвать функцию runtime.Gosched() (почти никогда не нужна, но она есть)  Основные принципы планировщика:\n Очередь FIFO (first in - first out) - порядок запуска горутин обуславливается порядом их вызова Необходимый минимум тредов - создается не больше тредов чем доступных ядер ЦП Захват чужой работы - когда тред простаивает, то он не удаляется рантаймом Go, а будет по возможности \u0026ldquo;нагружен\u0026rdquo; работой, взятой из очередей горутин на исполнение с других тредов \u0026ldquo;Неинвазивность\u0026rdquo; - работа горутин насильно не прерывается  Ограничения:\n Очередь FIFO (нет приоритезации и изменения порядка исполнения) Отсутствие гарантий времени выполнения (времени запуска горутин) Горутины могут перемещаться между тредами, что снижает эффективность кэшей     Что можно почитать:\n Горутины: всё, что вы хотели знать, но боялись спросить Что такое горутины и каков их размер?   Что такое горутина? Горутина (goroutine) - это функция, выполняющаяся конкурентно с другими горутинами в том же адресном пространстве.\nДля её запуска достаточно использовать ключевое слово go перед именем вызываемой (или анонимной) функции.\nГорутины очень легковесны (~2,6Kb на горутину). Практически все расходы - это создание стека, который очень невелик, хотя при необходимости может расти. Область их применения чаще всего следующая:\n Когда нужна асинхронность (например когда мы работаем с сетью, диском, базой данных, защищенным мьютексом ресурсом и т.п.) Когда время выполнения функции достаточно велико и можно получить выигрыш, нагрузив другие ядра  Сама структура горутины занимает порядка 600 байт, но для неё ещё выделяется и её собственный стек, минимальный размер котого составляет 2Kb, который увеличивается и уменьшается по мере необходимости (максимум зависит от архитектуры и составляет 1 ГБ для 64-разрядных систем и 250 МБ для 32-разрядных систем).\nПереключение между двумя Горутинами - супер дешевое, O(1), то есть, не зависит от количества созданных горутин в системе. Всё, что нужно сделать для переключения, это поменять 3 регистра - Program counter, Stack Pointer и DX.\nВ чем отличия горутин от потов ОС?  Каждый поток операционной системы имеет блок памяти фиксированного размера (зачастую до 2 Мбайт) для стека - рабочей области, в которой он хранит локальные переменные вызовов функций, находящиеся в работе или приостановленные на время вызова другой функции. В противоположность этому go-подпрограмма начинает работу с небольшим стеком, обычно около 2 Кбайт. Стек горутины, подобно стеку потока операционной системы, хранит локальные переменные активных и приостановленных функций, но, в отличие от потоков операционной системы, не является фиксированным; при необходимости он может расти и уменьшаться Потоки операционной системы планируются в ее ядре, а у go есть собственный планировщик (m:n) мультиплексирующий (раскидывающий) горутинки (m) по потокам (n). Основной плюс - отсутствие оверхеда на переключение контекста Планировщик Go использует параметр с именем GOMAXPROCS для определения, сколько потоков операционной системы могут одновременно активно выполнять код Go. Его значение по умолчанию равно количеству процессоров (ядер) компьютера, так что на машине с 8 процессорами (ядрами) планировщик будет планировать код Go для выполнения на 8 потоках одновременно. Спящие или заблокированные в процессе коммуникации go-подпрограммы потоков для себя не требуют. Go-подпрограммы, заблокированные в операции ввода-вывода или в других системных вызовах, или при вызове функций, не являющихся функциями Go, нуждаются в потоке операционной системы, но GOMAXPROCS их не учитывает В большинстве операционных систем и языков программирования, поддерживающих многопоточность, текущий поток имеет идентификацию, которая может быть легко получена как обычное значение (обычно - целое число или указатель). У горутин нет идентификации, доступной программисту. Так решено во время проектирования языка, поскольку локальной памятью потока программисты злоупотребляют  Где аллоцируется память для горутин? Так как горутины являются stackful - то и память для них (их состояние) хранится на стеке. Поэтому, теоритически, если очень постараться и сделать милилард вложенных вызовов, то можно сделать себе переполнение стека.\nДля самих же переменных, что используются внутри горутин память берётся с хипа (ограничены только размером \u0026ldquo;физического\u0026rdquo; хипа, т.е. объемом памяти сколько есть на машине).\n Что можно почитать:\n Достучаться до небес - Корутины, Горутины и прочие Рутины Go: как изменяется размер стека горутины?   Как завершить много горутин? Один из вариантов - это пристрелить main (шутка). Работу одной гороутины в принципе нельзя принудительно остановить из другой. Механизмы их завершения необходимо реализовывать отдельно (учить сами горутины завершаться).\nНаиболее часто используются 2 подхода - это использование контекста context.Context:\nimport ( \u0026#34;context\u0026#34; \u0026#34;time\u0026#34; ) func f(ctx context.Context) { loop: for { select { case \u0026lt;-ctx.Done(): println(\u0026#34;break f\u0026#34;) break loop default: println(\u0026#34;do some work\u0026#34;) \u0026lt;-time.After(time.Millisecond * 100) } } } func main() { ctx, cancel := context.WithCancel(context.Background()) for i := 0; i \u0026lt; 3; i++ { go f(ctx) // запускаем 3 горутины \t} \u0026lt;-time.After(time.Millisecond * 50) cancel() // отменяем контекст, на что горутины должны среагировать выходом \t\u0026lt;-time.After(time.Millisecond * 60) // do some work \t// do some work \t// do some work \t// break f \t// break f \t// break f } И отдельного канала для уведомлений о необходимости завершения (часто для уведомлений используется пустая структура struct{}, которая ничего не весит):\nimport ( \u0026#34;time\u0026#34; ) func f(c \u0026lt;-chan struct{}) { loop: for { select { case \u0026lt;-c: println(\u0026#34;break f\u0026#34;) break loop default: println(\u0026#34;do some work\u0026#34;) \u0026lt;-time.After(time.Millisecond * 100) } } } func main() { const workersCount = 3 var c = make(chan struct{}, workersCount) for i := 0; i \u0026lt; workersCount; i++ { go f(c) // запускаем 3 горутины \t} \u0026lt;-time.After(time.Millisecond * 50) for i := 0; i \u0026lt; workersCount; i++ { c \u0026lt;- struct{}{} // отправляем 3 сообщения в канал (по одному для каждой горутины) о выходе \t} // ВООБЩЕ - цикл с отправкой сообщений НЕ является обязательным, и можно просто закрыть канал \tclose(c) \u0026lt;-time.After(time.Millisecond * 60) // do some work \t// do some work \t// do some work \t// break f \t// break f \t// break f } Кейсы использования контекста Пакет context в Go особенно полезен при взаимодействиях с API и медленными процессами, особенно в production-grade системах. С его помощью можно уведомить горутины о необходимости завершить свою работу, \u0026ldquo;пошарить\u0026rdquo; какие-то данные (например, в middleware), или легко организовать работу с таймаутом.\ncontext.WithCancel() Эта функция создает новый контекст из переданного ей родительского, возвращая первым аргуметом функцию \u0026ldquo;отмены контекста\u0026rdquo; (при её вызове родительский контект \u0026ldquo;отменен\u0026rdquo; не будет), а вторым - новый контекст. Важно - вызывать функцию отмены контекста должна только та функция, которая его создает. При вызове функции отмены сам контекст и все котнекты, созданные на основе него получат в ctx.Done() пустую структуру и в ctx.Err() ошибку context.Canceled.\nctx, cancel := context.WithCancel(context.Background()) fmt.Println(ctx.Err()) // nil  cancel() fmt.Println(\u0026lt;-ctx.Done()) // {} fmt.Println(ctx.Err().Error()) // context canceled context.WithDeadline() Так же создает контекст от родительского, который отменится самостоятельно при наступлении переданного ему временной отметке, или при вызове функции отмены. Отмена/таймаут затрагивает только сам контекст и его \u0026ldquo;наследников\u0026rdquo;. ctx.Err() возвращает ошибку context.DeadlineExceeded. Полезно для реализации таймаутов:\nctx, cancel := context.WithDeadline( context.Background(), time.Now().Add(time.Millisecond*100), ) defer cancel() fmt.Println(ctx.Err()) // nil  \u0026lt;-time.After(time.Microsecond * 110) fmt.Println(\u0026lt;-ctx.Done()) // {} fmt.Println(ctx.Err().Error()) // context deadline exceeded context.WithTimeout() Работает аналогично context.WithDeadline() за исключением того, что принимает в качестве значения таймаута длительность (например - time.Second):\nctx, cancel := context.WithTimeout(context.Background(), time.Second*2) context.WithValue() Позволяет \u0026ldquo;пошарить\u0026rdquo; данные через всё контекстное деверо \u0026ldquo;ниже\u0026rdquo;. Часто используют чтоб передать таким образом, например, логгер или HTTP запрос в цепочке middleware (но в 9 из 10 случаев так делать не надо, это можно считать антипаттерном). Лучше всего использовать функции для помещения/извлечения данных из контекста (так как \u0026ldquo;в нём\u0026rdquo; они храняться как interface{}):\nimport ( \u0026#34;context\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) const loggerCtxKey = \u0026#34;logger\u0026#34; // should be unique  func PutLogger(ctx context.Context, logger *log.Logger) context.Context { return context.WithValue(ctx, loggerCtxKey, logger) } func GetLogger(ctx context.Context) *log.Logger { return ctx.Value(loggerCtxKey).(*log.Logger) } func f(ctx context.Context) { logger := GetLogger(ctx) logger.Print(\u0026#34;inside f\u0026#34;) println(logger) } func main() { var ( logger = log.New(os.Stdout, \u0026#34;\u0026#34;, 0) ctxWithLogger = PutLogger(context.Background(), logger) ) logger.Printf(\u0026#34;main\u0026#34;) println(logger) f(ctxWithLogger) // main \t// 0xc0000101e0 \t// inside f \t// 0xc0000101e0 }    Что можно почитать:\n Разбираемся с пакетом Context в Golang   При этом ok == true до того момента, пока в канале есть сообщения (вне зависимости от того, открыт он или закрыт), в противном случае ok == false а val будет нулевым значением в зависимости от типа данных канала. При попытке записи в закрытый канал будет паника (авторы языка так сделали \u0026ldquo;ибо нефиг - канал закрыт значит закрыт\u0026rdquo;).\nКак задетектить гонку? Пишем тесты, и запускаем их с флагом -race (в этом случае рантайм будет в случайном порядке переключаться между горутинами (если не ошибаюсь), и компилятор генерирует дополнительный код, который \u0026ldquo;журналирует\u0026rdquo; обращения к памяти). Этот флаг можно использовать как для go test, так и для go run или go build.\nДетектор гонки основан на библиотеке времени выполнения (runtime library) C/C++ ThreadSanitizer.\nТак же предпочитаю писать тесты, провоцирующие гонку. Код в этом случае будет работать значительно медленнее, но для этапа тестирования это и не так важно. А именно для тестируемоой структуры запускаю (например) 100 горутин которые читают и пишут что-то в случайном порядке.\nВажно и ещё одно высказывание - \u0026ldquo;Если race detector обнаруживает состояние гонки, то оно у вас наверняка есть; если же не обнаруживает - то это не означает что его нет\u0026rdquo;.\nТестирование Для unit-тестирования (aka модульного) используется команда вида go test, которая запускает все функции, что начинаются с префикса Test в файлах, что имеют в своем имени постфикс _test.go - всё довольно просто.\nВажно писать сам код так, чтоб его можно было протестировать (например - не забывать про инвертирование зависимостей и использовать интерфейсы там, где они уместны).\nTDT, Table-driven tests (табличное тестирование) Являются более предпочтительным вариантом для тестирования множества однотипных кейсов перед описанием \u0026ldquo;один кейс - один тест\u0026rdquo;, так как позволяют отделить часть входных данных и ожидаемых данных от всех этапов инициализации и tear-down (не знаю как это будет по-русски). Например, тестируемая функция и её тест могут выглядеть так:\npackage main func Sum(a, b int) int { return a + b } package main import \u0026#34;testing\u0026#34; func TestSum(t *testing.T) { for name, tt := range map[string]struct { // ключ мапы - имя теста \tgiveOne, giveSecond int wantResult int }{ \u0026#34;1 + 1 = 2\u0026#34;: { giveOne: 1, giveSecond: 1, wantResult: 2, }, \u0026#34;140 + 6 = 146\u0026#34;: { giveOne: 140, giveSecond: 6, wantResult: 146, }, } { t.Run(name, func(t *testing.T) { // setup here  if res := Sum(tt.giveOne, tt.giveSecond); res != tt.wantResult { t.Errorf(\u0026#34;Unexpected result. Want %d, got %d\u0026#34;, tt.wantResult, res) } // teardown here \t}) } } Имя пакета с тестами Если имя пакета в файле с тестами (foo_test.go) указывать с постфиксом _test (например - имя пакета, для которого пишутся тесты foo, а имя пакета указанное в самом файле с тестами для него - foo_test), то в тестах не будет доступа в не-экспортируемым свойствам, структурам и функциям, таким образом тестирование пакета будет происходить \u0026ldquo;как из-вне\u0026rdquo;, и не будет соблазна пытаться использовать что-то приватное, что в пакете содержится. По идее, в одной директории не может находиться 2 и более файлов, имена пакетов в которых отличаются, но *_test является исключением из этого правила.\nБолее того, этот подход стимулирует тестировать API, а не внутренние механизмы, т.е. относиться к функциональности как к \u0026ldquo;черному ящику\u0026rdquo;, что очень правильно.\nСтатические анализаторы (линтеры) Уже давно на все случаи жизни существует golangci-lint, который является универсальным решением, объединяющим множество линтеров в \u0026ldquo;одном флаконе\u0026rdquo;. Удобен как для запуска локально, так и на CI.\nОшибка в бенчмарке Про бенчмарки - иногда встречается кейс с написанием бенчмарка который внутри своего цикла выполняет тестируемую функцию, а результат этого действия никуда не присваивается и не передаётся:\nfunc BenchmarkWrong(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { ourFunc() } } Компилятор может принять это во внимание, и будет выполнять её содержимое как inline-последовательность инструкций. После чего, компилятор определит, что вызовы тестируемой функции не имеет никаких побочных эффектов (side-effects), т.е. никак не влияет на среду исполнения. После чего вызов тестируемой функции будет просто удалён. Один из вариантов избежать сценария выше – присваивать результат выполнения функции переменной уровня пакета. Примерно так:\nvar result uint64 func BenchmarkCorrect(b *testing.B) { var r uint64 for i := 0; i \u0026lt; b.N; i++ { r = ourFunc() } result = r } Теперь компилятор не будет знать, есть ли у функции side-effect и бенчмарк будет точен.\nЧто про функциональное тестирование? Тут всё зависит от того, что мы собираемся тестировать, и тянет на отдельную тему для разговора. Для HTTP посоветовать можно postman и его CLI-версию newman. Ещё как вариант \u0026ldquo;быстро и просто\u0026rdquo; - это hurl.\nДля за-mock-ивания стороннего HTTP API - jmartin82/mmock или lamoda/gonkey.\nПрофилирование (pprof) Для профилирования \u0026ldquo;родными\u0026rdquo; средствами в поставке с Go имеется пакет pprof и одноименная консольная утилита go tool pprof. Причинами необходимости в профилировании могут стать:\n Длительная работа различных частей программы Высокое потребление памяти Высокое потребление ресурсов процессора  Профилировщик является семплирующим - с какой-то периодичностью мы прерываем работу программы, берем стек-трейс, записываем его куда-то, а в конце, на основе того, как часто в стек-трейсах встречаются разные функции, мы понимаем, какие из них использовали больше ресурсов процессора, а какие меньше. Работа с ним состоит из двух этапов - сбор статистики по работе сервиса, и её визуализация + анализ. Собирать статистику можно добавив вызовы пакета pprof, либо запустив HTTP сервер.\nПример использования pprof Рассмотрим простой случай, когда у нас есть функция, которая выполняется по какой-то причине очень долго. Обрамим вызовы потенциально-тяжелого кода в startPprof и stopPprof:\nСпойлер (нажми чтоб раскрыть)  package main import ( \u0026#34;os\u0026#34; \u0026#34;runtime/pprof\u0026#34; \u0026#34;time\u0026#34; ) func startPprof() *os.File { // вспомогательная функция начала профилирования \tf, err := os.Create(\u0026#34;profile.pprof\u0026#34;) if err != nil { panic(err) } if err = pprof.StartCPUProfile(f); err != nil { panic(err) } return f } func stopPprof(f *os.File) { // вспомогательная функция завершения профилирования \tpprof.StopCPUProfile() if err := f.Close(); err != nil { panic(err) } } func main() { // наша основания функция \tvar ( slice = make([]int, 0) m = make(map[int]int) ) pprofFile := startPprof() // начинаем профилирование  // тут начинается какая-то \u0026#34;тяжелая\u0026#34; работа \tfor i := 0; i \u0026lt; 10_000_000; i++ { slice = append(slice, i*i) } for i := 0; i \u0026lt; 10_000_000; i++ { m[i] = i * i } \u0026lt;-time.After(time.Second) // а тут она завершается  stopPprof(pprofFile) // завершаем профилирование } После компиляции и запуска приложения (go build -o ./main . \u0026amp;\u0026amp; ./main) в текущей директории появится файл с именем profile.pprof, содержащий профиль работы. \u0026ldquo;Конвертируем\u0026rdquo; его в читаемое представление в виде svg изображения с помощью go tool pprof -svg ./profile.pprof (на Linux для этого понадобится установленный пакет graphviz) и открываем его (имя файла будет в виде profile001.svg):\nПосмотрим на получившийся граф вызовов. Изучая такой граф, в первую очередь нужно обращать внимание на толщину ребер (стрелочек) и на размер узлов графа (квадратиков). На ребрах подписано время - сколько времени данный узел или любой из ниже лежащих узлов находился в стек-трейсе во время профилирования.\nВ нашем профиле можем заметить, что runtime evacuate_fast64 занимает очень много времени. Связано это с тем, что из мапы данным приходиться эвакуироваться, так как размер мапы очень сильно растёт. Исправляем это (а заодно и слайс) всего в двух строчках:\nvar ( slice = make([]int, 0, 10_000_000) // заставляем аллоцировать память в слайсе  m = make(map[int]int, 10_000_000) // и в мапе заранее ) Повторяем все сделанные ранее операции снова, и видим уже совсем другую картину:\nТеперь картина значительно лучше, и следующее место оптимизации (потенциально) это пересмотреть работу с данными, а именно - нужна ли нам работа с мапой в принципе (может заменить её каким-то слайсом), и если нет - то как можно улучшить (оптимизировать) запись в неё.\n  Так как же профилировщик работает в принципе? Go runtime просит ОС посылать сигнал (man setitimer) с определенной периодичностью и назначает на этот сигнал обработчик. Обработчик берет стек-трейс всех горутин, какую-то дополнительную информацию, записывает ее в буфер и выходит.\nКаковы же недостатки данного подхода?\n Каждый сигнал - это изменение контекста, вещь довольно затратная в наше время. В Go сейчас получается получить порядка 100 в секунду. Иногда этого мало Для нестандартных сборок, например, с использованием -buildmode=c-archive или -buildmode=c-shared, профайлер работать по умолчанию не будет. Это связано с тем, что сигнал SIGPROF (который посылает ОС) придет в основной поток программы, который не контролируется Go Процесс user space, которым является программа на Go, не может получить ядерный стек-трейс. Неоптимальности и проблемы иногда кроются и в ядре  Основное преимущество, конечно, в том, что Go runtime обладает полной информацией о своем внутреннем устройстве. Внешние средства, например, по умолчанию ничего не знают о горутинах. Для них существуют только процессы и треды.\n   Что можно почитать:\n Профилирование и оптимизация программ на Go   Компилятор Компиляция - это процесс преобразования вашего (говно)кода в кашу из машинного кода. Первое понятно тебе, второе - машине.\nИз каких этапов состоит компиляция? cmd/compile содержит основные пакеты Go компилятора. Процесс компиляции может быть логически разделен на четыре фазы:\n Parsing (cmd/compile/internal/syntax) - сорец парсится, разбивается на токены, создается синтаксическое дерево Type-checking and AST (Abstract Syntax Tree) transformations (cmd/compile/internal/gc) - дерево переводится в AST, тут же происходит магия по авто-типизации, проверок интерфейсов этапа компиляции, определяется мертвый код и происходит escape-анализ Generic SSA (Static Single Assignment) (cmd/compile/internal/gc, cmd/compile/internal/ssa) - AST переводится в SSA (промежуточное представление более низкого уровня), что упрощает реализацию оптимизаций; так же применяются множественные оптимизации этого уровня (тут, например, циклы range переписываются в обычные for; а copy заменяется перемещением памяти), удаляются ненужные проверки на nil и т.д. Generating machine code (cmd/compile/internal/ssa, cmd/internal/obj) - универсальные штуки перезаписываются на машинно-зависимые (в зависимости от архитектуры и ОС), после чего над SSA снова выполняются оптимизации, удаляется мертвый код, распределяются регистры, размечается стековый фрейм; после - ассемблер превращает всё это добро в машинный код и записывает объектный файл   Что можно почитать:\n Введение в компилятор Go   Статическая компиляция/линковка - что это, и в чем особенности? Линковка (ну или компоновка) последний этап сборки. Статически слинкованный исполняемый файл не зависит от наличия других библиотек в системе во время своей работы.\nДля включения статической компиляции/линковки (при этом все внешние библиотеки, от которых зависит исполнение кода будут встроены в итоговый бинарный файл) необходимо использовать переменную окружения при сборке CGO_ENABLED=0 (т.е. CGO_ENABLED=0 go build ...). Полученный бинарный файл можно безбоязненно использовать, например, в docker-образе, основанном на scratch (т.е. не содержащем абсолютно никаких файлов, кристально чистая файловая система).\nОднако, это накладывает некоторые ограничения и привносит особенности, которые необходимо помнить:\n C-код будет недоступен, совсем (часть модулей из stdlib Go от него зависят, к слову, но не критичных) Не будет использоваться системный DNS-резольвер Не будет работать проверка x.509 сертификатов, которая должна работать на MacOS X  И ещё, если итоговый бинарный файл планируется использовать в docker scratch, то так же следует иметь в виду:\n Для осуществления HTTP запросов по протоколу HTTPS вашим приложением, в образ нужно будет поместить корневые SSL/TLS сертификаты /etc/ssl/certs Файл временной зоны (/etc/timezone) тоже будет необходим, чтоб корректно работать с датой/временем   Что можно почитать:\n Docker scratch \u0026amp; CGO_ENABLED=0 Кросс-компиляция в Go Go dns   Какие директивы компилятора знаешь? Компилятор Go понимает некоторые директивы (пишутся они в виде комментариев, как правило //go:directive), которые влияют на процесс компиляции (оптимизации, проверок, и т.д.) но не являются частью языка. Вот некоторые из них:\n//go:linkname Указывает компилятору реальное местонахождение функции или переменной. Можно использовать для вызова приватных функций из других пакетов. Требует импортирования пакета unsafe (import _ \u0026quot;unsafe\u0026quot;). Формат следующий:\n//go:linkname localname [importpath.name] Пример использования:\nimport ( _ \u0026#34;strings\u0026#34; // for explodeString \t_ \u0026#34;unsafe\u0026#34; // for go:linkname ) //go:linkname foo main.bar func foo() string func bar() string { return \u0026#34;bar\u0026#34; } //go:linkname explodeString strings.explode func explodeString(s string, n int) []string func main() { println(foo()) // bar \tprintln(explodeString(\u0026#34;foo\u0026#34;, -1)) // [3/3]0xc0000a00f0 } //go:nosplit Указывается при объявлении функции, и указывает на то, что вызов функции должен пропускать все обычные проверки на переполнение стека.\n//go:norace Так же указывается при объявлении функции и \u0026ldquo;выключает\u0026rdquo; детектор гонки (race detector) для неё.\n//go:noinline Отключает оптимизацию \u0026ldquo;инлайнига\u0026rdquo; для функции. Обычно используется отладки компилятора, escape-аналитики или бенчаркинга.\n//go:noescape Тоже \u0026ldquo;функциональная\u0026rdquo; директива, смысл которой сводится к тому, что \u0026ldquo;я доверяю этой функции, и ни один указатель, переданных в качестве аргументов (или возвращенных) этой функции не должен быть помещен в кучу (heap)\u0026rdquo;.\n//go:build Эта директива обеспечивает условную сборку. То есть мы можем \u0026ldquo;размечать\u0026rdquo; тегами файлы, и таким образом компилировать только определенные их \u0026ldquo;наборы\u0026rdquo; (тегов может быть несколько, а так же можно использовать ! для указания \u0026ldquo;не\u0026rdquo;). Часто используется для кодогенерации, указывая какой-то специфичный тег (например ignore - //go:build ignore) чтоб файл никогда не учавствовал с борке итогового приложения.\nВ качестве примера создадим 2 файла в одной директории:\n// file: main.go //go:build one  package main func main() { println(\u0026#34;one!\u0026#34;) } // file: main2.go //go:build two  package main func main() { println(\u0026#34;two!\u0026#34;) } И соберем с разными значениями -tags для go build или go run (обрати внимение - какой именно файл собирать не указывается, только тег):\n$ go run -tags one . one! $ go run -tags two . two! //go:generate Позволяет указать какие внешние команды должны вызваться при запуске go generate. Таким образом, мы можем использовать кодогенерацию, к примеру, или выполнять какие-то операции что дожны предшевствовать сборке (например - //go:generate go run gen.go где gen.go это файл, что содержит //go:build ignore т.е. исключён из компиляции, но при этом генерирует для нас какие-то полезные данные и/или целые .go файлы):\npackage main //go:generate echo \u0026#34;my build process\u0026#34; func main() { println(\u0026#34;hello world\u0026#34;) } $ go generate my build process //go:embed Позволяет \u0026ldquo;встраивать\u0026rdquo; внешние файлы в Go приложение. Требует импортирования пакета embed (import _ \u0026quot;embed\u0026quot;). Поддерживает типы string, []byte и embed.FS. Пример использования:\npackage main import _ \u0026#34;embed\u0026#34; //go:embed test.txt var hello string func main() { println(hello) } $ echo \u0026#34;hello world\u0026#34; \u0026gt; test.txt $ go run . hello world  Что можно почитать:\n pkg.go.dev/cmd/compile Go Compiler Directives Генерация кода в Go pkg.go.dev/embed  ","date":"2022-02-02T06:17:19Z","image":"https://blog.iddqd.uk/interview-section-golang/cover_hu032bd5f7e68e559a642ecef405e28712_26494_120x120_fill_box_smart1_3.png","permalink":"https://blog.iddqd.uk/interview-section-golang/","title":"Вопросы и ответы для собеседования Go-разработчика"},{"content":"Хочу рассказать про мужика-медоеда. Этот отморозок вызывает во мне искреннее восхищение.\nЖил-был Адриан Картон ди Виарт. Родился он в 1880 году в Бельгии, в аристократической семье. Чуть ли не с самого рождения он проявил хуевый характер: был вспыльчивым до бешенства, несдержанным, и все споры предпочитал разрешать, уебав противника без предупреждения.\nКогда Адриану исполнилось 17 лет, аристократический папа спихнул его в Оксфорд, и вздохнул с облегчением. Но в университете блистательный отпрыск не успевал по всем предметам. Кроме спорта. Там он был первым. Ну и еще бухать умел.\n— Хуйня какая-то эти ваши науки, — решил Адриан. — Вам не сделать из меня офисного хомячка.\nКогда ему стукнуло 19, на его радость началась англо-бурская война. Ди Виарт понятия не имел, кто с кем воюет, и ему было похуй. Он нашел ближайший рекрутерский пункт — это оказался пункт британской армии. Отправился туда, прибавил себе 6 лет, назвался другим именем, и умотал в Африку.\n— Ишь ты, как заебись! — обрадовался он, оказавшись впервые в настоящем бою. — Пули свищут, народ мрет — красота ж!\nНо тут Адриан был ранен в пах и живот, и его отправили на лечение в Англию. Аристократический папа, счастливый, что сынок наконец нашелся, заявил:\n— Ну все, повыёбывался, и хватит. Возвращайся в Оксфорд. — Да хуй-то там! — захохотал ди Виарт. — Я ж только начал развлекаться!\nПапа убедить его не смог, и похлопотал, чтобы отморозка взяли хотя бы в офицерский корпус. Чтоб фамилию не позорил. Адриан в составе корпуса отправился в Индию, где радостно охотился на кабанов. А в 1904 году снова попал на Бурскую войну, адъютантом командующего.\nТут уж он развернулся с неебической силой. Рвался во всякий бой, хуячил противника так, что аж свои боялись, и говорили:\n— Держитесь подальше от этого распиздяя, он когда в азарте, кого угодно уебет, и не вспомнит.\nХотели ему вручить медаль, но тут выяснилось, что он 7 лет уж воюет за Англию, а сам гражданин Бельгии.\n— Как же так получилось? — спросили Адриана. — Да не похуй ли, за кого воевать? — рассудительно ответил тот.\nНо все же ему дали британское подданство и звание капитана.\nВ 1908 году ди Виарт вдруг лихо выебнулся, женившись на аристократке, у которой родословная была круче, чем у любого породистого спаниеля. Звали ее Фредерика Мария Каролина Генриетта Роза Сабина Франциска Фуггер фон Бабенхаузен.\n— Ну, теперь-то уж он остепенится, — радовался аристократический папа. У пары родились две дочери, но Адриан заскучал, и собрался на войну.\n— Куда ты, Андрюша? — плакала жена, утирая слезы родословной. — Я старый, блядь, солдат, и не знаю слов любви, — сурово отвечал ди Виарт. — Быть женатым мне не понравилось. Все твои имена пока в койке выговоришь, хуй падает. А на самом деле ты какой-то просто Бабенхаузен. Я разочарован. Ухожу.\nИ отвалил на Первую Мировую. Начал он в Сомали, помощником командующего Верблюжьим Корпусом. Во время осады крепости дервишей, ему пулей выбило глаз и оторвало часть уха.\n— Врете, суки, не убьете, — орал ди Виарт, и продолжал штурмовать укрепления, хуяча на верблюде. Под его командованием вражеская крепость была взята. Только тогда ди Виарт соизволил обратиться в госпиталь.\nЕго наградили орденом, и вернули в Британию. Подлечившись, ди Виарт попросился на западный фронт.\n— Вы ж калека, у вас глаза нет, — сказали комиссии. — Все остальное, блядь, есть, — оскалился Адриан. — Отправляйте.\nОн для красоты вставил себе стеклянный глаз. И его отправили. Сразу после комиссии ди Виарт выкинул глаз, натянул черную повязку, и сказал:\n— Буду как Нельсон. Ну или как Кутузов. Похуй, пляшем. — Ну все, пиздец, — сказали немцы, узнав об этом. — Можно сразу сдаваться.\nИ были правы. Ди Виарт херачил их только так. Командовал он пехотной бригадой. Когда убивали командиров других подразделений, принимал командование на себя. И никогда не отступал.\nПод Соммой его ранили в голову и в плечо, под Пашендалем в бедро.\nПодлечившись, он отправлялся снова воевать. В бою на Ипре ему рего не отъебаться, и он будет служить еще лет сто или двести. Его произвели в генерал-лейтенанты, и отправили в Китай, личным представителем Черчилля.\nВ Китае случилась гражданская война, и ди Виарт очень хотел в ней поучаствовать, чтоб кого-нибудь замочить. Но Англия ему запретила. Тогда ди Виарт познакомился с Мао Дзе Дуном, и говорит:\n— А давайте Японию отпиздим? Чо они такие суки? — Нет, лучше давайте вступайте в Китайскую армию, такие люди нам нужны. — Ну на хуй, у вас тут скучно, — заявил ди Виарт. — Вы какие-то слишком мирные.\nИ в 1947 году наконец вышел в отставку. Супруга с труднопроизносимым именем померла. А в 1951 году ди Виарт женился на бабе, которая была на 23 года младше.\n— Вы ж старик уже, да еще и отполовиненный, как же вы с молодой женой справитесь? — охуевали знакомые. — А чего с ней справляться? — браво отвечал ди Виарт. — Хуй мне не оторвало.\n«Честно говоря, я наслаждался войной, — писал он в своих мемуарах. — Конечно, были плохие моменты, но хороших куда больше, не говоря уже о приятном волнении». Умер он в 1963 году, в возрасте 83 лет. Человек-медоед, не иначе.\n (с) Diana Udovichenko\n","date":"2019-01-20T07:52:56Z","image":"https://blog.iddqd.uk/adrian-karton-di-viart/cover_hue93400e0290949f7e2f718449ca8f3c5_59234_120x120_fill_q75_box_smart1.jpg","permalink":"https://blog.iddqd.uk/adrian-karton-di-viart/","title":"Пули свищут, народ мрет — красота!"},{"content":"При прошивки данной железки возникают некоторые вопросы, ответы на которые найти порой не так просто. Сейчас постараюсь ответить на основные:\n Можно ли установить на него dd-wrt или open-wrt? - Нет, не заведется, к сожалению Можно ли установить wive-ng? - Да, но \u0026ldquo;глючит\u0026rdquo; на столько, что работать с железкой в итоге не представляется возможным Можно ли после экспериментов \u0026ldquo;откатиться\u0026rdquo; на официальную версию? - Да, и это делается очень просто  Итак, если у тебя появится желание экспериментировать с железкой, то имей в виду следующие моменты:\n  Для того, чтоб выполнять манипуляции с прошивкой роутера необходимо его запустить в Recovery mode. Для этого:\n Вынимаем штекер питания роутера Нажимаем и удерживаем клавишу Reset роутера Вставляем штекер питания роутера, продолжая удерживать нажатой клавишу Reset Когда диод WPS начнет медленно мигать (через ~5 секунд) - отпускаем клавишу Reset Последующее простое выключение/включение роутера заставит его запуститься в стандартном режиме    Для прошивки роутера лучше всего его подключать патч-кордом напрямую к сетевой карте машины с которой будет производиться его прошивка. Оставлять включенным только одно сетевое подключение, всё лишнее - выключать\n  IP адрес выставлять 192.168.1.2 и только. Маска подсети 255.255.255.0. Использование любого другого адреса приводит к тому, что железка не обнаруживается и не прошивается\n  То что 192.168.1.1 (роутер) в Recovery mode не пингуется - нормально, не стоит переживать\n  Для прошивки можно использовать как tftpd, так и утилиту от Asus Firmware Restoration. Вторая проще, и выполняет по видимому всё тот же tftp put %файл%\n  Все основные файлы, которые тебе могут понадобиться как для экспериментов, так и восстановления на сток находятся по ссылкам ниже (прошивки openwrt, Wive-WR и сток находятся в директории ./firmware):\n Скачать  Ссылки по теме  Openwrt wiki касательно этой железки Прошивка роутера Asus RT-G32 C1 на Wive-NG-RTNL ","date":"2015-07-18T10:10:13Z","image":"https://blog.iddqd.uk/firmware-rt-g32/cover_hufd73581b96404e67b5185b9cf7a13a3b_10015_120x120_fill_q75_box_smart1.jpg","permalink":"https://blog.iddqd.uk/firmware-rt-g32/","title":"Прошивка роутера Asus RT-G32 ver. C1"},{"content":"В самом аппарате есть программное обеспечение (ПО), которое отвечает за все действия. При помощи этого ПО производится отсчет распечатанных страниц с чипа картриджа. Когда допустимое количество листов будет отпечатано, устройство блокируется. И заправкой картриджа, как вы понимаете здесь не обойтись.\nРешением сложившейся ситуации служит прошивка новым программным обеспечением ваш принтер. В обновленном ПО отсутствует счетчик страниц и уровень тонера всегда 100%.\nВ сети можно обнаружить великое множество ресурсов, на которых предлагают бесплатные и якобы рабочие прошивки. Может где-то оно и так, но тут публикую действительно рабочий способ и проверенный на себе способ.\n  Произведем печать отчета о конфигурации - вставляем в лоток 1 лист бумаги, зажимаем и удерживаем клавишу стоп (находится над кнопкой включения принтера) на 5..10 секунд - когда диод начинает медленно мигать зеленым цветом - отпускаем, после чего и распечатывается лист с отчетом. В отчете должны обнаружить версию прошивки v1.01.00.18 или v1.01.00.19. Если версия в отчете о конфигурации вашего принтера выше, то к сожалению этот способ не для вас;\n  Далее нужно скачать архив с генератором (ML1860GEN.zip, пароль на архив ML1860GEN) и извлечь из него файлы в удобное для вас место на компьютере. Данный офф-лайн генератор работает без подключения к сети интернет;\n  Приступаем к генерации файла прошивки для данного принтера. Для этого нужно найти в папке с распакованным архивом файл с именем ml-1860_19nu_gen.exe и делаем его запуск. В окне программа предложит вам ввести серийный номер;\n  Производим ввод серийного номера принтера, он как и версия прошивки находится в отчете о конфигурации. Состоит серийник из пятнадцати (15) знаков, например: Z5MBBKDB803345L, делаем запуск нажав на кнопку Generate. Далее вас проинформируют что генерация успешно завершилась - можно закрывать приложение. В папке, где расположен генератор, обнаружиться новый файл FIX_Z5MBBKDB803345L_ML1860_19NU.hd;\n  Мышью перетаскиваем полученный в предыдущем шаге файл (например, FIX_Z5MBBKDB803345L_ML1860_19NU.hd) на приложение usbprns2.exe. Затем откроется окно консоли Windows, которое по завершению процесса (3..10 секунд) закроется само. Принтер при этом немного пошумит механикой и произведет перезагрузку;\n  Выключаем принтер, достаем картридж, заклеиваем его контакты (например изолентой):\n   Вставляем картридж обратно, включаем принтер. Наблюдаем как диод теперь не мигает красным, а горит дружелюбным зеленым цветом :)  Так же распечатываем отчет (как в первом пункте). Проверяем чтоб после цифры версии появилась буква F (было V1.01.00.19 12-03-2010, стало V1.01.00.19F12-03-2010). Теперь для того чтоб картридж виделся как полный достаточно просто выключить и включить питание.\n","date":"2015-05-18T15:20:41Z","image":"https://blog.iddqd.uk/hack-printer-samsung-ml-1860/cover_hu20c3f0b842daba4ef0d24b51a21ac24b_26547_120x120_fill_q75_box_smart1.jpg","permalink":"https://blog.iddqd.uk/hack-printer-samsung-ml-1860/","title":"Прошивка принтера Samsung ML-1860"}]