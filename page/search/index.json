[{"content":"База данных (БД) - это организованная структура, предназначенная для хранения, изменения и обработки информации. Это структурированное хранилище данных.\n Какие типы БД знаешь?  Реляционные (SQL) Нереляционные (NoSQL)  Key/Value Документные (документ-ориентированные) Колоночные Графовые Time series (временны́х рядов)     Что такое CAP-теорема (теорема Брюера)? Что такое свойство ACID в базе данных? Вопросы по SQL  Из каких подмножеств состоит SQL? Что подразумевается под таблицей и полем в SQL? В чем разница между операторами DELETE и TRUNCATE? Что такое соединения (JOIN) в SQL? В чем разница между типом данных CHAR и VARCHAR в SQL? Что такое первичный ключ (Primary key)? Что такое ограничения (Constraints)? Что такое уникальный ключ (Unique key)? Что такое внешний ключ (Foreign key)? Что подразумевается под целостностью данных? Какие уровни изолированности транзакций можешь назвать? Что вы подразумеваете под денормализацией? Напишите SQL-запрос для отображения текущей даты?   Индексы  В чем разница между кластеризованным и не кластеризованным индексами в SQL? Какие типы индексов знаешь? Как устроен B-Tree индекс?      Какие типы БД знаешь? Реляционные (SQL) Характерны тем, что данные могут быть связанными между собой с помощью отношений (relation - связь, отношение), например - значение одной колонки может ссылаться на какую-либо колонку в другой таблице (aka \u0026ldquo;внешние ключи\u0026rdquo;). Данные хранятся в виде набора таблиц, состоящих из столбцов и строк. В каждом столбце (column) хранятся данные определенного типа.\nСхема таблиц объявляется при её создании.\nПримеры: MySQL (C++) (или её форк MariaDB), PostgreSQL (C), SQLite (C)\nНереляционные (NoSQL)  NoSQL - Not Only Structured Query Language\n Обладают гибкими схемами, т.е. объявлять структуру помещаемых данных заранее часто не является обязательным условием.\nKey/Value Хранилища предоставляют доступ к данным, которые хранятся по уникальным ключам в \u0026ldquo;плоском\u0026rdquo; представлении. Чтобы запросить данные, нужно знать их ключ. Часто используется хранение данных в виде JSON-объектов, но для СУБД это просто некоторый случайный набор байт (blob-объект).\nПримеры: Redis (C), KeyDB (C++), memcached (C), etcd (Go)\nДокументные (документ-ориентированные) Используют базовую семантику доступа и поиска хранилищ ключей и значений, часто имеют структуру дерева (иногда леса). Такие БД также используют ключ для уникальной идентификации данных. Разница между хранилищами \u0026ldquo;Key/Value\u0026rdquo; и документными БД заключается в том, что вместо хранения blob-объектов, документ-ориентированные базы хранят данные в структурированных форматах – JSON, BSON или XML.\nКак следствие:\n Документы могут быть организованы (сгруппированы) в коллекции (их можно считать отдалённым аналогом таблиц реляционных СУБД) База данных не предписывает определенный формат или схему Каждый документ может иметь свою внутреннюю структуру Документные БД являются хорошим выбором для быстрой разработки В любой момент можно менять свойства данных, не изменяя структуру или сами данные  Примеры: MongoDB (C++), RethinkDB (C++), Elasticsearch (Java), Aerospike (C)\nКолоночные Внешне похожи на реляционные БД (хранят данные, используя строки и столбцы), но с иной связью между элементами. Данные группируются не по строкам, а по столбцам. В ней \u0026ldquo;соседними\u0026rdquo; являются не данные из двух столбцов одной и той же строки, а данные из одного и того же столбца, но из разных строк.\nОсобенностью является высокая скорость и гибкость выполнения сложных запросов. Действительно, в \u0026ldquo;строчной\u0026rdquo; СУБД при поиске и считывании значений сканируется вся таблица по строкам и столбцам, а затем извлекаются строки целиком, даже в том случае, если нужно только одно значение каждой из них. Колоночные базы данных позволяют искать значения по отдельным столбцам и извлекать только те значения, которые требуются.\nПримеры: ClickHouse (C++), Cassandra (Java)\nГрафовые Вместо сопоставления связей с таблицами и внешними ключами, графовые базы данных устанавливают связи, используя узлы, рёбра и свойства. Они представляют данные в виде отдельных узлов, которые могут иметь любое количество связанных с ними свойств.\nПримеры: Neo4j (Java), Dgraph (Go), RedisGraph (C)\nTime series (временны́х рядов) Созданы для сбора и управления элементами, меняющимися с течением времени. Большинство таких БД организованы в структуры, которые записывают значения для одного элемента (например, временная метка и значение температуры процессора). В таблице может быть несколько метрик. Оптимизированы для быстрой записи данных.\nПримеры: Prometheus (Go), InfluxDB (Go)\nЧто такое CAP-теорема (теорема Брюера)? Утверждение о том, что в любой реализации распределённых вычислений возможно обеспечить не более двух из трёх следующих свойств:\n Согласованность данных (consistency) - как только мы успешно записали данные в наше распределенное хранилище, любой клиент при запросе получит эти последние данные Доступность (availability) - в любой момент клиент может получить данные из нашего хранилища, или получить ответ об их отсутствии, если их никто еще не сохранял Устойчивость к разделению (partition tolerance) - потеря сообщений между компонентами системы (возможно даже потеря всех сообщений) не влияет на работоспособность системы  С точки зрения теоремы CAP, распределённые системы в зависимости от пары практически поддерживаемых свойств из трёх возможных распадаются на три класса:\n CA (consistency + availability) - во всех узлах данные согласованы и обеспечена доступность, при этом она жертвует устойчивостью к распаду на секции CP (consistency + partition tolerance) - в каждый момент обеспечивает целостный результат и способна функционировать в условиях распада, но достигает этого в ущерб доступности - может не выдавать отклик на запрос AP (availability + partition tolerance) - не гарантируется целостность, но при этом выполнены условия доступности и устойчивости к распаду на секции   Что можно почитать:\n  CAP-теорема простым, доступным языком Недопонимание CAP-теоремы  Что такое свойство ACID в базе данных? ACID используется для обеспечения надежной обработки транзакций данных в СУБД и означает:\n Атомарность (Atomicity) - гарантирует, что транзакция будет полностью выполнена или потерпит неудачу, где транзакция представляет одну логическую операцию данных (\u0026ldquo;всё или ничего\u0026rdquo;) Согласованность или консистентность (Consistency) - гарантирует, что данные должны соответствовать всем правилам валидации Изолированность (Isolation) - контроль механизма параллельного изменения данных Долговечность или стойкость (Durability) - если транзакция была подтверждена (COMMIT), произошедшие в рамках транзакции изменения сохранятся независимо от того, что может встать у них на пути (например, потеря питания, сбой или ошибки любого рода)  В базах данных, следующих принципу ACID, данные остаются целостными и консистентными, несмотря на любые ошибки.\nNoSQL базы данных часто предназначены для обеспечения высокой доступности в кластере, а обычно это означает, что в некоторой степени жертвуют согласованностью (consistency) и/или стойкостью (durability). Хотя, разработчики такие как MarkLogic, OrientDB и Neo4j предлагают ACID-совместимые СУБД.\nВопросы по SQL Из каких подмножеств состоит SQL?  DDL (Data Definition Language, язык описания данных) -позволяет выполнять различные операции с базой данных, такие как CREATE (создание), ALTER (изменение) и DROP (удаление объектов) DML (Data Manipulation Language, язык управления данными) -позволяет получать доступ к данным и манипулировать ими, например, вставлять INSERT, обновлять UPDATE, удалять DELETE и извлекать данные SELECT из базы данных DCL (Data Control Language, язык контролирования данных) -позволяет контролировать доступ к базе данных; примеры -GRANT (предоставить права), REVOKE (отозвать права)  Что подразумевается под таблицей и полем в SQL? Таблица - организованный набор данных в виде строк и столбцов. Поле - это столбцы в таблице.\nВ чем разница между операторами DELETE и TRUNCATE?  Delete удаляет строку в таблице, а truncate удаляет все строки После delete возможно откатить изменения, а после truncate как правило нет Truncate работает быстрее  Что такое соединения (JOIN) в SQL? Это объединение строк из двух (или более) таблиц на основе связанного между ними столбца. Примеры JOIN-ов:\n INNER JOIN (внутреннее соединение) - пересечение двух таблиц, то есть строки, общие для каждой из них (пример: select * from a INNER JOIN b on a.a = b.b;) LEFT JOIN (левое соединение) - все строки из первой (левой) таблицы плюс все строки второй таблицы, имеющие совпадение со строками из первой таблицы (пример: select * from a LEFT OUTER JOIN b on a.a = b.b;) RIGHT JOIN (правое соединение) - все строки из второй (правой) таблицы плюс все строки первой таблицы, имеющие совпадение со строками из второй таблицы (пример: select * from a RIGHT OUTER JOIN b on a.a = b.b;) FULL JOIN (полное соединение) - полное соединение обеих таблиц (т.е. все строки из первой и второй таблиц); если соответствия нет, то значение null (пример: select * from a FULL OUTER JOIN b on a.a = b.b;)   Что можно почитать:\n Примеры   В чем разница между типом данных CHAR и VARCHAR в SQL? И CHAR, и VARCHAR служат символьными типами данных, но VARCHAR используется для строк символов переменной длины, тогда как CHAR используется для строк фиксированной длины. Например, CHAR(10) может хранить только 10 символов и не сможет хранить строку любой другой длины, тогда как VARCHAR(10) может хранить строку любой длины до 10, т.е. например 6, 8 или 2.\nЧто такое первичный ключ (Primary key)? Первичный ключ - столбец (или набор столбцов), которые однозначно идентифицируют каждую (одну) строку в таблице. Нулевые (null) значения не допускаются. Автоматически индексируются.\nЧто такое ограничения (Constraints)? Ограничения (constraints) используются для указания ограничения на тип данных таблицы. Они могут быть указаны при создании или изменении таблицы. Пример ограничений:\n NOT NULL - значение не может быть null CHECK - произвольные проверки на значение, например constraint uuid_is_valid check (is_uuid(uuid)) проверяет на валидность UUID идентификатор, а constraint login_min_length check (char_length(login) \u0026gt;= 3) на минимальную длину строки поля логина DEFAULT - устанавливает значение по умолчанию для поля в колонке UNIQUE - обязывает значение бить уникальным в рамках таблицы PRIMARY KEY - объявляет первичный ключ FOREIGN KEY - объявляет внешний ключ (связывает таблицы отношением), например constraint user_uuid_foreign_key foreign key (user_uuid) references users (uuid) on update cascade on delete cascade обязывает содержать значение в user_uuid только для существующей записи в таблице users и автоматически обновится если оно будет изменено в таблице users, а так же заставит запись удалиться при удалении записи о пользователе  Что такое уникальный ключ (Unique key)? Уникальный ключ однозначно идентифицирует одну строку в таблице (таблица не может содержать дубликатов). В одной таблице может быть несколько уникальных ключей. Возможны нулевые (null) значения.\nЧто такое внешний ключ (Foreign key)? Внешний ключ поддерживает ссылочную целостность, обеспечивая связь между данными в двух таблицах. Внешний ключ в дочерней таблице ссылается на первичный ключ в родительской таблице. Ограничение внешнего ключа предотвращает действия, которые разрушают связи между дочерней и родительской таблицами.\nЧто подразумевается под целостностью данных? Целостность данных определяет точность, а также согласованность данных, хранящихся в базе данных. Она также определяет ограничения целостности для обеспечения соблюдения бизнес-правил для данных, когда они вводятся в приложение или базу данных.\n Например, вес детали должен быть положительным; количество знаков в телефонном номере не должно превышать 15; возраст родителей не может быть меньше возраста их биологического ребёнка и так далее.\n Какие уровни изолированности транзакций можешь назвать? Транзакция - это N (N≥1) запросов к БД, которые выполнятся успешно все вместе или не выполнятся вовсе. Изолированность же транзакции показывает то, насколько сильно влияют друг на друга параллельно выполняющиеся транзакции.\n Read uncommitted (самая плохая согласованность данных, но самая высокая скорость выполнения) - каждая транзакция видит незафиксированные изменения другой транзакции (феномен \u0026ldquo;грязного чтения\u0026rdquo;). На данном уровне нельзя использовать данные, на основе которых делаются важные для приложения выводы и критические решения Read committed (используется по умолчанию в PostgreSQL) - параллельно исполняющиеся транзакции видят только зафиксированные изменения из других транзакций (защита от \u0026ldquo;грязного чтения\u0026rdquo;). Т.е. для транзакции, работающей на этом уровне, запрос SELECT (без предложения FOR UPDATE/SHARE) видит только те данные, которые были зафиксированы до начала запроса; она никогда не увидит незафиксированных данных или изменений, внесённых в процессе выполнения запроса параллельными транзакциями. Этот уровень подвержен феномену неповторяющегося чтения Repeatable read (используется по умолчанию в MySQL) - уровень, позволяющий предотвратить феномен неповторяющегося чтения. Т.е. мы не видим в исполняющейся транзакции измененные и удаленные записи другой транзакцией. Но все еще видим вставленные записи из другой транзакции. Чтение фантомов никуда не уходит. Serializable (самая низкая скорость выполнения и самая высокая согласованность) - транзакции ведут себя как будто ничего более не существует, никакого влияния друг на друга нет. В классическом представлении этот уровень избавляет от эффекта чтения фантомов   Что можно почитать:\n Уровни изолированности транзакций для самых маленьких   Что вы подразумеваете под денормализацией? Денормализация - техника, которая используется для преобразования из высших к низшим нормальным формам. Она помогает разработчикам баз данных повысить производительность всей инфраструктуры, поскольку вносит избыточность в таблицу. Она добавляет избыточные данные в таблицу, учитывая частые запросы к базе данных, которые объединяют данные из разных таблиц в одну таблицу.\nНапишите SQL-запрос для отображения текущей даты? Есть несколько способов (проверял на MySQL 8.0):\n select CURDATE(); select CURRENT_DATE вернёт 2022-03-16 select NOW() вернёт 2022-03-16 12:21:10, т.е. дату с текущим временем select UNIX_TIMESTAMP() вернёт 1647433317, т.е. временную метку в UNIX-формате  Индексы Индекс создает отдельную структуру для индексируемого поля и, следовательно, позволяет быстрее получать данные (аналогично тому, как указатель в книге помогает вам быстро найти необходимую информацию).\nВ чем разница между кластеризованным и не кластеризованным индексами в SQL? Различия между кластеризованным и не кластеризованным индексами в SQL:\n Кластеризованный индекс используется для простого и быстрого извлечения данных из базы данных, тогда как чтение из не кластеризованного индекса происходит относительно медленнее Кластеризованный индекс изменяет способ хранения записей в базе данных - он сортирует строки по столбцу, который установлен как кластеризованный индекс, тогда как в не кластеризованном индексе он не меняет способ хранения, но создает отдельный объект внутри таблицы, который указывает на исходные строки таблицы при поиске Одна таблица может иметь только один кластеризованный индекс, тогда как не кластеризованных у нее может быть много  Какие типы индексов знаешь? PostgreSQL поддерживает несколько типов индексов: B-Tree, Hash, GiST, SP-GiST, GIN и BRIN. Для разных типов индексов применяются разные алгоритмы, ориентированные на определённые типы запросов. По умолчанию команда CREATE INDEX создаёт индексы типа B-Tree, эффективные в большинстве случаев.\n B-Tree (self-balancing tree data structure) - хорошо работают в условиях на равенство и в проверках диапазонов с данными, которые можно отсортировать в некотором порядке (операторы \u0026lt;, \u0026lt;=, =, \u0026gt;=, \u0026gt;). Также оптимизатор может использовать индексы этого типа в запросах с операторами сравнения по шаблону LIKE и ~, если этот шаблон определяется константой и он привязан к началу строки - например, col LIKE 'foo%' или col ~ '^foo', но не col LIKE '%bar' Hash хранят 32-битный хеш-код, полученный из значения индексированного столбца, поэтому хеш-индексы работают только с простыми условиями равенства = GiST представляют собой не просто разновидность индексов, а инфраструктуру, позволяющую реализовать много разных стратегий индексирования. Применим для типов данных box, circle, inet, point, polygon, tsquery, tsvector и диапазоны (для разных типов поддерживаются различные наборы операторов). В общем, хорош для гео-данных и данных сетевой адресации SP-GiST позволяет организовывать на диске самые разные несбалансированные структуры данных, такие как деревья квадрантов, k-мерные и префиксные деревья GIN - это \u0026ldquo;инвертированные\u0026rdquo; индексы, в которых могут содержаться значения с несколькими ключами, например массивы. Инвертированный индекс содержит отдельный элемент для значения каждого компонента, и может эффективно работать в запросах, проверяющих присутствие определённых значений компонентов. Поддерживает операторы \u0026lt;@, @\u0026gt;, = и \u0026amp;\u0026amp; BRIN (Block Range INdexes, Индексы зон блоков) хранят обобщённые сведения о значениях, находящихся в физически последовательно расположенных блоках таблицы. Для типов данных, имеющих линейный порядок сортировки, записям в индексе соответствуют минимальные и максимальные значения данных в столбце для каждой зоны блоков. Поддерживает операторы \u0026lt;, \u0026lt;=, =, \u0026gt;= и \u0026gt;   Что можно почитать:\n Обзор типов индексов Oracle, MySQL, PostgreSQL, MS SQL   Как устроен B-Tree индекс? Семейство B-Tree индексов - это наиболее часто используемый тип индексов, организованных как сбалансированное дерево, упорядоченных ключей. Они поддерживаются практически всеми СУБД как реляционными, так нереляционными, и практически для всех типов данных.\n","date":"2022-03-04T07:05:42Z","image":"https://blog.hook.sh/interview-section-databases/cover_hu954bdcfd609a05cdb15db44fde92cc9d_27988_120x120_fill_box_smart1_3.png","permalink":"https://blog.hook.sh/interview-section-databases/","title":"Вопросы и ответы по базам данных"},{"content":"Часто на интервью задают вопросы связанные не только с основным/дополнительным ЯП или СУБД, но и с тем, как приложения взаимодействуют между собой используя сетевую коммуникацию. Для понимания того, как эти шестерёнки вращаются и что нужно иметь в виду отвечая на вопросы из этой серии и была написана эта заметка.\n Что происходит после ввода адреса в браузер?  DNS Отправка пакета TLS Handshake HTTP запрос   Перечисли все уровни модели OSI? Что такое IP адрес? Какие режимы передачи данных бывают? Что такое NAT? Расскажи про DHCP? Что такое ICMP? Что такое TCP/IP?  IP (Internet Protocol) TCP (Transmission Control Protocol) UDP (User Datagram Protocol)   Какие бывают версии HTTP?  HTTP/0.9 HTTP/1.0 HTTP/1.1 HTTP/2 HTTP/3   Как работает HTTPS?  SSL TLS Шифрование      Что происходит после ввода адреса в браузер? Адрес (по-другому URL), который был введён в строку адреса состоит из:\n Протокола, который используется для доступа к ресурсу (http, https, ftp и т.д.)  Если протокол введён не был, то браузер смотрит - есть ли он у него в списке HSTS (HTTP Strict Transport Security, механизм принудительно активирующий защищенное соединение через протокол https), и если домен есть у него в списке - запрос будет отправлен используя протокол https, иначе - http (включается он с помощью HTTP заголовка на сервере домена Strict-Transport-Security: max-age=31536000; includeSubDomains; preload;)   Хоста или домена (example.com, linux.org) Номера порта (опционально)  Для общения с веб-сервером на запрашиваемом домене, нам нужно установить TCP соединение с определенным портом. В случае, если он указан явно (http://1.1.1.1:8080) - то используется он, а иначе - используется стандартный порт для запрошенного протокола (80 для http, 443 для https, и так далее)   И запроса (query, ресурс, URN) - строки адреса ресурса (например - адрес страницы)  DNS После разбора адреса мы должны установить соединение с сервером, и сделать это по IP адресу (а не доменному имени, TCP/IP же), для чего нам нужно преобразовать имя домена в IP адрес (другими словами - разрезолвить адрес; вообще, домены используются в первую очередь для удобства, и для возможности размещать несколько сайтов на одном IP адресе). Для этого:\n Сперва браузер смотрит в свой кэш (браузера) Если там не обнаружено - то смотрит в файл hosts (в котором можно захардкодить любой IP для любого домена) Если и там нет, но смотрит в кэше операционной системы (systemd-resolve) Если нигде нет, то отправляется за адресом в сеть:  Отправляется запрос на сетевой DNS сервер (который был получен по DHCP или прописан ручками)  Если и у него нет, то он (сервер) идёт в корневой сервер, тот - в DNS сервер ответственный за зону (например - .com) - и так до тех пор, пока целевой NS (где хранятся записи) не будет найден Когда целевой NS сервер достигнут (тот, где и содержится искомая запись для домена; обычно это A или CNAME) - то IP адрес сервера (A запись содержит IP, а вот с CNAME история резолвинга повторяется по кругу, так как она просто перенаправляет на другое доменное имя) возвращается по цепочке обратно (до запросившей её стороны), попутно кэшируясь на промежуточных серверах (если это необходимо и возможно)      Отправка пакета Далее, когда нам известен IP адрес сервера, мы можем сформировать и отправить запрос. Вспоминая устройство стека протоколов TCP/IP происходит следующее:\n На прикладном уровне (application layer) браузером формируется запрос к серверу (будь то DNS, HTTP, HTTPS и тому подобное) Далее, на транспортном уровне (transport layer, TCP или UDP протокол) в заголовки пакета добавляется порт, по которому нужно стучаться На сетевом уровне (network layer, IP протокол) добавляется IP адрес к нашему пакету На канальном уровне (data link layer) с помощью ARP (Address Resolution Protocol, протокол предназначенный для определения MAC-адреса другого компьютера по известному IP-адресу) определяется \u0026ldquo;есть ли такой адрес в сети?\u0026rdquo;  Если адрес есть в сети - то к нему передаётся пакет В противном случае пакет передаётся на шлюз, который, поднимаясь по уровням выше (смотря на то, какой IP адрес и смотря свою таблицу маршрутизации) - направляет пакет в нужном направлении (пока не закончится TTL протокола IP, либо пакет не достигнет пункта своего назначения)    TLS Handshake Если запрос был отправлен по протоколу https, то наступает пора установить защищенное соединение (TLS Handshake), для этого:\n Браузер отправляет Client hello серверу со своей версией протокола TLS (например - TLSv1.3) Сервер отвечает клиенту сообщением Server hello, содержащим версию TLS, выбранным методом шифрования, методом компрессии и публичным сертификатом сервиса (подписанный центром сертификации; сертификат содержит публичный ключ, который будет использоваться клиентом для шифрования) Клиент подтверждает сертификат сервера с помощью своего списка центров сертификации (если сертификат сервера подписан центром из списка - то ему можно доверять) Клиент отправляет серверу некоторые данные, зашифрованные с помощью публичного ключа сервера Сервер расшифровывает сообщение с помощью своего приватного ключа и генерирует симметричный мастер-ключ Клиент отправляет серверу сообщение Finished, шифруя хэш передачи с помощью симметричного ключа Сервер генерирует собственный хэш, а затем расшифровывает полученный от клиента хэш что бы проверить совпадает ли он с собственным; если совпадение обнаружено - сервер отправляет клиенту Finished, а так же зашифрованный собственный симметричный ключ Далее клиент и сервер отправляют сообщения с помощью этого симметричного ключа  HTTP запрос На прикладном уровне браузер формирует запрос к серверу по http протоколу:\n В запрос вставляется используемый HTTP-метод (в нашем случае это будет GET) Далее указывается URN (запрос, или query-строка) Версия используемого протокола (например - HTTP/1.1) И на новой строке указывается заголовок Host с именем запрашиваемого домена (так как на одном IP может быть несколько виртуальных серверов) и другие заголовки, формируемые самим браузером или иным ПО  После формирования запроса на прикладном уровне он передаётся на транспортный уровень (и ниже) и по установленному ранее (в случае с http) TCP соединению доставляется на сервер. Сервер же:\n По номеру запрошенного порта определяет какому приложению он адресован Смотрит в HTTP-заголовок Host для определения какому сайту (виртуальному серверу) он был адресован Определяет, может ли виртуальный хост обработать запрошенный метод и куда его отдавать на обработку по запрошенному URN (строке запроса)  После обработки запроса сервер вернёт клиенту ответ на его запрос, содержащий версию HTTP протокола (в случае с HTTP/2), код ответа, и заголовки/тело запроса, если они имеются. Далее браузер уже принимает ответы от сервера и отображает страницу (рендерит её, HTML парсится во много проходов, для чего создаётся DOM и CSSOM).\n  Перечисли все уровни модели OSI?  L7 - Приложений или Прикладной (Application layer), например HTTP, FTP, WebSocket L6 - Представления (Presentation layer), например ASCII, JPEG L5 - Сеансовый (Session layer), например RPC, L2TP, gRPC L4 - Транспортный (Transport layer), например TCP, UDP, порты L3 - Сетевой (Network layer), например IPv4, IPsec, ICMP L2 - Канальный (Data Link layer), например PPP, IEEE, Ethernet, сетевая карта L1 - Физический (Physical layer), например USB, RJ (витая пара), радиоканал     Что можно почитать:\n Wiki: Сетевая модель OSI   Что такое IP адрес? Это уникальный внутри подсети идентификатор устройства сетевого уровня модели OSI (протокола IP), который состоит из 4 байт (32 бита; в IPv6 используется 128 бит для кодирования адреса). Всего может существовать 4_294_967_296 адресов.\nIP адрес у устройства может быть статический (не меняется и всегда остается одним и тем же) и динамический (назначается на определенное время, затем заменяется другим).\nКакие режимы передачи данных бывают? Механизм передачи данных или информации между двумя связанными устройствами, соединенными по сети, называется режимом передачи.\n Симплексный - связь является однонаправленной, то есть данные могут передаваться только в одном направлении (как на улице с односторонним движением; пример - клавиатура, телевизионное вещание) Полудуплексный - данные могут передаваться в обе стороны, но не одновременно (пример - рация) Полнодуплексный - данные могут одновременно передаваться в обе стороны (как на улице с двухсторонним движением)  Что такое NAT? Сети обычно проектируются с использованием частных IP адресов. Частные адреса используются внутри организации или площадки, чтобы позволить устройствам общаться локально, и они не маршрутизируются в интернете:\n 10.0.0.0/8 (10.0.0.0 – 10.255.255.255/8, 16_777_216 хостов) 172.16.0.0/12 (172.16.0.0 – 172.31.255.255/12, 1_048_576 хостов) 192.168.0.0/16 (192.168.0.0 – 192.168.255.255/16, 65_536 хостов)  Чтобы позволить устройству с приватным IPv4-адресом обращаться к устройствам и ресурсам за пределами локальной сети, приватный адрес сначала должен быть переведен на общедоступный (публичный) адрес, чем NAT (Network Address Translation) и занимается (переводит приватные адреса, в общедоступные).\nNAT позволяет устройству с частным адресом IPv4 обращаться к ресурсам за пределами его частной сети. NAT в сочетании с частными адресами IPv4 оказался полезным методом сохранения общедоступных IPv4-адресов. Один общедоступный IPv4-адрес может быть использован сотнями, даже тысячами устройств, каждый из которых имеет частный IPv4-адрес. NAT имеет дополнительное преимущество, заключающееся в добавлении степени конфиденциальности и безопасности в сеть, поскольку он скрывает внутренние IPv4-адреса из внешних сетей.\nЧаще всего для трансляции IP адресов NAT использует тип трансляции PAT (Port Address Translation) - транслирует несколько частных адресов на один или несколько общедоступных адресов. Фактически, PAT \u0026ldquo;привязывает\u0026rdquo; каждый сеанс выхода клиента из внутренней сети во внешнюю к своему случайному порту (из диапазона 0-511, 512-1023 или 1024-65535), тем самым \u0026ldquo;запоминая\u0026rdquo; куда (какому именно клиенту) отправить полученные в ответе пакеты обратно.\n Что можно почитать:\n NAT на пальцах - что это?   Расскажи про DHCP? Dynamic Host Configuration Protocol (DHCP) - это прикладной протокол (L7 по модели OS, передача данных производится при помощи протокола UDP), позволяющий сетевым устройствам автоматически получать IP-адрес и другие параметры (сетевую маску, адреса DNS серверов), необходимые для работы в сети TCP/IP. Доступен как для IPv4 (DHCPv4), так и для IPv6 (DHCPv6).\nDHCPv4 включает три разных механизма распределения адресов:\n Ручное распределение (Manual Allocation) - администратор назначает предварительно установленный IPv4-адрес клиенту, а DHCP сервер передает IPv4-адрес на устройство Автоматическое распределение(Automatic Allocation) - DHCPv4 автоматически назначает статический IPv4-адрес на устройство, выбирая его из пула доступных адресов. Нет аренды (lease), и адрес постоянно назначается устройству Динамическое распределение (Dynamic Allocation) - DHCPv4 динамически назначает или дает в аренду IPv4-адрес из пула адресов в течение ограниченного периода времени, выбранного сервером, или пока клиент больше не нуждается в адресе  DHCPv4 работает в режиме клиент (порт 67) - сервер (порт 68). Когда клиент взаимодействует с сервером DHCPv4, сервер назначает или арендует IPv4-адрес этому клиенту. Он подключается к сети с этим арендованным IP-адресом до истечения срока аренды и должен периодически связываться с сервером DHCP, чтобы продлить аренду. Этот механизм аренды гарантирует, что клиенты, которые перемещаются или выходят из строя - не сохраняют за собой адреса, которые им больше не нужны. По истечении срока аренды сервер DHCP возвращает адрес в пул, где он может быть перераспределен по мере необходимости.\nРассмотрим процесс получения адреса:\n Когда клиент хочет присоединиться к сети, он начинает четырех-этапный процесс для получения аренды. Он запускает процесс с широковещательным (broadcast) сообщением DHCPDISCOVER со своим собственным MAC-адресом для обнаружения доступных DHCP-серверов. Поскольку у клиента нет способа узнать подсеть, к которой он принадлежит, у сообщения DHCPDISCOVER адрес назначения IPv4 адреса - широковещательный адрес 255.255.255.255 (т.е. отправляется всем устройствам в его сети на сетевом L3 уровне) и целевой MAC-адрес FF:FF:FF:FF:FF:FF (тоже является широковещательным для канального L2 уровня). А поскольку у клиента еще нет настроенного адреса IPv4, то исходный IPv4-адрес - 0.0.0.0 Когда DHCPv4-сервер получает сообщение DHCPDISCOVER, он резервирует доступный IPv4-адрес для аренды клиенту. Сервер также создает запись ARP, состоящую из MAC-адреса клиента и арендованного IPv4-адреса DHCP сервер отправляет связанное сообщение DHCPOFFER запрашивающему клиенту, как одноадресная передача (unicast), используя MAC-адрес сервера в качестве исходного адреса и MAC-адрес клиента в качестве адреса доставки Когда клиент получает DHCPOFFER с сервера, он отправляет обратно сообщение DHCPREQUEST. Это сообщение используется как для получения, так и для продления аренды При получении сообщения DHCPREQUEST сервер проверяет информацию об аренде с помощью ICMP-запроса на этот адрес, чтобы убедиться, что он уже не используется и создает новую ARP запись для аренды клиента, а затем отвечает одноадресным DHCPACK-сообщением. Это сообщение является дубликатом DHCPOFFER, за исключением изменения поля типа сообщения. Когда клиент получает сообщение DHCPACK, он регистрирует информацию и выполняет поиск ARP для назначенного адреса. Если ответа на ARP нет, клиент знает, что адрес IPv4 действителен и начинает использовать его как свой собственный   Что можно почитать:\n Wiki: DHCP   Что такое ICMP? Internet Control Message Protocol (ICMP) - это сетевой протокол (L3 по модели OSI) который чаще всего используется для передачи сообщений об ошибках и других исключительных ситуациях, возникших при передаче данных. Хотя формально протокол использует IP (ICMP-пакеты инкапсулируются в IP пакеты), он является неотъемлемой частью IP-протокола и обязателен при реализации стека TCP/IP.\nICMP основан на протоколе IP. Каждое ICMP-сообщение инкапсулируется непосредственно в пределах одного IP-пакета, и, таким образом, как и UDP и в отличие от TCP, ICMP является т. н. «ненадежным» (не контролирующим доставку и её правильность).\nНапример, каждая машина, которая перенаправляет IP-пакеты (например маршрутизатор), уменьшает значение поля Time to live (TTL) заголовка IP-пакета на единицу; если TTL достигает 0, на источник пакета отправляется ICMP-сообщение о превышении TTL.\n Что можно почитать:\n Wiki: ICMP   Что такое TCP/IP? Изначально стек протоколов TCP/IP разработан в 1972 году на основе Network Control Protocol, но только спустя 4 года создана передача данных с применением протокола TCP. К концу 80-х было выделено две отдельные функции – TCP и IP. И уже к 1983 году удалось полностью перейти на современный протокол, что и считается отправной точкой развития Интернета.\nСтек модели TCP/IP контролирует взаимодействие различных уровней системы (стек делится на отдельные уровни, каждый из которых направлен на решение определенной задачи). Ключевыми в нем являются сами протоколы, которые встраиваются друг в друга (работают одновременно, без конфликтов, сбоев и незавершенных операций) и обеспечивают передачу данных.\nIP (Internet Protocol) Маршрутизируемый протокол сетевого уровня модели стека протоколов TCP/IP, нужен для логической адресации устройств в компьютерной сети или сети передачи данных. Ключевые понятия о протоколе IP:\n Каждый узел на сетевом уровне в модели TCP/IP должен иметь IP-адрес, который состоит из 4 байт (254.254.254.254) Минимальной единицей измерения данных здесь является IP-пакет (который чаще всего инкапсулируется в Ethernet кадр) При доставке IP-пакета возможна его фрагментация (дробление) на более мелкие (получатель должен будет его собрать обратно). Так же возможен и запрет на фрагментацию (отправителю будет отправлен ICMP-сообщение об ошибке) Функция IP протокола заключается в том, чтобы доставить пакет из точки А в точку Б через множество промежуточных сетей (при этом IP-пакеты при передаче данных могут быть изменены, потеряны, повреждены, пакеты могут прийти получателю не в той последовательности, в которой они были отправлены - обо всем этом протокол IP не заботится, его задачей является организовать маршрут) Протокол использует передачу данных без установки соединения  Размер заголовка IP-пакета составляет от 20 (обычный заголовок без дополнительных опций) до 60 байт.\nTCP (Transmission Control Protocol) Протокол транспортного уровня, управляющий передачей данных. Фактически, если IP протокол связывает между собой машины в сети, то TCP связывает конкретные приложения используя порты (которых одновременно на машине может быть до 65535, т.к. номер порта занимает 2 байта). Ключевые характеристики:\n Требует установки соединения (для этого сервер делает passive open - ждёт входящие запросы, а клиент active open - отправляет серверу SYN, на что сервер должен ответить ACK + SYN, клиент в ответ на это должен ответить ACK, и после этого соединение считается установленным) Нумерует пакеты, посылает подтверждения о получении данных (ACK) и запрашивает повторную передачу, если данные не получены или искажены (или истёк таймаут для ответа), т.е. обеспечивает гарантию доставки Любое установленное TCP-соединение симметрично, и пакеты с данными по нему всегда идут в обе стороны (двунаправленная взаимосвязь) Когда один из узлов решает, что пора заканчивать соединение, он посылает специальный пакет FIN, после этого узлы прощаются и разрывают соединение Использование принципа \u0026ldquo;скользящего окна\u0026rdquo; для увеличения скорости передачи (ACK не каждого сообщения, а определенной \u0026ldquo;пачки\u0026rdquo;; причём размер окна может меняться динамически) Контролирует загруженность соединения  UDP (User Datagram Protocol) Протокол транспортного уровня, передающий сообщения-датаграммы без необходимости установки соединения в IP-сети. UDP допускает потери пакетов, их дублирование, перемешивание, но контролирует целостность полученных датаграмм. Так же UDP не контролирует загруженность канала (более жадный).\nБлагодаря такой не избирательности и бесконтрольности, UDP доставляет пакеты данных (датаграммы) гораздо быстрее, потому для приложений, которые рассчитаны на широкую пропускную способность и быстрый обмен, UDP можно считать оптимальным протоколом. К таковым относятся сетевые и браузерные игры, а также программы просмотра потокового видео и приложения для видео (или голосовой) связи - от потери пакета, полной или частичной, ничего не меняется, повторять запрос не обязательно, зато загрузка происходит намного быстрее.\nЯ бы рассказал отличную шутку про UDP, но боюсь, не до всех она дойдёт 😄\n   Что можно почитать:\n Wiki: IP IP-пакет в протоколе IPv4. Структура, заголовок и поля в IP-пакете Протоколы TCP и UDP   Какие бывают версии HTTP? HTTP (HyperText Transfer Protocol) - это клиент-серверный протокол прикладного уровня, реализованный поверх протокола TCP/IP (третья версия протокола работает используя UDP). Сам HTTP зависит от протокола TCP/IP (UDP), позволяющего посылать и отправлять запросы между клиентом и сервером. По умолчанию используется 80 порт TCP, но могут использоваться и другие (HTTPS, например, использует 443 порт).\nВыполнить простейший HTTP запрос можно с помощью telnet:\n$ telnet google.com 80 Trying 142.251.1.113... Connected to google.com. Escape character is \u0026#39;^]\u0026#39;. GET /robots.txt HTTP/1.1 Host: google.com # просто 2 пустые строки (2 раза нажми enter) HTTP/1.1 301 Moved Permanently (headers) (content) HTTP/0.9 Появился в конце 1990 года (разработан Тимом Бернерсом-Ли) и был экстремально простым - запрос состоял из одной строки и умел только метод GET (GET /mypage.html), а ответ в свою очередь только контент ответа (обычно HTML; без заголовков) и даже без кода ответа.\nGET /mypage.html \u0026lt;HTML\u0026gt; A very simple HTML page \u0026lt;/HTML\u0026gt; HTTP/1.0 Спецификация (RFC 1945) была опубликована в ноябре 1996 года. Информация о версии протокола теперь отправляется с каждым запросом (GET /mypage.html HTTP/1.0). Код ответа отправляется в самом начале ответа (200 OK). Добавлена поддержка заголовков (как запросов, так и ответов) для передачи мета-информации. К методу GET добавились HEAD, POST, PUT, DELETE, LINK, UNLINK. Кроме того, с помощью заголовка Content-Type стало возможным передавать разные типы контента:\nGET /mypage.html HTTP/1.0 User-Agent: NCSA_Mosaic/2.0 (Windows 3.1) 200 OK Date: Tue, 15 Nov 1996 08:12:31 GMT Server: CERN/3.0 libwww/2.17 Content-Type: text/html \u0026lt;HTML\u0026gt; A page with an image \u0026lt;IMG SRC=\u0026#34;/myimage.gif\u0026#34;\u0026gt; \u0026lt;/HTML\u0026gt; Для каждого запроса и ответа между клиентом и сервером создаётся новое TCP-соединение (пожалуй, главный недостаток, поскольку каждое новое TCP-соединение требует \u0026ldquo;тройного рукопожатия\u0026rdquo;, за которым следует медленный старт).\nHTTP/1.1 Появился всего через несколько месяцев после версии 1.1 (в январе 1997 года, RFC 2068, и по 2014 год выходили \u0026ldquo;дополнительные\u0026rdquo; RFC для этой версии протокола), и изменения были следующие:\n Соединение могло быть пере-использовано (не требуется постоянно поднимать новое TCP соединение для запроса, управляется с помощью заголовка Connection: close или Connection: keep-alive) Добавлена поддержка заголовка Host содержащего имя домена, для которого предназначен запрос (опционально и номер порта), что позволило держать на одном IP множество доменов (сайтов) Добавлены методы OPTIONS, TRACE, PATCH, CONNECT (последний добавлен в 2014 году) Добавлено согласование контента (включающее в себя язык Accept-Language: \u0026lt;lang\u0026gt;, кодировку Accept-Encoding: \u0026lt;directives\u0026gt;, тип данных - Accept: \u0026lt;mime_type\u0026gt;/* и другие) Добавлены заголовки управления кэшированием контента (Cache-Control: \u0026lt;directives\u0026gt;, Expires: \u0026lt;http-date\u0026gt;, Last-Modified: \u0026lt;when\u0026gt;, ETag: \u0026lt;hash\u0026gt; и другие) Добавлена возможность доставки контента частями (или чанками, chunks), управляется заголовком Transfer-Encoding: \u0026lt;directives\u0026gt; и другими (в этом случае нет необходимости заранее знать точный размер всего тела HTTP-сообщения); HTTP/2 не поддерживает эту фичу, но имеет другие, более эффективные механизмы для потовой передачи данных Добавлена конвейерная обработка, позволяющая передавать сразу несколько запросов в одном соединении, не ожидая соответствующих ответов (но нужно помнить, что сервер должен отдавать ответы в строго той же последовательности, как получались запросы, и один затормозивший запрос тормозит все последующие в \u0026ldquo;пачке\u0026rdquo;); в HTTP/2 эта фича была заменена на мульти-плексирование Добавлена возможность использования заголовка Upgrade: \u0026lt;protocol\u0026gt;[/\u0026lt;version\u0026gt;] для переключения на другой протокол, например HTTP/2.0 или WebSockets, и эта функциональность присуща только версии HTTP/1.1  GET /en-US/docs/Glossary/Simple_header HTTP/1.1 Host: developer.mozilla.org User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 Accept-Language: en-US,en;q=0.5 Accept-Encoding: gzip, deflate, br Referer: https://developer.mozilla.org/en-US/docs/Glossary/Simple_header 200 OK Connection: Keep-Alive Content-Encoding: gzip Content-Type: text/html; charset=utf-8 Date: Wed, 20 Jul 2016 10:55:30 GMT Etag: \u0026#34;547fa7e369ef56031dd3bff2ace9fc0832eb251a\u0026#34; Keep-Alive: timeout=5, max=1000 Last-Modified: Tue, 19 Jul 2016 00:59:33 GMT Server: Apache Transfer-Encoding: chunked Vary: Cookie, Accept-Encoding (content) HTTP/2 Спецификация (RFC 7540) была опубликована в мае 2015 года, основан на протоколе SPDY (a.k.a \u0026ldquo;speedy\u0026rdquo;, разработан Google в 2012 году, поддержка которого прекратилась в феврале 2015 в пользу HTTP/2; при его использовании время загрузки страниц уменьшалось на ~36%). В 2021 году порядка 50,2% самых популярных сайтов поддерживают этот протокол.\nВ отличии от HTTP/1.1:\n Протокол стал бинарным (сообщения быстрее разбираются автоматически, но неудобны для чтения человеком), основные составляющие HTTP/2 — фреймы (Frames) и потоки (Streams):  HTTP-сообщения состоят из одного или более фреймов (HEADERS для мета-данных, DATA для данных, RST_STREAM для прерывания потоков - при этом соединение останется открытым что позволяет работать остальным потокам, SETTINGS, PRIORITY и другие) Каждый запрос и ответ HTTP/2 получает уникальный ID потока и разделяется на фреймы Фреймы представляют собой просто бинарные части данных; коллекция фреймов называется потоком (Stream) Каждый фрейм содержит ID потока, показывающий, к какому потоку он принадлежит; а также каждый фрейм содержит общий заголовок (идентификатор потока уникален; каждый клиентский запрос использует нечётные id, а ответ от сервера — чётные)   Добавлено мультиплексирование - передача нескольких асинхронных HTTP-запросов по одному TCP-соединению  Ответ сервера не имеет порядка, и клиент использует ID потока, чтобы понять, к какому потоку принадлежит тот или иной пакет Клиенту не придётся простаивать, ожидая обработки длинного запроса, ведь во время ожидания могут обрабатываться остальные запросы   Реализовано сжатие передаваемых заголовков (методом HPACK)  Клиент и сервер поддерживают единую таблицу заголовков Повторяющиеся заголовки (например, user-agent) опускаются при повторных запросах и ссылаются на их позицию в таблице заголовков Сами заголовки ничем не отличаются от HTTP/1.1, но добавились псевдо-заголовки вида :method, :scheme, :host, :path   Появился Server Push - несколько ответов на один запрос  Сервер имеет право послать то содержимое, которое ещё не было запрошено клиентом, используя специальный фрейм PUSH_PROMISE   Добавлена явная приоритизация запросов (используя фрейм HEADERS которым открывается поток, или в любое другое время используя фрейм PRIORITY) Повышена безопасность (хотя спецификация не требует шифрования для HTTP/2, оно всё равно станет обязательным по умолчанию, так как браузеры без шифрования не работают с этим протоколом)  Так же стоит знать, что мультиплексирование ведёт к проблеме доставки контента при ошибках на сетевом уровне. Представьте, что мы асинхронно выполняем 5 запросов к одному серверу. При использовании HTTP/2 все эти запросы будут выполняться в рамках одного TCP-соединения, а значит, если один из сегментов любого запроса потеряется или придёт неверно, передача всех запросов и ответов остановится, пока не будет восстановлен потерявшийся сегмент (у этой проблемы есть и название - \u0026ldquo;head-of-line blocking\u0026rdquo;). Очевидно, что чем хуже качество соединения, тем медленнее работает HTTP/2 (когда потерянные пакеты составляют всего 2% от всех, HTTP/1.1 в браузере показывает себя лучше, чем HTTP/2 за счёт того, что открывает 6 соединений, а не одно).\nHTTP/3 Проектируется для решения проблем HTTP/2 и сейчас проходит тестирование с опубликованной спецификацией. Новый протокол должен решать текущие проблемы скорости, надёжности и безопасности для широкого сектора устройств. HTTP/3 строится на основе нового протокола QUIC, разрабатываемого в Google с 2012 года. Основные отличия от предшественника:\n Вместо TCP будет использоваться UDP QUIC сам обеспечивает мультплексирование, и потеря одного пакета повлияет только на имеющий к этому пакету поток, другие потоки в рамках соединения продолжат свою работу Заголовки запросов и ответов сжимаются QPACK вместо HPACK Для шифрования используется TLS 1.3 (эффективно использующийся в HTTPS) - оно включено в протокол  Это позволяет устанавливать соединение и обмениваться публичными ключами за одно рукопожатие, а также позволяет использовать хитрый механизм 0-RTT handshake и вообще избежать задержек при рукопожатии Кроме того, теперь можно шифровать отдельные пакеты данных (это позволяет не ждать завершения приёма данных из стрима, а расшифровывать полученные пакеты независимо)   Концепция лёгких стримов позволяет отвязать соединение от IP-адреса клиента (например, когда клиент переключается с одной Wi-Fi точки доступа на другую, изменяя свой IP - при использовании TCP происходит длительный процесс, в ходе которого существующие TCP-соединения отваливаются по таймауту; в случае с QUIC, клиент просто продолжает посылать серверу пакеты с нового IP со старым ID стрима) QUIC реализуется на уровне приложения, а не операционной системы (позволяет быстрее вносить изменения в протокол, т.к. чтобы получить обновление достаточно просто обновить библиотеку, а не ждать новую версию ОС)  Последние версии браузеров Chrome, Firefox, Edge, Opera и некоторые мобильные браузеры уже поддерживают работу по HTTP/3, но для работы должна быть и поддержка со стороны сервера. На данный момент HTTP/3 активно используется в Google и Cloudflare.\nПо статистике на июль 2021 года только 20% вебсайтов доступны по HTTP/3. По отчетам Google через gQUIC страницы загружаются примерно на 5% быстрее, а в потоковом видео на 30% меньше подвисаний по сравнению с TCP.\nК слабым сторонам протокола пока что можно отнести высокое потребление CPU, жадность (unfairness) к пропускной способности канала и более медленная передача небольших (до 10 кб) объектов. А так же неготовность интернета к полному переходу на UDP.\n Что можно почитать:\n Evolution of HTTP Путь к HTTP/2 HTTP/3: прошлое, настоящее и будущее Введение в HTTP/2   Как работает HTTPS? Проблема протокола HTTP в том, что данные передаются по сети в открытом незашифрованном виде. Это позволяет злоумышленнику слушать передаваемые пакеты и извлекать любую информацию из параметров, заголовков и тела сообщения. Для устранения уязвимости был разработан HTTPS (S в конце значит Secure) - он, хоть не является отдельным протоколом, всего лишь HTTP поверх SSL (а позже TLS), позволяет безопасно обмениваться данными. В отличие от HTTP со стандартным TCP/IP портом 80, для HTTPS используется порт 443.\nДля того, чтоб ваш сервер был доступен по https необходимо выпустить сертификат, подписанный центром сертификации (который является доверенным), и сконфигурировать используемое ПО на его использование.\nSSL Secure Sockets Layer (SSL) - это криптографический протокол, обеспечивающий безопасное общение пользователя и сервера по небезопасной сети. Располагается между транспортным уровнем и уровнем программы-клиента (FTP, HTTP и т.п.). С 2015 года признан полностью устаревшим.\nTLS Transport Layer Security - это развитие идей, заложенных в протоколе SSL. На данный момент актуальной является версия TLSv1.3. Протокол обеспечивает услуги: приватности (сокрытие передаваемой информации), целостности (обнаружение изменений), аутентификации (проверка авторства). Достигаются они за счет гибридного шифрования, то есть совместного использования ассиметричного и симметричного шифрования.\nШифрование Симметричное шифрование предполагает наличие общего ключа одновременно у отправителя и получателя, с помощью которого происходит шифровка и дешифровка данных.\nПри использовании ассиметричного шифрования существует открытый ключ, который можно свободно распространять, и закрытый ключ, который держится в секрете у одной из сторон. Этот тип работает медленно, относительно симметричного шифрования, однако скомпрометировать закрытый ключ сложнее.\nЧтобы решить проблему производительности (шифровать ассиметрично абсолютно все - сложно), в TLS используется гибридное шифрование - общий ключ для симметричного шифрования данных передается от клиента серверу зашифрованным открытым ключом сервера, после этого сервер может его расшифровать своим закрытым ключом и использовать для обмена данными с клиентом.\nДля установки безопасного соединения происходит TLS Handshake, который схематично выглядит следующим образом:\n Что можно почитать:\n Основы HTTPS, TLS, SSL  ","date":"2022-02-14T12:37:08Z","image":"https://blog.hook.sh/interview-section-network/cover_hu21de3eef183cf18e204d3e54b899aa35_31715_120x120_fill_box_smart1_3.png","permalink":"https://blog.hook.sh/interview-section-network/","title":"Вопросы и ответы по сетям и протоколам"},{"content":"В этой заметки содержатся (и, возможно, будут периодически добавляться) задачи на лайв-кодинг для Go разработчиков, что встречаются на интервью, либо являются хорошими кандидатами для этого.\nЛучше всего чтоб ты самостоятельно попытался решить эти задачи, и только для проверки результата смотрел код готовых решений.\n Найти пересечение двух неупорядоченных слайсов любой длины Развернуть односвязный список Написать генератор случайных чисел Слить N каналов в один Сделать конвейер чисел Сделать кастомную WaitGroup на семафоре Алгоритм бинарного (двоичного) поиска Обход ссылок из файла    Найти пересечение двух неупорядоченных слайсов любой длины Перечесение - это те элементы, что присутствуют в обоих слайсах, то есть:\n f([]int{1, 2, 2, 1}, []int{2, 2}) == []int{2, 2} f([]int{4, 9, 5}, []int{9, 4, 9, 8, 4}) == []int{4, 9} or []int{9, 4}  Можно решить сортировкой, за более долгое время, но без выделения дополнительной памяти. А можно выделить дополнительную память и решить за линейное время:\nРешение  package main import \u0026#34;fmt\u0026#34; func intersection(one, two []int) []int { var m = make(map[int]uint) // не делаем пре-аллокацию, так как не знаем количество дублей  for i := range one { // пробегаясь по первому слайсу \u0026#34;прогреваем\u0026#34; карту  m[one[i]]++ // так как нулевое значение для uint это 0 - то просто увеличиваем \t} var result = make([]int, 0) // тоже без пре-аллокации, т.к. не знаем сколько пересечений  for i := range two { // пробегаясь по второму - ищем пересечение \tif value, ok := m[two[i]]; ok { if value \u0026gt; 0 { m[two[i]]-- result = append(result, two[i]) } else { delete(m, two[i]) // прибираемся, так как ключ уже не нужен (== 0) \t} } } return result } func main() { fmt.Printf(\u0026#34;%v\\n\u0026#34;, intersection([]int{23, 3, 1, 2}, []int{6, 2, 4, 23})) // [2, 23]  fmt.Printf(\u0026#34;%v\\n\u0026#34;, intersection([]int{1, 1, 1}, []int{1, 1, 1, 1})) // [1, 1, 1] }    Сложность этого решения получается O(n+m) где n - это длина первого слайса и m второго (сложность вставки в мапу O(1); поиска тоже, чаще всего).\nИли вот универсальный вариант, что ищет пересечение в неограниченном количестве слайсов на входе:\nУниверсальное решение  package main import \u0026#34;fmt\u0026#34; func intersection(in ...[]int) []int { var result = make([]int, 0) if len(in) \u0026lt; 2 { return result } var longestSliceIdx = 0 for i := 0; i \u0026lt; len(in); i++ { // находим самый длинный слайс  if len(in[i]) \u0026gt; len(in[longestSliceIdx]) { longestSliceIdx = i } } var m = make([]map[int]uint, len(in)-1) // слайс из мап для счётчиков значений  for i, j := 0, 0; i \u0026lt; len(in); i++ { // \u0026#34;прогреваем\u0026#34; мапы по каждому полученному слайсу  if i == longestSliceIdx { // кроме самого длинного  continue } m[j] = make(map[int]uint) for _, k := range in[i] { m[j][k]++ } j++ } valuesLoop: for _, value := range in[longestSliceIdx] { // проходимся по всем значениям из самого длинного слайса  for _, mmap := range m { // пробегаемся по всем мапам, что хранят количество вхождений  if count, ok := mmap[value]; ok { // и если в карте найдено значение из самого длинного слайса  if count \u0026gt; 0 { // и его счётчик больше нуля  mmap[value]-- // то уменьшаем его счётчик и НЕ прерываем цикл  } else { // если значения есть и оно == 0  delete(mmap, value) // то удаляем его (прибираемся)  continue valuesLoop // и переходим к следующему значению (не ищем во всех мапах)  } } else { continue valuesLoop // если значения в мапе нет, то и в других мапах искать нет смысла  } result = append(result, value) } } return result } func main() { fmt.Printf(\u0026#34;%v\\n\u0026#34;, intersection([]int{23, 3, 1, 2}, []int{6, 2, 4, 23})) // [23, 2]  fmt.Printf(\u0026#34;%v\\n\u0026#34;, intersection([]int{1, 1, 1}, []int{1, 1, 1, 1})) // [1, 1, 1]  fmt.Printf(\u0026#34;%v\\n\u0026#34;, intersection([]int{1, 2, 2, 1}, []int{2, 2})) // [2, 2]  fmt.Printf(\u0026#34;%v\\n\u0026#34;, intersection([]int{4, 9, 5}, []int{9, 4, 9, 8, 4})) // [9, 4] }    Развернуть односвязный список Односвязный список (single linked list) может быть представлен структурой:\ntype LinkNode struct { next *LinkNode value int } Нужно создать три элемента, и связать их последовательно. А после развернуть этот список в обратную сторону.\nРешение  package main type LinkNode struct { next *LinkNode value int } func (l *LinkNode) Print() { // ставим current указателем на первый элемент, на каждой итерации заменяя его на next \t// до тех пор, пока current не станет nil \tfor current := l; current != nil; current = current.next { print(current.value) if current.next != nil { println(\u0026#34; -\u0026gt;\u0026#34;, current.next.value) } } println() } func main() { // инициализируем элементы списка \tvar n1, n2, n3 = LinkNode{value: 1}, LinkNode{value: 2}, LinkNode{value: 3} n1.next, n2.next = \u0026amp;n2, \u0026amp;n3 // и связываем их  n1.Print() // 1 -\u0026gt; 2 \t// 2 -\u0026gt; 3 \t// 3  // и теперь обратим список в зад \tvar prev, next *LinkNode // крутим цикл до тех пор, пока current не станет nil \tfor current := \u0026amp;n1; current != nil; { next, current.next = current.next, prev prev, current = current, next } n3.Print() // 3 -\u0026gt; 2 \t// 2 -\u0026gt; 1 \t// 1 }    Написать генератор случайных чисел Легкая задача, на базовые знания по асинхронному взаимодействию в Go. Главная особенность - не выделять память заранее под случайные числа, так как их могут быть миллионы (в этом же и есть весть смысл генератора). Функция RandomGen возвращает канал, в который пишутся случайные сислы и функцию, которая генератор останавливает, освобождая все необходимые ресурсы:\nРешение  package main import ( \u0026#34;math/rand\u0026#34; \u0026#34;sync/atomic\u0026#34; \u0026#34;time\u0026#34; ) func RandomGen() (\u0026lt;-chan int, func()) { var ( rnd = rand.New(rand.NewSource(time.Now().UnixNano())) out, exit = make(chan int), make(chan struct{}) exited uint32 // atomic usage only  ) go func() { defer close(out) // уходя гасим за собой свет (закрываем канал)  for { select { case \u0026lt;-exit: // закрытие канала exit вызовет этот case  return case out \u0026lt;- rnd.Int(): // пока канал exit не закрыт - отправляем  // do nothing  } } }() return out, func() { // вызов функции закроет канал exit  if atomic.CompareAndSwapUint32(\u0026amp;exited, 0, 1) { // защита от повторного вызова  close(exit) } } } func main() { rnd, stop := RandomGen() defer stop() // можно вызвать несколько раз - ничего страшного  for i := 0; i \u0026lt; 3; i++ { println(\u0026lt;-rnd) // выведет 3 случайных числа  } stop() // останавливаем генератор  println(\u0026lt;-rnd, \u0026lt;-rnd) // вернёт дважды 0 }    Слить N каналов в один Даны n каналов типа chan int. Надо написать функцию, которая смерджит все данные из этих каналов в один и вернет его. Мы хотим, чтобы результат работы функции выглядел примерно так:\npackage main func main() { var a, b, c = make(chan int), make(chan int), make(chan int) // ...  for num := range joinChannels(a, b, c) { println(num) } } Для этого создаём канал для смердженных данных, запускаем N горутин для чтения из каналов (по количеству каналов), и используем дополнительный канал для того, чтоб определить когда у нас работа будет завершена (эдакий аналог sync.WaitGroup):\nРешение  package main func joinChannels(in ...\u0026lt;-chan int) \u0026lt;-chan int { var ( out = make(chan int, len(in)) done = make(chan struct{}) // канал для пустых сообщений, аналог sync.WaitGroup  ) for i := 0; i \u0026lt; len(in); i++ { // запускаем горутины по кол-ву каналов на входе  go func(c \u0026lt;-chan int) { defer func() { done \u0026lt;- struct{}{} }() // по завершению работы пишем в канал \u0026#34;done\u0026#34;  for { value, isOpened := \u0026lt;-c if !isOpened { // если канал закрылся - то выходим  return } out \u0026lt;- value // иначе пишем в результирующий канал  } }(in[i]) } go func() { // запускаем отдельную горутину, которая ожидает завершения работы  for i := 0; i \u0026lt; len(in); i++ { // с помощью этого счётчика  \u0026lt;-done // который N раз просто читает пустую структуру и блокируется  } close(done) close(out) }() return out } func main() { var a, b, c = make(chan int), make(chan int), make(chan int) go func() { for _, num := range []int{1, 2, 3} { a \u0026lt;- num } close(a) }() go func() { for _, num := range []int{20, 10, 30} { b \u0026lt;- num } close(b) }() go func() { for _, num := range []int{300, 200, 100} { c \u0026lt;- num } close(c) }() for num := range joinChannels(a, b, c) { println(num) // 1, 2, 3, 20, 10, 300, 200, 30, 100  } }    Сделать конвейер чисел Даны два канала. В первый пишутся числа. Нужно, чтобы числа читались из первого по мере поступления, что-то с ними происходило (допустим, возводились в квадрат) и результат записывался во второй канал. Задача пердельно простая.\nРешение  package main func main() { var in, out = make(chan int), make(chan int) go func() { for i := 0; i \u0026lt; 10; i++ { in \u0026lt;- i } close(in) }() go func() { defer close(out) for { num, isOpened := \u0026lt;-in if !isOpened { return } out \u0026lt;- num * num } }() for num := range out { println(num) } }    Сделать кастомную WaitGroup на семафоре  Семафо́р (англ. semaphore) — примитив синхронизации работы процессов и потоков, в основе которого лежит счётчик, над которым можно производить две атомарные операции: увеличение и уменьшение значения на единицу, при этом операция уменьшения для нулевого значения счётчика является блокирующейся.\n Семафор можно легко получить из канала. Чтоб не аллоцировать лишние данные, будем складывать туда пустые структуры.\nРешение  package main type Semaphore chan struct{} func (s Semaphore) Increment(n int) { for i := 0; i \u0026lt; n; i++ { s \u0026lt;- struct{}{} } } func (s Semaphore) Decrement(n int) { for i := 0; i \u0026lt; n; i++ { \u0026lt;-s } } func main() { const count = 5 var s = make(Semaphore, count) for i := 0; i \u0026lt; count; i++ { go func(n int) { defer s.Increment(1) print(n, \u0026#34; \u0026#34;) }(i) } s.Decrement(count) // 1 4 3 2 0 (порядок будет произвольный) }    Решение с использованием atomic и каналов, полностью повторяет API sync.WaitGroup  package main import ( \u0026#34;sync\u0026#34; \u0026#34;sync/atomic\u0026#34; ) type WaitGroup struct { state int32 // atomic usage only  subsMu sync.Mutex subs []chan struct{} } func NewWaitGroup() WaitGroup { return WaitGroup{subs: make([]chan struct{}, 0)} } func (wg *WaitGroup) Add(n uint) { atomic.AddInt32(\u0026amp;wg.state, int32(n)) } func (wg *WaitGroup) Done() { if atomic.AddInt32(\u0026amp;wg.state, -1); atomic.LoadInt32(\u0026amp;wg.state) \u0026lt;= 0 { wg.subsMu.Lock() if wg.subs != nil { for i := 0; i \u0026lt; len(wg.subs); i++ { close(wg.subs[i]) // закрытие \u0026#34;стриггерит\u0026#34; все каналы  } wg.subs = nil } wg.subsMu.Unlock() } } func (wg *WaitGroup) Wait() { if atomic.LoadInt32(\u0026amp;wg.state) \u0026gt; 0 { var c = make(chan struct{}) wg.subsMu.Lock() wg.subs = append(wg.subs, c) wg.subsMu.Unlock() \u0026lt;-c // ожидаем закрытия канала (блокируемся)  } return } func main() { var wg = NewWaitGroup() wg.Wait() // пролетает сразу же, так как не было вызовов Add()  wg.Add(2) wg.Add(0) // ничего не делает  wg.Done() wg.Done() wg.Wait() // тоже пролетает сразу же  for i := 0; i \u0026lt; 5; i++ { wg.Add(1) go func(n int) { defer wg.Done() print(n, \u0026#34; \u0026#34;) }(i) } wg.Wait() // 1 4 3 2 0 (порядок будет произвольный) }    Алгоритм бинарного (двоичного) поиска Также известен как метод деления пополам или дихотомия - классический алгоритм поиска элемента в отсортированном массиве (слайсе), использующий дробление массива (слайса) на половины. У нас на входе может быть слайс вида []int{1, 3, 4, 6, 8, 10, 55, 56, 59, 70, 79, 81, 91, 10001}, и нужно вернуть индекс числа 55 (результат будет 6 true):\nРешение  package main func BinarySearch(in []int, searchFor int) (int, bool) { if len(in) == 0 { return 0, false } var first, last = 0, len(in) - 1 for first \u0026lt;= last { var mid = ((last - first) / 2) + first if in[mid] == searchFor { return mid, true } else if in[mid] \u0026gt; searchFor { // нужно искать в \u0026#34;левой\u0026#34; части слайса \tlast = mid - 1 } else if in[mid] \u0026lt; searchFor { // нужно искать в \u0026#34;правой\u0026#34; части слайса \tfirst = mid + 1 } } return 0, false }    Обход ссылок из файла Дан некоторый файл, в котором содержатся HTTP ссылки на различные ресурсы. Нужно реализовать обход всех этих ссылок, и вывести в терминал OK в случае 200-го кода ответа, и Not OK в противном случае. Засучаем рукава и в бой, пишем наивный вариант (читаем файл в память, и итерируем слайс ссылок):\nПервая итерация  package main import ( \u0026#34;bufio\u0026#34; \u0026#34;context\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; ) func main() { if err := run(); err != nil { println(err.Error()) os.Exit(1) } } func run() error { var ctx = context.Background() // открываем файл  f, err := os.Open(\u0026#34;links_list.txt\u0026#34;) if err != nil { return err } defer func() { _ = f.Close() }() // читаем файл построчно  var scan = bufio.NewScanner(f) for scan.Scan() { var url = strings.TrimSpace(scan.Text()) if ok, fetchErr := fetchLink(ctx, http.MethodGet, url); fetchErr != nil { return fetchErr } else { if ok { println(\u0026#34;OK\u0026#34;, url) } else { println(\u0026#34;Not OK\u0026#34;, url) } } } // проверяем сканер на наличие ошибок  if err = scan.Err(); err != nil { return err } return nil } // объявляем HTTP клиент для переиспользования var httpClient = http.Client{Timeout: time.Second * 5} func fetchLink(ctx context.Context, method, url string) (bool, error) { // создаём объект запроса  var req, err = http.NewRequestWithContext(ctx, method, url, http.NoBody) if err != nil { return false, err } // выполняем его  resp, err := httpClient.Do(req) if err != nil { return false, err } // валидируем статус код  if resp.StatusCode == http.StatusOK { return true, nil } return false, nil }    Файл со списком ссылок (links_list.txt):\nhttps://www.yahoo.com/foobar https://stackoverflow.com/foobar https://blog.hook.sh/ https://google.com/404error https://ya.ru/ https://github.com/foo/bar https://stackoverflow.com/ Запускаем код (go run .), видим результат:\nNot OK https://www.yahoo.com/foobar Not OK https://stackoverflow.com/foobar OK https://blog.hook.sh/ Not OK https://google.com/404error OK https://ya.ru/ Not OK https://github.com/foo/bar OK https://stackoverflow.com/ И тут интервьювер обновляет постановку задачи - нужно выполнять работу асинхронно. И сделать так, чтоб после получения двух OK останавливать всю работу, отменяя уже отправленные запросы. Приводим свой код в соответствие, используя каналы по-максимуму:\nВторая итерация  package main import ( \u0026#34;bufio\u0026#34; \u0026#34;context\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; ) func main() { if err := run(); err != nil { println(\u0026#34;Fatal error:\u0026#34;, err.Error()) os.Exit(1) } } type result struct { // объявляем структуру для описания результата опроса URL  url string ok bool } func run() error { var ctx, cancel = context.WithCancel(context.Background()) // заменяем контекст на контекст с отменой  defer cancel() f, err := os.Open(\u0026#34;links_list.txt\u0026#34;) if err != nil { return err } defer func() { _ = f.Close() }() var urlsCh, errCh, resultsCh = make(chan string), make(chan error), make(chan result) // объявляем каналы для работы  defer func() { close(errCh); close(resultsCh) }() go func() { // читаем файл построчно в отдельной горутине и пишем в каналы (запускаем \u0026#34;планировщик\u0026#34;)  defer close(urlsCh) // не забываем закрыть канал (когда список кончится или контекст отменится)  var scan = bufio.NewScanner(f) for scan.Scan() { select { case \u0026lt;-ctx.Done(): // проверяем контекст на факт его отмены  return default: if url := strings.TrimSpace(scan.Text()); url != \u0026#34;\u0026#34; { urlsCh \u0026lt;- url // и пишем в канал для ссылок по одной  } } } if err = scan.Err(); err != nil { errCh \u0026lt;- err } }() const workersCount uint8 = 4 // объявляем константу с количеством \u0026#34;воркеров\u0026#34;  var progress, done = make(chan struct{}), make(chan struct{}) // каналы для сообщений о ходе работы и её завершении  defer close(done) go func() { // запускаем горутину, что будет N раз ничего не делать, а по завершении запишет в канал done  for i := uint8(0); i \u0026lt; workersCount; i++ { \u0026lt;-progress } close(progress) done \u0026lt;- struct{}{} }() for i := uint8(0); i \u0026lt; workersCount; i++ { // запускаем горутины для выполнения HTTP запросов  go func() { defer func() { progress \u0026lt;- struct{}{} }() // когда она завершится, то запишет в канал progress  for { select { case \u0026lt;-ctx.Done(): // так же проверяем контекст на факт его отмены  return case url, isOpened := \u0026lt;-urlsCh: // и читаем из канала для ссылок  if !isOpened { // если он закрыт нашим \u0026#34;планировщиком\u0026#34;  return // то выходим  } if ok, fetchErr := fetchLink(ctx, http.MethodGet, url); fetchErr != nil { errCh \u0026lt;- fetchErr } else if ctx.Err() == nil { // дополнительно проверяем контекст  resultsCh \u0026lt;- result{url: url, ok: ok} // результаты пишем в канал для ответов  } } } }() } var ( okCounter uint // счётчик успешных запросов  lastError error // переменная для последней \u0026#34;пойманной\u0026#34; ошибки  ) loop: for { select { case workingErr, isOpened := \u0026lt;-errCh: // если пришла ошибка (при чтении файла или HTTP)  if isOpened \u0026amp;\u0026amp; !errors.Is(workingErr, context.Canceled) { // игнорируем ошибку \u0026#34;отмены контекста\u0026#34;  lastError = workingErr // то сохраняем её в lastError  cancel() // и отменяем контекст (чтоб горутины завершились) но не прерываем цикл  } case res := \u0026lt;-resultsCh: // если пришел результат от воркера  if res.ok { okCounter++ println(\u0026#34;OK\u0026#34;, res.url) } else { println(\u0026#34;Not OK\u0026#34;, res.url) } if okCounter \u0026gt;= 2 { // а вот как раз и наше условие для отмены  cancel() } case \u0026lt;-done: // и выход из цикла обязательно должен осуществится после сообщения в done  println(\u0026#34;work is done\u0026#34;) break loop // только тут прерываем цикл, так как горутины все вышли и никто не напишет в закрытые каналы  } } return lastError } // объявляем HTTP клиент для переиспользования var httpClient = http.Client{Timeout: time.Second * 5} func fetchLink(ctx context.Context, method, url string) (bool, error) { // создаём объект запроса  var req, err = http.NewRequestWithContext(ctx, method, url, http.NoBody) if err != nil { return false, err } // выполняем его  resp, err := httpClient.Do(req) if err != nil { return false, err } // валидируем статус код  if resp.StatusCode == http.StatusOK { return true, nil } return false, nil }   ","date":"2022-02-08T06:47:03Z","image":"https://blog.hook.sh/interview-section-golang-coding/cover_hu6c745680144d0a85df5a67b80461116c_57776_120x120_fill_box_smart1_3.png","permalink":"https://blog.hook.sh/interview-section-golang-coding/","title":"Задачи и решения для лайв-кодинга на Go"},{"content":"Структурирование информации - очень полезный навык. И дабы привнести некоторый порядок в этап подготовки к интервью на должность Golang разработчика (и немножко техлида) решил записывать в этой заметке в формате FAQ те вопросы, которые я задавал, задавали мне или просто были мной найдены на просторах сети вместе с ответами на них. Стоит относиться к ним как к шпаргалке (если затупишь на реальном интервью - будет где подсмотреть) и просто набору тем, которым тебе стоит уделить внимание.\n Расскажи о себе? Расскажи о своем самом интересном проекте? Кем был создан язык, какие его особенности?  Go - императивный или декларативный? А в чем разница?   Что такое ООП? Как это сделано в Golang?  Как устроено инвертирование зависимостей? Как сделать свои методы для стороннего пакета?   Типы данных и синтаксис  Как устроены строки в Go? В чём ключевое отличие слайса (среза) от массива?  Как вы отсортируете массив структур по алфавиту по полю Name?   Как работает append в слайсе?  Задача про слайсы #1 Задача про слайсы #2   Какое у слайса zero value? Какие операции над ним возможны? Что можешь рассказать про map?  Как растет map? Что там про поиск? Есть ли у map такие же методы как у слайса: len, cap? Какие типы ключей разрешены для ключа в map? Может ли ключом быть структура? Если может, то всегда ли? Что будет в map, если не делать make или short assign? Race condition. Потокобезопасна ли мапа?   Что такое интерфейс?  Как устроен Duck-typing в Go? Интерфейсный тип Пустой interface{} На какой стороне описывать интерфейс - на передающей или принимающей?   Что такое замыкание? Что такое сериализация? Зачем она нужна? Что такое type switch? Какие битовые операции знаешь? Дополнительный блок фигурных скобок в функции Что такое захват переменной? Как работает defer? Как работает init? Прерывание for/switch или for/select Сколько можно возвращать значений из функции? Дженерики - это про что?  Параметризованные функции Параметризованные типы     Память и управление ей  Что такое heap и stack? Где выделяется память под переменную? Можно ли этим управлять? Как работает Garbage Collection (GC) в Go? Какое поведение по умолчанию используется в Go при передаче в функцию? Что можешь рассказать про escape analysis?   Сoncurrency (конкурентность)  Как устроен мьютекс?  В чем отличие sync.Mutex от sync.RWMutex?   Что такое synс.Map? Какие ещё примитивы синхронизации знаешь?  sync.WaitGroup sync.Cond sync.Once sync.Pool   Какие типы каналов существуют?  Что можно делать с закрытым каналом?   Расскажи про планировщик (горутин) Что такое горутина?  В чем отличия горутин от потов ОС? Где аллоцируется память для горутин? Как завершить много горутин?   Кейсы использования контекста  context.WithCancel() context.WithDeadline() context.WithTimeout() context.WithValue()   Как задетектить гонку?   Тестирование  TDT, Table-driven tests (табличное тестирование) Имя пакета с тестами Статические анализаторы (линтеры) Ошибка в бенчмарке Что про функциональное тестирование?   Профилирование (pprof)  Пример использования pprof Так как же профилировщик работает в принципе?   Компилятор  Из каких этапов состоит компиляция? Статическая компиляция/линковка - что это, и в чем особенности? Какие директивы компилятора знаешь?  //go:linkname //go:nosplit //go:norace //go:noinline //go:noescape //go:build //go:generate //go:embed        Расскажи о себе? Чаще всего этот вопрос идёт первым и даёт возможность интервьюверу задать вопросы связанные с твоим резюме, познакомиться с тобой, попытаться понять твой характер для построения последующих вопросов. Следует иметь в виду, что интервьюверу не всегда удается подготовиться к интервью, или он банально не имеет перед глазами твоего резюме. Тут есть смысл ещё раз представиться (часто в мессенджерах используются никнеймы, а твоё реальное имя он мог забыть), назвать свой возраст, образование, рассказать о предыдущих местах работы и должностях, сколько лет в индустрии, какие ЯП и технологии использовал - только \u0026ldquo;по верхам\u0026rdquo;, для того чтоб твой собеседник просто понял с кем он \u0026ldquo;имеет дело\u0026rdquo;.\nРасскажи о своем самом интересном проекте? К этому вопросу есть смысл подготовиться заранее и не спустя рукава. Дело в том, что это тот момент, когда тебе надо подобно павлину распустить хвост и создать правильное первое впечатление о себе, так как этот вопрос чаще всего идёт первым. Возьми и выпиши для себя где-нибудь на листочке основные тезисы о том, что это был за проект/сервис/задача, уделяя основное внимание тому какой профит это принесло для компании/команды в целом. Например:\n Я со своей командой гоферов из N человек в течении трех месяцев создали аналог сервиса у которого компания покупала данные за $4000 в месяц, а после перехода на наш сервис - расходы сократились до $1500 в месяц и значительно повысилось их качество и uptime; Внедренные мной практики в CI/CD пайплайны позволили сократить время на ревью изменений в проектах на 25..40%, а зная сколько стоит время работы разработчиков - вы сами всё понимаете; Разработанный мной сервис состоял из такого-то набора микросервисов, такие-то службы и протоколы использовал, были такие-то ключевые проблемы которые мы так-то зарешали; основной ценностью было то-то.  Кем был создан язык, какие его особенности? Go (часто также golang) - компилируемый многопоточный язык программирования, разработанный внутри компании Google. Разработка началась в 2007 году, его непосредственным проектированием занимались Роберт Гризмер, Роб Пайк и Кен Томпсон. Официально язык был представлен в ноябре 2009 года.\nВ качестве ключевых особенностей можно выделить:\n Простая грамматика (минимум ключевых слов - язык создавался по принципу \u0026ldquo;что ещё можно выкинуть\u0026rdquo; вместо \u0026ldquo;что бы ещё в него добавить\u0026rdquo;) Строгая типизация и отказ от иерархии типов (но с сохранением объектно-ориентированных возможностей) Сборка мусора (GC) Простые и эффективные средства для распараллеливания вычислений Чёткое разделение интерфейса и реализации Наличие системы пакетов и возможность импортирования внешних зависимостей (пакетов) Богатый тулинг \u0026ldquo;из корочки\u0026rdquo; (бенчмарки, тесты, генерация кода и документации), быстрая компиляция  Для того, чтоб вспомнить историю создания Go и о его особенностях можно посмотреть:\n  Go - императивный или декларативный? А в чем разница? Go является императивным языком.\nИмперативное программирование - это описание того, как ты делаешь что-то (т.е. конкретно описываем необходимые действия для достижения определенного результата), а декларативное — того, что ты делаешь (например, декларативным ЯП является SQL - мы описываем что мы хотим получить от СУБД, но не описываем как именно она должна это сделать).\nЧто такое ООП? Как это сделано в Golang? ООП это методология (подход) программирования, основанная на том, что программа представляет собой некоторую совокупность объектов-классов, которые образую иерархию наследования. Ключевые фишки - минимализация повторяемости кода (принцип DRY) и удобство понимания/управления. Фундаментом ООП можно считать идею описания объектов в программировании подобно объектам из реального мира - у них есть свойства, поведение, они могут взаимодействовать. Мы (люди) так понимаем мир, и нам (людям) так проще описывать всякие штуки в коде. Основные принципы в ООП:\n  Абстракция вообще присуща для любого программирования, а не только для ООП. По большому счету (топорный, но понятный пример) это про выделение общего и объединение этого в какие-то сущности но без реализации, про контракты. Например - экземпляры абстрактных классов не могут быть созданы (new AbstractClass), но могут содержать абстрактные методы, чтоб разработчик решив наследоваться от этого абстрактного класса их реализовал так, как ему нужно для своих целей (например - ходить в SQL СУБД или файл). Другой пример - это интерфейсы, они же контракты чистой воды - содержат только сигнатуры методов и ни капельки реализации. Но абстракция не ограничивается ими и должна быть умеренной, так как усложняет архитектуру приложения в общем и целом. Опираться следует на интуицию и опыт. Слишком много слоев абстракции (ещё раз - тут дело не ограничивается интерфейсами и абстрактными классами) приводит к переусложнению и головной боли последующего сопровождения продукта. Недостаточная - к сложности внесения изменений и расширению функционала.\n  Инкапсуляция про контроль доступа к свойствам объекта и их динамическая валидация/преобразования. Если метод/свойство должно быть доступно \u0026ldquo;из вне\u0026rdquo; объекта - объявляем публичным, иначе - приватным. Если есть необходимость переопределять его из потомков класса - то защищенным (protected). Python, например, реализуют инкапсуляцию, но не предусматривает возможности сокрытия в принципе; в то время как С++ и Java она просто всюду.\n  Наследование это возможность (барабанная дробь!) наследоваться одним объектам от других, \u0026ldquo;перенимая\u0026rdquo; все методы родительских объектов. Своеобразный вариант Матрешки. Т.е. выделяя в родительских объектах \u0026ldquo;всё общее\u0026rdquo; мы можем не повторяться в реализации частных, а просто \u0026ldquo;наследоваться\u0026rdquo;.\n  Полиморфизм - \u0026ldquo;поли\u0026rdquo; - много, \u0026ldquo;морф\u0026rdquo; - вид. Везде, где есть интерфейсы - подразумевается полиморфизм. Суть - это контракты (интерфейсы), мы можем объявить \u0026ldquo;что-то умеет закрывать себя методом Close()\u0026rdquo;, и нам не важно что именно это будет. Реализаций может быть много, и если это что-то умеет делать то, что нам надо - нам удобнее с этим работать.\n  Тут же можно упомянуть про знание SOLID, а именно:\n  S (single responsibility principle, принцип единственной ответственности) - определенный класс/модуль должен решать только определенную задачу, максимально узко но максимально хорошо (своеобразные UNIX-way). Если для выполнения своей задачи ему требуются какие-то другие ресурсы - они в него должны быть инкапсулированы (это отсылка к принципу инверсии зависимостей).\n  O (open-closed principle, принцип открытости/закрытости) - классы/модули должны быть открыты для расширения, но закрыты для модификации. Должна быть возможность расширить поведение, наделить новым функционалом, но при этом исходный код/логика модуля должна быть неизменной.\n  L (Liskov substitution principle, принцип подстановки Лисков) - поведение наследующих классов не должно противоречить поведению, заданному базовым классом, то есть поведение наследующих классов должно быть ожидаемым для кода.\n  I (interface segregation principle, принцип разделения интерфейса) - много тонких интерфейсов лучше, чем один толстый.\n  D (dependency inversion principle, принцип инверсии зависимостей) - \u0026ldquo;завязываться\u0026rdquo; на абстракциях (интерфейсах), а не конкретных реализациях. Так же (это уже про IoC, но всё же) можно рассказать что если какому-то классу для своей работы требуется функциональность другого - то есть смысл \u0026ldquo;запрашивать\u0026rdquo; её в конструкторе нашего класса используя интерфейс, под который подходит наша зависимость. Таким образом целевая реализация опирается только на интерфейсы (не зависит от реализаций) и соответствует принципу под буквой S.\n  А теперь о том, как это реализовано в Go (наконец-то!).\nВ Go нет классов, объектов, исключений и шаблонов. Нет иерархии типов, но есть сами типы (т.е. возможность описывать свои типы/структуры). Структурные типы (с методами) служат тем же целям, что и классы в других языках. Так же следует упомянуть что структура определяет состояние.\nВ Go нет наследования. Совсем. Но есть встраивание (называемое \u0026ldquo;анонимным\u0026rdquo;, так как Foo в Bar встраивается не под каким-то именем, а без него) при этом встраиваются и свойства, и функции:\nimport \u0026#34;fmt\u0026#34; type Foo struct { name string Surname string } func (f Foo) SayName() string { return f.name } type Bar struct { Foo } func main() { bar := Bar{Foo{name: \u0026#34;one\u0026#34;, Surname: \u0026#34;baz\u0026#34;}} fmt.Println(bar.SayName()) // one \tfmt.Println(bar.Surname) // baz  bar.name = \u0026#34;two\u0026#34; fmt.Println(bar.SayName()) // two } Есть интерфейсы (это типы, которые объявляют наборы методов). Подобно интерфейсам в других языках, они не имеют реализации. Объекты, которые реализуют все методы интерфейса, автоматически реализуют интерфейс (так называемый Duck-typing). Не существует наследования или подклассов или ключевого слова Implements:\nimport \u0026#34;fmt\u0026#34; type Speaker interface { Speak() string } type Foo struct{} func (Foo) Speak() string { return \u0026#34;foo\u0026#34; } type Bar struct{} func (Bar) Speak() string { return \u0026#34;bar\u0026#34; } func main() { var foo, bar Speaker = new(Foo), \u0026amp;Bar{} fmt.Println(foo.Speak()) // foo \tfmt.Println(bar.Speak()) // bar } А примере выше мы объявили переменные foo и bar с явным указанием интерфейсного типа, а так интерфейс это ссылочный тип - то и структуры мы инициализировали указателями на них с использованием new() (что аллоцирует структуру с возвращает указатель на неё) и (или) \u0026amp;.\nИнкапсуляция реализована на уровне пакетов. Имена, начинающиеся со строчной буквы, видны только внутри этого пакета (не являются экспортируемыми). И наоборот - всё, что начинается с заглавной буквы - доступно из-вне пакета. Дешево и сердито.\nПолиморфизм - это основа объектно-ориентированного программирования: способность обрабатывать объекты разных типов одинаково, если они придерживаются одного и того же интерфейса. Интерфейсы Go предоставляют эту возможность очень прямым и интуитивно понятным способом. Пример использования интерфайса был описан выше.\n Что можно почитать:\n ООП в картинках Golang и ООП   Как устроено инвертирование зависимостей? Инвертирование зависимостей позволяет в нашем коде не \u0026ldquo;завязываться\u0026rdquo; на конкретную реализацию (используя, например, интерфейсы), тем самым понижая связанность кода и повышая его тестируемость. Так же сужается зона ответственности конечной структуры/пакета, что повышает его переиспользуемость.\nПринцип инверсии зависимостей (dependency inversion principle) в Go который можно реализовывать следующим образом:\nimport ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; ) type speaker interface { Speak() string } type Foo struct { s speaker // s *Foo - было бы плохо } func NewFoo(s speaker) (*Foo, error) { if s == nil { return nil, errors.New(\u0026#34;speaker is nil\u0026#34;) } return \u0026amp;Foo{s: s}, nil } func (f Foo) SaySomething() string { return f.s.Speak() } func main() { var foo, err = NewFoo(someSpeaker) if err != nil { panic(err) } fmt.Println(foo.SaySomething()) // depends on the speaker implementation } Мы объявляем интерфейс speaker не экспортируемым на нашей, принимающей стороне, и используя псевдо-конструктор NewFoo гарантируем что свойство s будет проинициализировано верным типом (дополнительно проверяя его на nil).\nКак сделать свои методы для стороннего пакета? Например, если мы используем логгер Zap в нашем проекте, и хотим к этому Zap-у прикрутить наши методы - то для этого нам нужно будет создать свою структуру, внутри в неё встраивать логгер Zap-а, и к этой структуре уже прикручивать требуемые методы. Просто \u0026ldquo;навесить сверху\u0026rdquo; функции на сторонний пакет мы не можем.\nТипы данных и синтаксис К фундаментальным типам данных можно отнести:\n Целочисленные - int{8,16,32,64}, int, uint{8,16,32,64}, uint, byte как синоним uint8 и rune как синоним int32. Типы int и uint имеют наиболее эффективный размер для определенной платформы (32 или 64 бита), причем различные компиляторы могут предоставлять различный размер для этих типов даже для одной и той же платформы Числа с плавающей запятой - float32 (занимает 4 байта/32 бита) и float64 (занимает 8 байт/64 бита) Комплексные числа - complex64 (вещественная и мнимая части представляют числа float32) и complex128 (вещественная и мнимая части представляют числа float64) Логические aka bool Строки string  Как устроены строки в Go? В Go строка в действительности является слайсом (срезом) байт, доступным только для чтения. Строка содержит произвольные байты, и у неё нет ёмкости (cap). При преобразовании слайса байт в строку (str := string(slice)) или обратно (slice := []byte(str)) - происходит копирование массива (со всеми следствиями).\nСоздание подстрок работает очень эффективно. Поскольку строка предназначена только для чтения, исходная строка и строка, полученная в результате операции среза, могут безопасно совместно использовать один и тот же массив:\nvar ( str = \u0026#34;hello world\u0026#34; sub = str[0:5] usr = \u0026#34;/usr/kot\u0026#34;[5:] ) print(sub, \u0026#34; \u0026#34;, usr) // hello kot Go использует тип rune (алиас int32) для представления Unicode. Конструкция for ... range итерирует строку посимвольно (а не побайтово, как можно было бы предположить):\nvar str = \u0026#34;привет\u0026#34; println(str, len(str)) // привет 12  for i, c := range str { println(i, c, string(c)) } // 0 1087 п // 2 1088 р // 4 1080 и // 6 1074 в // 8 1077 е // 10 1090 т И мы видим, что для кодирования каждого символа кириллицы используются по 2 байта.\nЭффективным способом работы со строками (когда есть необходимость часто выполнять конкатенацию, например) является использование слайса байт или strings.Builder:\nimport \u0026#34;strings\u0026#34; func main() { // происходит только 1 аллокация при вызове `Grow()` \tvar str strings.Builder str.Grow(12) // сразу выделяем память  str.WriteString(\u0026#34;hello\u0026#34;) str.WriteRune(\u0026#39; \u0026#39;) str.WriteString(\u0026#34;мир\u0026#34;) println(str.String()) // hello мир } И ещё одну важную особенность стоит иметь в виду - это подсчет длины строки (например - для какой-нибудь валидации). Если считать по количеству байт, и строка содержит не только ASCII символы - то количество байт и фактическое количество символов будут расходиться:\nconst str = \u0026#34;hello мир!\u0026#34; println(len(str), utf8.RuneCountInString(str)) // 13 10 Тут дело в том, что для кодирования символов м, и и р используются 2 байта вместо одного. Поэтому len == 13, а фактически в строке лишь 10 символов (пакет utf8, к примеру, нам в помощь).\n Что можно почитать:\n Строка, байт, руна, символ в Golang   В чём ключевое отличие слайса (среза) от массива?  Срез - всегда указатель на массив, массив - значение Срез может менять свой размер и динамически аллоцировать память   В Go не бывает ссылок - но есть указатели. Где говорится про \u0026ldquo;по ссылке\u0026rdquo; имеется в виду \u0026ldquo;по указателю\u0026rdquo;\n Слайсы и массивы в Go это проиндексированные упорядоченные структуры данных последовательностей элементов. Ёмкость массива объявляется в момент его создания, и после изменить её уже нельзя (его длина это часть его типа). Память, необходимая для хранения элементов массива выделяется соответственно сразу при его объявлении, и по умолчанию инициализируется в соответствии с нулевыми значением для типа (fasle для bool, 0 для int, nil для интерфейсов и т.д.). На стеке можно разместить массив объемом 10 MB. В качестве размера можно использовать константы (компилятор должен знать это значение на этапе компиляции, т.е. что-то вида var a [getSize()]int или i := 3; var a [i]int недопустимо):\nconst mySize uint8 = 8 type myArray [mySize]byte var constSized = [...]int{1, 2, 3} // размер сам посчитается исходя из кол-ва эл-ов Кстати, массивы с элементами одного типа но с разными размерами являются разными типами. Массивы не нужно инициализировать явно; нулевой массив - это готовый к использованию массив, элементы которого являются нулями:\nvar a [4]int // [0 0 0 0]  a[0] = 1 // [1 0 0 0] i := a[0] // i == 1 Представление [4]int в памяти - это просто четыре целых значения, расположенных последовательно. Так же следует помнить что в Go массивы передаются по значению, т.е. передавая массив в какую-либо функцию она получает копию массива (для передачи его указателя нужно явно это указывать, т.е. foo(\u0026amp;a)).\nА слайс же это своего рода версия массива но с вариативным размером (структура данных, которая строится поверх массива и предоставляет доступ к элементами базового массива). Слайсы до 64 KB могут быть размещены на стеке. Если посмотреть исходники Go (src/runtime/slice.go), то увидим:\ntype slice struct { array unsafe.Pointer // указатель на массив \tlen int // длина (length) \tcap int // вместимость (capacity) } Для аллокации слайса можно воспользоваться одной из команд ниже:\nvar ( a = []int{} // [] len=0 cap=0 \tb = []int{1, 2} // [1 2] len=2 cap=2 \tc = []int{5: 1} // [0 0 0 0 0 123] len=6 cap=6 \td = make([]int, 5, 10) // [0 0 0 0 0] len=5 cap=10 ) В последнем случае рантайм Go создаст массив из 10 элементов (выделит память и заполнит их нулями) но доступны прямо сейчас нам будут только 5, и установит значения len в 5, а cap в 10. Cap означает ёмкость и помогает зарезервировать место в памяти на будущее, чтобы избежать лишних операций выделения памяти при росте слайса (это ключевой параметр для аллокации памяти, влияет на производительность вставки в срез). При добавлении новых элементов в слайс новый массив для него не будет создаваться до тех пор, пока cap меньше len.\nСлайсы передаются \u0026ldquo;по ссылке\u0026rdquo; (фактически будет передана копия структуры slice со своими len и cap, но указатель на массив array будет тот-же самый). Для защиты слайса от изменений следует передавать его копию:\nvar ( a = []int{1, 2, 0, 0, 1} b = make([]int, len(a)) ) copy(b, a) fmt.Println(a, b) // [1 2 0 0 1] [1 2 0 0 1] Важной особенностью является то, так как \u0026ldquo;под капотом\u0026rdquo; у слайса лежит указатель на массив - при изменении значений слайса они будут изменяться везде, где слайс используется (будь то присвоение в переменную, передача в функцию и т.д.) до момента, пока размер слайса не будет переполнен и не будет выделен новый массив для его значений (т.е. в момент изменения cap слайса всегда происходит копирование данных массива):\nvar ( one = []int{1, 2} // [1 2] \ttwo = one // [1 2] ) two[0] = 123 fmt.Println(one, two) // [123 2] [123 2]  one = append(one, 666) fmt.Println(one, two) // [123 2 666] [123 2]  Что можно почитать:\n Как не наступать на грабли в Go Слайсы в Go: использование и особенности Принцип работы типа slice в GO   Как вы отсортируете массив структур по алфавиту по полю Name? Например, преобразую массив в слайс и воспользуюсь функцией sort.SliceStable:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sort\u0026#34; ) func main() { var arr = [...]struct{ Name string }{{Name: \u0026#34;b\u0026#34;}, {Name: \u0026#34;c\u0026#34;}, {Name: \u0026#34;a\u0026#34;}} // ^^^^^^^^^^^^^^^^^^^^^ анонимная структура с нужным нам полем  fmt.Println(arr) // [{b} {c} {a}]  sort.SliceStable(arr[:], func(i, j int) bool { return arr[i].Name \u0026lt; arr[j].Name }) // ^^^ вот тут вся \u0026#34;магия\u0026#34; - из массива сделали слайс  fmt.Println(arr) // [{a} {b} {c}] } Вся магия в том, что при создании слайса из массива \u0026ldquo;под капотом\u0026rdquo; у слайса начинает лежать исходный массив, и функции из пакета sort нам становятся доступны над ними. Т.е. изменяя порядок элементов в слайсе функцией sort.SliceStable мы будем менять их в нашем исходном массиве.\nКак работает append в слайсе? append() делает простую операцию - добавляет элементы в слайс и возвращает новый. Но под капотом там делаются довольно сложные манипуляции, чтобы выделять память только при необходимости и делать это эффективно.\nСперва append сравнивает значения len и cap у слайса. Если len меньше чем cap, то значение len увеличивается, а само добавляемое значение помещается в конец слайса. В противном случае происходит выделение памяти под новый массив для элементов слайса, в него копируются значения из старого, и значение помещается уже в новый массив.\nУвеличении размера слайса (метод growslice) происходит по следующему алгоритму - если его размер менее 1024 элементов, то его размер будет увеличиваться вдвое; иначе же слайс увеличивается на ~12.5% от своего текущего размера.\nЧто важно помнить - если на основании слайса one выделить подслайс two, а затем увеличим слайс one (и его вместимость будет превышена) - то one и two будут уже ссылаться на разные участки памяти!\nvar ( one = make([]int, 4) // [0 0 0 0] \ttwo = one[1:3] // [0 0] ) one[2] = 11 fmt.Println(one, two) // [0 0 11 0] [0 11] fmt.Printf(\u0026#34;%p %p\\n\u0026#34;, one, two) // 0xc0000161c0 0xc0000161c8  one = append(one, 1) fmt.Printf(\u0026#34;%p %p\\n\u0026#34;, one, two) // 0xc00001c1c0 0xc0000161c8  one[2] = 22 fmt.Println(one, two) // [0 0 22 0 1] [0 11] fmt.Printf(\u0026#34;%p %p\\n\u0026#34;, one, two) // 0xc00001c1c0 0xc0000161c8 Есть еще много примеров добавления, копирования и других способов использования слайсов тут - Slice Tricks.\n Что можно почитать:\n Как не наступать на грабли в Go   Задача про слайсы #1 Вопрос: У нас есть 2 функции - одна делает append() чего-то в слайс, а другая просто сортирует слайс, используя пакет sort. Модифицируют ли слайс первая и (или) вторая функции?\nОтвет: append() не модифицирует а возвращает новый слайс, а sort модифицирует порядок элементов, если он изначально был не отсортирован.\nЗадача про слайсы #2 Вопрос: Что выведет следующая программа?\npackage main import \u0026#34;fmt\u0026#34; func main() { a := [5]int{1, 2, 3, 4, 5} t := a[3:4:4] fmt.Println(t[0]) } Ответ  Выведет 4   Объяснение: Такой синтаксис позволяет задать capacity (вместимость) для полученного под-слайса, который будет равен \u0026ldquo;последний элемент минус первый элемент из выражения в квадратных скобках\u0026rdquo;, т.е. из примера выше он будет равен 1 (т.к. от четырёх, т.е. третьего сегмента вычитаем первый, т.е. тройку). Если бы выражение имело вид a[3:4:5], то cap была бы равна 2 (5 - 3 = 2). Но при этом на сами данные он не влияет.\nПоявилась эта штука в Go 1.2.\n Что можно почитать:\n Slicing a slice with slice [a : b : c] Full slice expressions   Какое у слайса zero value? Какие операции над ним возможны? Zero value у слайса всегда nil, а len и cap равны нулю, так как \u0026ldquo;под ним\u0026rdquo; нет инициализированного массива:\nvar a []int println(a == nil, len(a), cap(a)) // true 0 0 a = append(a, 1) println(a == nil, len(a), cap(a)) // false 1 1 Как видно из примера выше - несмотря на то, что a == nil (слайс \u0026ldquo;не инициализирован\u0026rdquo;), с этим слайсом возможна операция append - в этом случае Go самостоятельно создаёт нижележащий массив и всё работает так, как и ожидается. Более того - для полной очистки слайса рекомендуется его присваивать к nil.\nТак же важно помнить, что не делая make для слайса - не получится сделать пре-аллокацию, что часто очень болезненно для производительности.\nЧто можешь рассказать про map? Карта (map или hashmap) - это неупорядоченная коллекция пар вида ключ-значение. Пример:\ntype myMap map[string]int Подобно массивам и слайсам, к элементам мапы можно обратиться с помощью скобок:\nvar m = make(map[string]int) // инициализация  m[\u0026#34;one\u0026#34;] = 1 // запись в мапу  fmt.Println(m[\u0026#34;one\u0026#34;], m[\u0026#34;two\u0026#34;]) // 1 0  Лучше выделить память заранее (передавая вторым аргументом функции make), если известно количество элементов - избежим эвакуаций\n В случае с m[\u0026quot;two\u0026quot;] вернулся 0 так как это является нулевым значением для типа int. Для проверки существования ключа используем конструкцию вида (доступ к элементу карты может вернуть два значения вместо одного) называемую \u0026ldquo;multiple assignment\u0026rdquo;:\nvar m = map[string]int{\u0026#34;one\u0026#34;: 1} v1, ok1 := m[\u0026#34;one\u0026#34;] // чтение v2, ok2 := m[\u0026#34;two\u0026#34;] fmt.Println(v1, ok1) // 1 true fmt.Println(v2, ok2) // 0 false  for k, v := range m { // итерация всех эл-ов мапы \tfmt.Println(k, v) } delete(m, \u0026#34;one\u0026#34;) // удаление  v1, ok1 = m[\u0026#34;one\u0026#34;] fmt.Println(v1, ok1) // 0 false Мапы всегда передаются по ссылке (вообще-то Go не бывает ссылок, невозможно создать 2 переменные с 1 адресом, как в С++ например; но зато можно создать 2 переменные, указывающие на один адрес - но это уже указатели). Если же быть точнее, то мапа в Go - это просто указатель на структуру hmap:\ntype hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/reflectdata/reflect.go. \t// Make sure this stays in sync with the compiler\u0026#39;s definition. \tcount int // # live cells == size of map. Must be first (used by len() builtin) \tflags uint8 B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) \tnoverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details \thash0 uint32 // hash seed  buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. \toldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing \tnevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated)  extra *mapextra // optional fields } Так же структура hmap содержит в себе следующее:\n Количество элементов Количество \u0026ldquo;ведер\u0026rdquo; (представлено в виде логарифма для ускорения вычислений) Seed для рандомизации хэшей (чтобы было сложнее заddosить - попытаться подобрать ключи так, что будут сплошные коллизии) Всякие служебные поля и главное указатель на buckets, где хранятся значения  На картинке схематичное изображение структуры в памяти - есть хэдер hmap, указатель на который и есть map в Go (именно он создается при объявлении с помощью var, но не инициализируется, из-за чего падает программа при попытке вставки). Поле buckets - хранилище пар ключ-значение, таких \u0026ldquo;ведер\u0026rdquo; несколько, в каждом лежит 8 пар. Сначала в \u0026ldquo;ведре\u0026rdquo; лежат слоты для дополнительных битов хэшей (e0..e7 названо e - потому что extra hash bits). Далее лежат ключи и значения как сначала список всех ключей, потом список всех значений.\nПо хэш функции определяется в какое \u0026ldquo;ведро\u0026rdquo; мы кладем значение, внутри каждого \u0026ldquo;ведра\u0026rdquo; может лежать до 8 коллизий, в конце каждого \u0026ldquo;ведра\u0026rdquo; есть указатель на дополнительное, если вдруг предыдущее переполнилось.\nКак растет map? В исходном коде можно найти строчку Maximum average load of a bucket that triggers growth is 6.5. То есть, если в каждом \u0026ldquo;ведре\u0026rdquo; в среднем более 6,5 элементов, происходит увеличение массива buckets. При этом выделяется массив в 2 раза больше, а старые данные копируются в него маленькими порциями каждые вставку или удаление, чтобы не создавать очень крупные задержки. Поэтому все операции будут чуть медленнее в процессе эвакуации данных (при поиске тоже, нам же приходится искать в двух местах). После успешной эвакуации начинают использоваться новые данные.\nИз-за эвакуации данных нельзя и взять адрес мапы - представьте, что мы взяли адрес значения, а потом мапа выросла, выделилась новая память, данные эвакуировались, старые удалились, указатель стал неправильным, поэтому такие операции запрещены.\nЧто там про поиск? Поиск, если разобраться, устроен не так уж и сложно: проходимся по цепочкам \u0026ldquo;ведер\u0026rdquo;, переходя в следующее, если в этом не нашли. Поиск в \u0026ldquo;ведре\u0026rdquo; начинается с быстрого сравнения дополнительного хэша, для которого используется всего 8 бит (вот для чего эти e0...e7 в начале каждого - это \u0026ldquo;мини\u0026rdquo; хэш пары для быстрого сравнения). Если не совпало, идем дальше, если совпало, то проверяем тщательнее - определяем где лежит в памяти ключ, подозреваемый как искомый, сравниваем равен ли он тому, что запросили. Если равен, определяем положение значения в памяти и возвращаем.\nК сожалению, мир не совершенен. Когда имя хешируется, то некоторые данные теряются, так как хеш, как правило, короче исходной строки. Таким образом, в любой реализации хеш таблицы неизбежны коллизии когда по двум ключам получаются одинаковые хеши. Как следствие, поиск может быть дороже чем O(1) (возможно это связано с кешем процессора и коллизиями коротких хэшей), так что иногда выгоднее использовать бинарный поиск по слайсу данных нежели чем поиск в мапе (пишите бенчмарки).\n Что можно почитать:\n Хэш таблицы в Go. Детали реализации Кажется, поиск в map дороже чем O(1)   Есть ли у map такие же методы как у слайса: len, cap? У мапы есть len но нет cap. У нас есть только overflow который указывает \u0026ldquo;куда-то\u0026rdquo; когда мапа переполняется, и поэтому у нас не может быть capacity.\nКакие типы ключей разрешены для ключа в map? Любым сравнимым (comparable) типом, т.е. булевы, числовые, строковые, указатели, канальные и интерфейсные типы, а также структуры или массивы, содержащие только эти типы. Слайсы, мапы и функции использовать нельзя, так как эти типы не сравнить с помощью оператора == или !=.\nМожет ли ключом быть структура? Если может, то всегда ли? Как было сказано выше - структура может быть ключом до тех пор, пока мы в поля структуры не поместим какой-либо слайс, мапу или любой другой non-comparable тип данных (например - функцию).\nЧто будет в map, если не делать make или short assign? Будет паника (например - при попытке что-нибудь в неё поместить), так как любые \u0026ldquo;структурные\u0026rdquo; типы (а мапа как мы знаем таковой является) должны быть инициализированы для работы с ними.\nRace condition. Потокобезопасна ли мапа? Нет, потокобезопасной является sync.Map. Для обеспечения безопасности вокруг мапы обычно строится структура вида:\ntype ProtectedIntMap struct { mx sync.RWMutex m map[string]int } func (m *ProtectedIntMap) Load(key string) (val int, ok bool) { m.mx.RLock() val, ok = m.m[key] m.mx.RUnlock() return } func (m *ProtectedIntMap) Store(key string, value int) { m.mx.Lock() m.m[key] = value m.mx.Unlock() } Что такое интерфейс? Интерфейсы - это инструменты для определения наборов действий и поведения. Интерфейсы - это в первую очередь контракты. Они позволяют объектам опираться на абстракции, а не фактические реализации других объектов. При этом для компоновки различных поведений можно группировать несколько интерфейсов. В общем смысле - это набор методов, представляющих стандартное поведение для различных типов данных.\nКак устроен Duck-typing в Go?  Если это выглядит как утка, плавает как утка и крякает как утка, то это, вероятно, утка и есть.\n Если структура содержит в себе все методы, что объявлены в интерфейсе, и их сигнатуры совпадают - она автоматически удовлетворяет интерфейс.\nТакой подход позволяет полиморфно (полиморфизм - способность функции обрабатывать данные разных типов) работать с объектами, которые не связаны в иерархии наследования. Достаточно, чтобы все эти объекты поддерживали необходимый набор методов.\nИнтерфейсный тип В Go интерфейсный тип выглядит вот так:\ntype iface struct { tab *itab data unsafe.Pointer } Где tab - это указатель на Interface Table или itable - структуру, которая хранит некоторые метаданные о типе и список методов, используемых для удовлетворения интерфейса, а data указывает на реальную область памяти, в которой лежат данные изначального объекта (статическим типом).\nКомпилятор генерирует метаданные для каждого статического типа, в которых, помимо прочего, хранится список методов, реализованных для данного типа. Аналогично генерируются метаданные со списком методов для каждого интерфейса. Теперь, во время исполнения программы, runtime Go может вычислить itable на лету (late binding) для каждой конкретной пары. Этот itable кешируется, поэтому просчёт происходит только один раз.\nЗная это, становится очевидно, почему Go ловит несоответствия типов на этапе компиляции, но кастинг к интерфейсу - во время исполнения.\nЧто важно помнить - переменная интерфейсного типа может принимать nil. Но так как объект интерфейса в Go содержит два поля: tab и data - по правилам Go, интерфейс может быть равен nil только если оба этих поля не определены (faq):\nvar ( builder *strings.Builder stringer fmt.Stringer ) fmt.Println(builder, stringer) // nil nil fmt.Println(stringer == nil) // true fmt.Println(builder == nil) // true  stringer = builder fmt.Println(builder, stringer) // nil nil fmt.Println(stringer == nil) // false (!!!) fmt.Println(builder == nil) // true Пустой interface{} Ему удовлетворяет вообще любой тип. Пустой интерфейс ничего не означает, никакой абстракции. Поэтому использовать пустые интерфейсы нужно в самых крайних случаях.\n Что можно почитать:\n Краш-курс по интерфейсам в Go Реализация интерфейсов в Golang Интерфейсы в Go - как красиво выстрелить себе в ногу   На какой стороне описывать интерфейс - на передающей или принимающей? Многое зависит от конкретного случая, но по умолчанию описывать интерфейсы следует на принимающей стороне - таким образом, ваш код будет меньше зависеть от какого-то другого кода/пакета/реализации.\nДругими словами, если нам в каком-то месте требуется \u0026ldquo;что-то что умеет себя закрывать\u0026rdquo;, или - умеет метод Close() error, или (другими словами) удовлетворят интерфейсу:\ntype something interface { Close() error } То он (интерфейс) должен быть описан на принимающей стороне. Так принимающая сторона не будет ничего знать о том, что именно в неё может \u0026ldquo;прилететь\u0026rdquo;, но точно знает поведение этого \u0026ldquo;чего-то\u0026rdquo;. Таким образом реализуется инверсия зависимости, и код становится проще переиспользовать/тестировать.\nЧто такое замыкание? Замыкания - это такие функции, которые вы можете создавать в рантайме и им будет доступно текущее окружение, в рамках которого они были созданы.\nФункции, у которых есть имя - это именованные функции. Функции, которые могут быть созданы без указания имени - это анонимные функции.\nfunc main() { var text = \u0026#34;some string\u0026#34; var ourFunc = func() { // именованное замыкание \tprintln(text) } ourFunc() // some string \tgetFunc()() // another string } func getFunc() func() { return func() { // анонимное \tprintln(\u0026#34;another string\u0026#34;) } } Замыкания сохраняют состояние. Это означает, что состояние переменных содержится в замыкании в момент декларации. Одна из самых очевидных ловушек - это создание замыканий в цикле:\nvar funcs = make([]func(), 0, 5) for i := 0; i \u0026lt; 5; i++ { funcs = append(funcs, func() { println(\u0026#34;counter =\u0026#34;, i) }) // исправляется так: \t//var value = i \t//funcs = append(funcs, func() { println(\u0026#34;counter =\u0026#34;, value) }) } for _, f := range funcs { f() } // counter = 5 (так все 5 раз)  Что можно почитать:\n Замыкания   Что такое сериализация? Зачем она нужна? Сериализация - это процесс преобразования объекта в поток байтов для сохранения или передачи. Обратной операцией является десериализация (т.е. восстановление объекта/структуры из последовательности байтов). Синонимом можно считать термин \u0026ldquo;маршалинг\u0026rdquo; (от англ. marshal - упорядочивать).\nИз минусов сериализации можно выделить нарушение инкапсуляции, т.е. после сериализации \u0026ldquo;приватные\u0026rdquo; свойства структур могут быть доступны для изменения.\nТипичными примерами сериализации в Go являются преобразование структур в json-объекты. Кроме json существуют различные кодеки типа MessagePack, CBOR и т.д.\nЧто такое type switch? Проверка типа переменной, а не её значения. Может быть в виде одного switch и множеством case:\npackage main func checkType(i interface{}) { switch i.(type) { case int: println(\u0026#34;is integer\u0026#34;) case string: println(\u0026#34;is string\u0026#34;) default: println(\u0026#34;has unknown type\u0026#34;) } } А может в виде if-конструкции:\npackage main func main() { var any interface{} any = \u0026#34;foobar\u0026#34; if s, ok := any.(string); ok { println(\u0026#34;this is a string:\u0026#34;, s) } // а так можно проверить наличие функций у структуры  if closable, ok := any.(interface{ Close() }); ok { closable.Close() } } Какие битовые операции знаешь? Побитовые операторы проводят операции непосредственно на битах числа.\n// Побитовое И/AND (разряд результата равен 1 только тогда, когда оба соответствующих бита операндов равны 1) println(0b111_000 /* 56 */ \u0026amp; 0b011_110 /* 30 */ == 0b011_000 /* 24 */) // Побитовое ИЛИ/OR (разряд результата равен 0 только тогда, когда оба соответствующих бита в равны 0) println(0b111_000 /* 56 */ | 0b011_110 /* 30 */ == 0b111_110 /* 62 */) // Исключающее ИЛИ/XOR (разряд результата равен 1 только тогда, когда только один бит равен 1) println(0b111_000 /* 56 */ ^ 0b011_110 /* 30 */ == 0b100_110 /* 38 */) // Сброс бита AND NOT println(0b111_001 /* 57 */ \u0026amp;^ 0b011_110 /* 30 */ == 0b100_001 /* 33 */) // Сдвиг бита влево println(0b000_001 /* 1 */ \u0026lt;\u0026lt; 3 == 0b001_000 /* 8 */) // Сдвиг бита вправо println(0b000_111 /* 7 */ \u0026gt;\u0026gt; 1 == 0b000_011 /* 3 */) Пример использования простой битовой маски:\ntype Bits uint8 const ( F0 Bits = 1 \u0026lt;\u0026lt; iota // 0b00_000_001 == 1 \tF1 // 0b00_000_010 == 2 \tF2 // 0b00_000_100 == 4 ) func Set(b, flag Bits) Bits { return b | flag } func Clear(b, flag Bits) Bits { return b \u0026amp;^ flag } func Toggle(b, flag Bits) Bits { return b ^ flag } func Has(b, flag Bits) bool { return b\u0026amp;flag != 0 } func main() { var b Bits b = Set(b, F0) b = Toggle(b, F2) for i, flag := range [...]Bits{F0, F1, F2} { println(i, Has(b, flag)) } // 0 true \t// 1 false \t// 2 true }  Что можно почитать:\n О битовых операциях Поразрядные операции   Дополнительный блок фигурных скобок в функции Его можно использовать, и он означает отдельный скоуп для всех переменных, объявленных в нём (возможен и \u0026ldquo;захват переменных\u0026rdquo; объявленных вне скоупа ранее, естественно). Иногда используется для декомпозиции какого-то отдельного куска функции, к примеру.\nvar i, s1 = 1, \u0026#34;foo\u0026#34; { var j, s2 = 2, \u0026#34;bar\u0026#34; println(i, s1) // 1 foo \tprintln(j, s2) // 2 bar  s1 = \u0026#34;baz\u0026#34; } println(i, s1) // 1 baz //println(j, s2) // ERROR: undefined: j and s2 Так же это может быть связано с AST (Abstract Syntax Tree) - когда оно строится и происходят SSA (Static Single Assignment) оптимизации, к сожалению SSA не работает на всю длину дерева. Как следствие, если у нас слишком длинная функция (примерно дохулион строк) и мы по каким-то причинам не можем её декомпозировать, но можем изолировать какие-то скоупы то, таким образом, мы помогаем SSA произвести оптимизации (если они возможно).\nЧто такое захват переменной? Во вложенном скоупе есть возможность обращаться к переменным, объявленных в скоупе выше (но не наоборот). Обращение к переменным из вышестоящего скоупа и есть их захват. Типичной ошибкой является использование значение итератора в цикле:\nvar out []*int for i := 0; i \u0026lt; 3; i++ { out = append(out, \u0026amp;i) } println(*out[0], *out[1], *out[2]) // 3 3 3 Испраляется путём создания локальной (для скоупа цикла) переменной с копией знаяения итератора:\nvar out []*int for i := 0; i \u0026lt; 3; i++ { i := i // Copy i into a new variable. \tout = append(out, \u0026amp;i) } println(*out[0], *out[1], *out[2]) // 0 1 2  Что можно почитать:\n Using reference to loop iterator variable   Как работает defer? Defer является функцией отложенного вызова. Выполняется всегда (даже в случае паники внутри функции вызываемой) после того, как функция завершила своё выполнение но до того, как управление вернётся вызывающей стороне (более того - внутри defer возможен захват переменных, и даже возвращаемого результата). Часто используется для освобождения ресурсов/снятия блокировок. Пример использования:\nfunc main() { println(\u0026#34;result =\u0026#34;, f()) // f started \t// defer \t// defer in defer \t// result = 25 } func f() (i int) { println(\u0026#34;f started\u0026#34;) defer func() { recover() defer func() { println(\u0026#34;defer in defer\u0026#34;); i += 5 }() println(\u0026#34;defer\u0026#34;) i = i * 2 }() i = 10 panic(\u0026#34;panic is here\u0026#34;) } Когда выполняется ключевое слово defer, оно помещает следующий за ним оператор в список, который будет вызван до возврата функции.\nКак работает init? В Go есть предопределенная функция init(). Она выделяет фрагмент кода, который должен выполняться перед всеми другими частями пакета. Этот код будет выполняться сразу после импорта пакета.\nТакже функция init() используется для автоматической регистрации одного пакета в другом (например, так работает подавляющее большинство \u0026ldquo;драйверов\u0026rdquo; для различных СУБД, например - go-sql-driver/mysql/driver.go).\nФункцию init() можно использовать неоднократно в рамках даже одного файла, выполняться они будут в этом случае в порядке, как их встречает компилятор.\nХотя использование init() и является довольно полезным, но часто оно затрудняет чтение/понимание кода, и (почти) всегда можно обойтись без неё, поэтому необходимость её использования - всегда очень большой вопрос.\nПрерывание for/switch или for/select Что произойдёт в следующем примере, если f() вернёт true?\nfor { switch f() { case true: break case false: // Do something  } } Очевидно, будет вызван break. Вот только прерван будет switch, а не цикл for. Простое решение проблемы – использовать именованный (labeled) цикл и вызывать break c этой меткой, как в примере ниже:\nloop: for { switch f() { case true: break loop case false: // Do something  } } Сколько можно возвращать значений из функции? Теоретически, неограниченное количество значений. Так же хочется отметить, что есть правила \u0026ldquo;де-факто\u0026rdquo;, которых следует придерживаться:\n Последним значением возвращать ошибку, если её возврат подразумевается Первым значением возвращать контекст, если он подразумевается Хорошим тоном является не возвращать более четырёх значений Если функция что-то проверяет и возвращает значение + булевый результат проверки - то результат проверки возвращать последним (пример - os.LookupEnv(key string) (string, bool)) Если возвращается ошибка, то остальные значения возвращать нулевыми или nil  Дженерики - это про что? Дженерики, или обобщения - это средства языка, позволяющего работать с различными типами данных без изменения их описания.\nВ версии 1.18 появились дженерики (вообще-то они были и ранее, но мы не могли их использовать в своём коде - вспомни функцию make(T type)), и они позволяют объявлять (описывать) универсальные методы, т.е. в качестве параметров и возвращаемых значений указывать не один тип, а их наборы.\nПоявились новые ключевые слова:\n any - аналог interface{}, можно использовать в любом месте (func do(v any) any, var v any, type foo interface { Do() any }) comparable - интерфейс, который определяет типы, которые могут быть сравнены с помощью == и != (переменные такого типа создать нельзя - var j comparable будет вызывать ошибку)  И появилась возможность определять интерфейсы, которые можно будет использовать в параметризованных функциях и типах (переменные такого типа создать нельзя - var j Int будет вызывать ошибку):\ntype Int interface { int | int32 | int64 } Если добавить знак ~ перед типами то интерфейсу будут соотвествовать и производные типы, например myInt из примера ниже:\ntype Int interface { ~int | ~int32 | ~int64 } type myInt int Разработчики golang создали для нас уже готовый набор интерфейсов (пакет constraints), который очень удобно использовать.\nПараметризованные функции Рассмотрим пример функции, что возвращает максимум из двух переданных значений, причём тип может быть любым:\nimport \u0026#34;constraints\u0026#34; func Max[T constraints.Ordered](a T, b T) T { if a \u0026gt; b { return a } return b } Ограничения на используемые типы описываются в квадратных скобочках. В качестве ограничения для типов можно использовать любой интерфейс и особые интерфейсы описанные выше.\nДля слайсов и мап был создан набор готовых полезных функций.\nПараметризованные типы import \u0026#34;reflect\u0026#34; type myMap[K comparable, V any] map[K]V func main() { m := myMap[int, string]{5: \u0026#34;foo\u0026#34;} println(m[5]) // foo \tprintln(reflect.TypeOf(m)) // main.myMap[int,string] }  Что можно почитать:\n Зачем нужны дженерики в Go? Golang пощупаем дженерики   Память и управление ей Что такое heap и stack? Стек (stack) - это область оперативной памяти, которая создаётся для каждого потока. Он работает в порядке LIFO (Last In, First Out), то есть последний добавленный в стек кусок памяти будет первым в очереди на вывод из стека. Каждый раз, когда функция объявляет новую переменную, она добавляется в стек, а когда эта переменная пропадает из области видимости (например, когда функция заканчивается), она автоматически удаляется из стека. Когда стековая переменная освобождается, эта область памяти становится доступной для других стековых переменных.\nСтек быстрый, так как часто привязан к кэшу процессора. Размер стека ограничен, и задаётся при создании потока.\nКуча (heap) - это хранилище памяти, также расположенное в ОЗУ, которое допускает динамическое выделение памяти и не работает по принципу стека: это просто склад для ваших переменных. Когда вы выделяете в куче участок памяти для хранения переменной, к ней можно обратиться не только в потоке, но и во всем приложении. Именно так определяются глобальные переменные. По завершении приложения все выделенные участки памяти освобождаются. Размер кучи задаётся при запуске приложения, но, в отличие от стека, он ограничен лишь физически, и это позволяет создавать динамические переменные.\nВ сравнении со стеком, куча работает медленнее, поскольку переменные разбросаны по памяти, а не сидят на верхушке стека. То что попадает в кучу, живёт там пока не придёт GC.\nНо почему стек так быстр? Основных причин две:\n Стеку не нужно иметь сборщик мусора (garbage collector). Как мы уже упоминали, переменные просто создаются и затем вытесняются, когда функция завершается. Не нужно запускать сложный процесс освобождения памяти от неиспользуемых переменных и т.п. Стек принадлежит одной горутине, переменные не нужно синхронизировать в сравнении с теми, что находятся в куче. Что также повышает производительность  Где выделяется память под переменную? Можно ли этим управлять? Прямых инструментов для управления местом, где будет выделена память у нас, к сожалению - нет. Но есть некоторые практики, которые позволяют это понять и использовать эффективно.\nПамять под переменную может быть выделена в куче (heap) или стеке (stack). Очень приблизительно:\n Стек содержит последовательность переменных для заданной горутины (как только функция завершила работу, переменные вытесняются из стека) Куча содержит общие (shared) переменные (глобальные и т.п.)  Давайте рассмотрим простой пример, в котором вы возвращаем значение:\nfunc getFooValue() foo { var result foo // Do something \treturn result } Здесь переменная result создаётся в текущей горутине. И эта переменная помещается в стек. Как только функция завершает работу, клиент получает копию этой переменной. Исходная переменная вытесняется из стека. Эта переменная всё ещё существует в памяти, до тех пор, пока не будет затёрта другой переменной, но к этой переменной уже нельзя получить доступ.\nТеперь тот же пример, но с указателем:\nfunc getFooPointer() *foo { var result foo // Do something \treturn \u0026amp;result } Переменная result также создаётся текущей горутиной, но клиент получает указатель (копию адреса переменной). Если result вытеснена из стека, клиент функции не сможет получить доступ к переменной.\nВ подобном сценарии компилятор Go вынужден переместить переменную result туда, где она может быть доступна (shared) – в кучу (heap).\nХотя есть и исключение. Для примера:\nfunc main() { p := \u0026amp;foo{} f(p) } Поскольку мы вызываем функцию f() в той же горутине, что и функцию main(), переменную p не нужно перемещать. Она просто находится в стеке и вложенная функция f() будет иметь к ней доступ.\nВ качестве заключения, когда мы создаём функцию - поведением по умолчанию должно быть использование передачи по значению, а не по указателю. Указатель должен быть использован только когда мы действительно хотим переиспользовать данные.\nКак работает Garbage Collection (GC) в Go? Garbage Collection - это процесс освобождения места в памяти, которая больше не используется. Стек освобождается быстро и просто (условно-самостоятельно), а вот с кучей имеются некоторые сложности.\nВ основе работы GC в Go лежит:\n \u0026ldquo;Трехцветный алгоритм пометки и очистки\u0026rdquo; (выполняется параллельно с основной программой) - все данные в куче представляются в виде связанного графа, каждая вершина которого (каждый объект, данные) может быть помечена как \u0026ldquo;белая\u0026rdquo;, \u0026ldquo;серая\u0026rdquo;, или \u0026ldquo;чёрная\u0026rdquo;; данный граф обходится в несколько проходов, все вершины размечаются своими цветами, и \u0026ldquo;белые\u0026rdquo; (мусорные) объекты могут быть удалены (\u0026ldquo;чёрные\u0026rdquo; - точно нельзя удалять; \u0026ldquo;серые\u0026rdquo; - под вопросом, пока не трогать) Write Barrier, следящий за тем, чтоб черные объекты не указывали на белые; и \u0026ldquo;останавливать мир\u0026rdquo; (Stop The World, STW) для включения или отключения Write Barrier  GC можно вызвать ручками - runtime.GC(), но пользоваться этим нужно с осторожностью (есть риск блокировки вызывающей стороны или всего приложения целиком).\nПо умолчанию, GC запускается самостоятельно когда размер кучи становится в 2 раза больше (за это отвечает Pacer; данный коэффициент можно регулировать при сборке с помощью env GOGC).\nПолный цикл работы GC:\n Sweep termination - фаза завершения очистки:  Stop the World Ожидаем пока все горутины достигнут safe-point Завершаем очистку ресурсов   Mark phase - фаза разметки (выполняется конкурентно с основной программой, выделяется на неё ~25% CPU):  Включаем Write Barrier Start the World Запускаем сканирование глобальных переменных и стеков При сканировании работа горутины приостанавливается (но не происходит полная остановка всей программы) Выполняем 3-х цветный алгоритм поиска мусора   Mark termination - фаза завершения разметки  Stop the World (не является обязательной, но с ней проце было реализовать) Дожидаемся завершения обработки последних задач из очереди Очистка кэшей Завершаем разметку   Sweep phase - фаза очистки  Отключаем Write Barrier Start The World Очистка ресурсов происходит в фоне    👎 Недостатки:\n Не реализован алгоритм поколений (GC Generations) Не реализовано уплотнение Stop the World (STW), вызываемый аж дважды Нет возможности тонкой настройки  Для оптимизации можно:\n Уменьшить частоту вызова GC с помощью GOGC Использовать балласт (выделять большое количество памяти при запуске приложения make([]byte, 10 \u0026lt;\u0026lt; 30) // 10 GiB), который увеличивает базовый размер кучи, не будет выделен как мусор, помечается за O(1), и выделяется в виртуальном пространстве не используя физическую память Использовать sync.Pool (он хорошо дружит с GC)    Какое поведение по умолчанию используется в Go при передаче в функцию? По умолчанию всегда используется копирование, т.е. передача по значению. Для передачи по указателю необходимо это явно указывать:\nfunc main() { var i = 5 byValue(i) // 5 \tbyPointer(\u0026amp;i) // 5 } func byValue(i int) { println(i) } // передача по значению (копии переменной) func byPointer(i *int) { println(*i) } // передача по указателю Что можешь рассказать про escape analysis? Escape analysis - это процесс, который компилятор использует для определения размещения значений, созданных вашей программой.\nВ частности, компилятор выполняет статический анализ кода, чтобы определить, может ли значение быть помещено в стековый фрейм для функции, которая его строит, или значение должно \u0026ldquo;сбежать\u0026rdquo; в кучу. Используется разработчиками для оптимизации кода и аналитики причин возможного замедления.\nКоманда для запуска escape-анализа: go build -gcflags=\u0026quot;-m\u0026quot; (так же можно использовать флаги -N для отключени оптимизаций, -l для отключения \u0026ldquo;инлайнинга\u0026rdquo;).\n Что можно почитать:\n Языковая механика escape analysis Escape Analysis in Golang   Сoncurrency (конкурентность) В данном разделе будут вопросы, относящиеся к параллелизму и конкурентной работе.\nКак устроен мьютекс? Mutex означает MUTual EXclusion (взаимное исключение), и обеспечивает безопасный доступ к общим ресурсам.\nПод капотом мьютекса используются функции из пакета atomic (atomic.CompareAndSwapInt32 и atomic.AddInt32), так что можно считать мьютекс надстройкой над atomic. Мьютекс медленнее чем atomic, потому что он блокирует другие горутины на всё время действия блокировки. А в свою очередь atomic быстрее потому как использует атомарные инструкции процессора.\nВ момент, когда нужно обеспечить защиту доступа - вызываем метод Lock(), а по завершению операции изменения/чтения данных - метод Unlock().\nВ чем отличие sync.Mutex от sync.RWMutex? Помимо Lock() и Unlock() (у sync.Mutex), у sync.RWMutex есть отдельные аналогичные методы только для чтения - RLock() и RUnlock(). Если участок в памяти нуждается только в чтении - он использует RLock(), который не заблокирует другие операции чтения, но заблокирует операцию записи и наоборот.\nПо большому счёту, RWMutex это комбинация из двух мьютексов.\nЧто такое synс.Map? Коротко - предоставляет атомарный доступ к элементам map.\nGo, как известно, является языком созданным для написания concurrent программ - программ, который эффективно работают на мультипроцессорных системах. Но тип map не безопасен для параллельного доступа. То есть для чтения, конечно, безопасен - 1000 горутин могут читать из map без опасений, но вот параллельно в неё ещё и писать - уже нет.\nДля обеспечения потоко-безопасного доступа к map можно использовать sync.RWMutex, но он имеет проблему производительности при работе на большом количестве ядер процессора (в RWMutex при блокировке на чтение каждая горутина должна обновить поле readerCount - простой счётчик, с помощью atomic.AddInt32(), что проиводит к сбросу кэша для этого адреса памяти для всех ядер, и каждое ядро становится в очередь и ждёт этот сброс и вычитывание из кэша - эта проблема называется cache contention).\nsync.Map решает совершенно конкретную проблему cache contention в стандартной библиотеке для таких случаев, когда ключи в map стабильны (не обновляются часто) и происходит намного больше чтений, чем записей.\nПример работы с sync.Map:\nvar m sync.Map m.Store(\u0026#34;one\u0026#34;, 1) // запись one, ok := m.Load(\u0026#34;one\u0026#34;) // чтение  fmt.Println(one, ok) // 1 true  m.Range(func(k, v interface{}) bool { // итерация эл-ов мапы \tfmt.Println(k, v) // one 1  return true }) m.Delete(\u0026#34;one\u0026#34;) // удаление  Что можно почитать:\n Разбираемся с новым sync.Map в Go 1.9   Какие ещё примитивы синхронизации знаешь? Как было сказано выше - для синхронизации можно использовать мьютексы. Кроме того из стандартной библиотеки нам доступны:\nsync.WaitGroup Используется для координации в случае, когда программе приходится ждать окончания работы нескольких горутин (эта конструкция похожа на CountDownLatch в Java). Отличный способ дождаться завершения набора одновременных операций. Принцип работы следующий:\nvar wg sync.WaitGroup wg.Add(1) // увеличиваем счётчик на 1 go func() { fmt.Println(\u0026#34;task 1\u0026#34;) \u0026lt;-time.After(time.Second) fmt.Println(\u0026#34;task 1 done\u0026#34;) wg.Done() // уменьшаем счётчик на 1 }() wg.Add(1) // увеличиваем счётчик на 1 go func() { fmt.Println(\u0026#34;task 2\u0026#34;) \u0026lt;-time.After(time.Second) fmt.Println(\u0026#34;task 2 done\u0026#34;) wg.Done() // уменьшаем счётчик на 1 }() wg.Wait() // блокируемся, пока счётчик не будет == 0 // task 2 // task 1 // task 2 done // task 1 done // Total time: 1.00s sync.Cond Условная переменная (CONDition variable) полезна, например, если мы хотим разблокировать сразу несколько горутин (Broadcast), что не получится сделать с помощью канала. Метод Signal отправляет сообщение самой долго-ожидающей горутине. Пример использования:\nvar ( c = sync.NewCond(\u0026amp;sync.Mutex{}) wg sync.WaitGroup // нужна только для примера  free = true ) wg.Add(1) go func() { defer wg.Done() c.L.Lock() for !free { // проверяем, что ресурс свободен \tc.Wait() } fmt.Println(\u0026#34;work\u0026#34;) c.L.Unlock() }() free = false // забрали ресурс, чтобы выполнить с ним работу \u0026lt;-time.After(1 * time.Second) // эмуляция работы free = true // освободили ресурс c.Signal() // оповестили горутину  wg.Wait() sync.Once Позволяет определить задачу для однократного выполнения за всё время работы программы. Содержит одну-единственную функцию Do, позволяющую передавать другую функцию для однократного применения.\nvar once sync.Once for i := 0; i \u0026lt; 10; i++ { once.Do(func() { fmt.Println(\u0026#34;Hell yeah!\u0026#34;) }) } // Hell yeah! (выводится 1 раз вместо 10) sync.Pool Используется для уменьшения давления на GC путём повторного использования выделенной памяти (потоко-безопасно). Пул необязательно освободит данные при первом пробуждении GC, но он может освободить их в любой момент. У пула нет возможности определить и установить размер и нет необходимости заботиться о его переполнении.\n Что можно почитать:\n Go sync.Pool   Какие типы каналов существуют? Если которотко, то синхронные (небуферизированным) и асинхронные (буферизированные), оба работают по принципу FIFO (first in, first out) очереди.\nКанал - это объект связи, с помощью которого (чаще всего) горутины обмениваются данными. Потокобезопасен, передаётся \u0026ldquo;по указателю\u0026rdquo;. Технически это можно представить как конвейер (или трубу), откуда можно считывать и помещать данные. Для создания канала предоставляет ключевое слово chan - создание не буферизированного канала c := make(chan int), для чтения из канала - data := \u0026lt;-c, для записи - c \u0026lt;- 123, и закрытие close(c).\nЗапись данных в закрытый канал вызовет панику.\nЧтение или запись данных в небуферизированный канал блокирует горутину и контроль передается свободной горутине. Через закрытый канал невозможно будет передать или принять данные (проверить открытость канала можно используя val, isOpened := \u0026lt;- channel, где isOpened == true в том случае, если канал открыт; в противном случае вернётся false и нулевое значение val исходя из типа данных для канала; isOpened == false если канал закрыт и отсутствуют данные для чтения из него).\nБуферизированный канал создается указанием второго аргумента для make - c := make(chan int, 5), в этом случае горутина не блокируется до тех пор, пока буфер не будет заполнен. Подобно слайсам, буферизированный канал имеет длину (len, количество сообщений в очереди, не считанных) и емкость (cap, размер самого буфера канала):\nc := make(chan string, 5) c \u0026lt;- \u0026#34;foo\u0026#34; c \u0026lt;- \u0026#34;bar\u0026#34; close(c) println(len(c), cap(c)) // 2 5  for { val, ok := \u0026lt;-c // обрати внимание - читаем из уже закрытого канала  if !ok { break } println(val) } // \u0026#34;foo\u0026#34; // \u0026#34;bar\u0026#34; Используя буферизованный канал и цикл for val := range c { ... } мы можем читать с закрытых каналов (поскольку у закрытых каналов данные все еще живут в буфере).\nКроме того, сужествует синтаксический сахар однонаправленных каналов (улучшает безопасность типов в программe, что, как следствие, порождает меньше ошибок):\n c := make(\u0026lt;-chan int) - только для чтения c := make(chan\u0026lt;- int) - только для записи  Так же можно в сигнатуре принимаемой функции указать однонаправленность канала (func write(c chan\u0026lt;- string) { ... }) - в этом случае функция не сможет из него читать, а сможет только писать или закрыть его.\nЧитать \u0026ldquo;одновременно\u0026rdquo; из нескольких каналов возможно с помощью select (оператор select является блокируемым, за исключением использования default):\nc1, c2 := make(chan string), make(chan string) defer func() { close(c1); close(c2) }() // не забываем прибраться  go func(c chan\u0026lt;- string) { \u0026lt;-time.After(time.Second); c \u0026lt;- \u0026#34;foo\u0026#34; }(c1) go func(c chan\u0026lt;- string) { \u0026lt;-time.After(time.Second); c \u0026lt;- \u0026#34;bar\u0026#34; }(c2) for i := 1; ; i++ { select { // блокируемся, пока в один из каналов не попадёт сообщение \tcase val := \u0026lt;-c1: println(\u0026#34;channel 1\u0026#34;, val) case val := \u0026lt;-c2: println(\u0026#34;channel 2\u0026#34;, val) } if i \u0026gt;= 2 { // через 2 итерации выходим (иначе будет deadlock) \tbreak } } // channel 1 foo // channel 2 bar // Total execution time: 1.00s В случае, если в оба канала одновременно придут сообщения (или они уже там были), то case будет выбран случайно (а не по порядку их объявления, как могло бы показаться).\nЕсли ни один из каналов недоступен для взаимодействия, и секция default отсутствует, то текущая горутина переходит в состояние waiting до тех пор, пока какой-то из каналов не станет доступен.\nЕсли в select указан default, то он будет выбран в том случае, если все каналы не имеют сообщений (таким образом select становится не блокируемым).\nПод капотом (src/runtime/chan.go) канал представлен структурой:\ntype hchan struct { qcount uint // количество элементов в буфере \tdataqsiz uint // размерность буфера \tbuf unsafe.Pointer // указатель на буфер для элементов канала \telemsize uint16 // размер одного элемента в канале \tclosed uint32 // флаг, указывающий, закрыт канал или нет \telemtype *_type // содержит указатель на тип данных в канале \tsendx uint // индекс (смещение) в буфере по которому должна производиться запись \trecvx uint // индекс (смещение) в буфере по которому должно производиться чтение \trecvq waitq // указатель на связанный список горутин, ожидающих чтения из канала \tsendq waitq // указатель на связанный список горутин, ожидающих запись в канал \tlock mutex // мьютекс для безопасного доступа к каналу } В общем случае, горутина захватывает мьютекс, когда совершает какое-либо действие с каналом, кроме случаев lock-free проверок при неблокирующих вызовах.\nGo не выделяет буфер для синхронных (небуферизированных) каналов, поэтому указатель на буфер равен nil и dataqsiz равен нулю. При чтении из канала горутина произведёт некоторые проверки, такие как: закрыт ли канал, буферизирован он или нет, содержит ли гоуртины в send-очереди. Если ожидающих отправки горутин нет - горутина добавит сама себя в recvq и заблокируется. При записи другой горутиной все проверки повторяются снова, и когда она проверяет recvq очередь, она находит ожидающую чтение горутину, удаляет её из очереди, записывает данные в её стек и снимает блокировку. Это единственное место во всём рантайме Go, когда одна горутина пишет напрямую в стек другой горутины.\nПри создании асинхронного (буферизированного) канала make(chan bool, 1) Go выделяет буфер и устанавливает значение dataqsiz в единицу. Чтобы горутине отправить отправить значение в канал, сперва производятся несколько проверок: пуста ли очередь recvq, пуст ли буфер, достаточно ли места в буфере. Если всё ок, то она просто записывает элемент в буфер, увеличивает значение qcount и продолжает исполнение далее. Когда буфер полон, буферизированный канал будет вести себя точно так же, как синхронный (небуферизированный), тоесть горутина добавит себя в очередь ожидания и заблокируется.\nПроверки буфера и очереди реализованы как атомарные операции, и не требуют блокировки мьютекса.\nПри закрытии канала Go проходит по всем ожидающим на чтение или запись горутинам и разблокирует их. Все получатели получают дефолтные значение переменных того типа данных канала, а все отправители паникуют.\n Что можно почитать:\n Анатомия каналов в Go Как устроены каналы в Go Под капотом Golang - как работают каналы. Часть 1 Строение каналов в Golang. Часть 2   Что можно делать с закрытым каналом? Из закрытого канала можно читать с помощью for val := range c { ... } - вычитает все сообщения что в нём есть, или с помощью:\nfor { if val, ok := \u0026lt;-c; ok { println(val) } else { break } } Расскажи про планировщик (горутин) Goroutine scheduler является перехватывающим задачи (work-stealing) планировщиком, который был введен еще в Go 1.1 Дмитрием Вьюковым вместе с командой Go. Основная его суть заключается в том, что он управляет:\n G (горутинами) - просто горутины Go M (машинами aka потоками или тредами) - потоки ОС, которые могут выполнять что-либо или же бездействовать P (процессорами) - можно рассматривать как ЦП (физическое ядро); представляет ресурсы, необходимые для выполнения нашего Go кода, такие как планировщик или состояние распределителя памяти  Основная задача планировщика состоит в том, чтобы сопоставить каждую G (код, который мы хотим выполнить) с M (где его выполнять) и P (права и ресурсы для выполнения).\nКогда M (поток ОС) прекращает выполнение нашего кода, он возвращает свой P (ЦП) в пул свободных P. Чтобы возобновить выполнение Go кода, он должен повторно заполучить его. Точно так же, когда горутина завершается, объект G (горутина) возвращается в пул свободных G и позже может быть повторно использован для какой-либо другой горутины.\nGo запускает столько тредов, сколько доступно процессорных ядер (если вы специально это не перенастраиваете) и распределяет на эти треды сколько угодно горутин которые уже запускает программист. В один момент на одном ядре ЦП может находиться в исполнении только одна грутина, а в очереди исполнения их может быть неограниченное количество.\nТреды M во время выполнения могут переходить от одного процессора P к другому. Например, когда тред делает системный вызов, в ответ на который ОС блокирует этот тред (например - чтение какого-то большого файла с диска) - мало того что заблокируется сама горутина, что спровоцировала этот вызов, но и все остальные, что стоят в очереди для этого процессора P. Чтоб этого не происходило - Go отвязывает горутины стоящие в очереди от этого процессора P и переназначает на другие.\nОсновные типы многозадачности что используются в большинстве ОС это \u0026ldquo;вытесняющая\u0026rdquo; (все ресурсы делятся между всеми программами одинаково, всем выделяется одинаковое время выполнения) и \u0026ldquo;кооперативная\u0026rdquo; (программы выполняются столько, сколько им нужно, и сами уступают друг-другу место). В Go используется неявная кооперативность:\n Горутина уступает место другис при обращении к вводу-выводу, каналам, вызовам ОС и т.д. Может уступить место при вызове любой функции (с некоторой вероятностью произойдет переключение между горутинами) Есть явный способ переключить планировщик на другую горутину - вызвать функцию runtime.Gosched() (почти никогда не нужна, но она есть)  Основные принципы планировщика:\n Очередь FIFO (first in - first out) - порядок запуска горутин обуславливается порядом их вызова Необходимый минимум тредов - создается не больше тредов чем доступных ядер ЦП Захват чужой работы - когда тред простаивает, то он не удаляется рантаймом Go, а будет по возможности \u0026ldquo;нагружен\u0026rdquo; работой, взятой из очередей горутин на исполнение с других тредов \u0026ldquo;Неинвазивность\u0026rdquo; - работа горутин насильно не прерывается  Ограничения:\n Очередь FIFO (нет приоритезации и изменения порядка исполнения) Отсутствие гарантий времени выполнения (времени запуска горутин) Горутины могут перемещаться между тредами, что снижает эффективность кэшей     Что можно почитать:\n Горутины: всё, что вы хотели знать, но боялись спросить Что такое горутины и каков их размер?   Что такое горутина? Горутина (goroutine) - это функция, выполняющаяся конкурентно с другими горутинами в том же адресном пространстве.\nДля её запуска достаточно использовать ключевое слово go перед именем вызываемой (или анонимной) функции.\nГорутины очень легковесны (~2,6Kb на горутину). Практически все расходы - это создание стека, который очень невелик, хотя при необходимости может расти. Область их применения чаще всего следующая:\n Когда нужна асинхронность (например когда мы работаем с сетью, диском, базой данных, защищенным мьютексом ресурсом и т.п.) Когда время выполнения функции достаточно велико и можно получить выигрыш, нагрузив другие ядра  Сама структура горутины занимает порядка 600 байт, но для неё ещё выделяется и её собственный стек, минимальный размер котого составляет 2Kb, который увеличивается и уменьшается по мере необходимости (максимум зависит от архитектуры и составляет 1 ГБ для 64-разрядных систем и 250 МБ для 32-разрядных систем).\nПереключение между двумя Горутинами - супер дешевое, O(1), то есть, не зависит от количества созданных горутин в системе. Всё, что нужно сделать для переключения, это поменять 3 регистра - Program counter, Stack Pointer и DX.\nВ чем отличия горутин от потов ОС?  Каждый поток операционной системы имеет блок памяти фиксированного размера (зачастую до 2 Мбайт) для стека - рабочей области, в которой он хранит локальные переменные вызовов функций, находящиеся в работе или приостановленные на время вызова другой функции. В противоположность этому go-подпрограмма начинает работу с небольшим стеком, обычно около 2 Кбайт. Стек горутины, подобно стеку потока операционной системы, хранит локальные переменные активных и приостановленных функций, но, в отличие от потоков операционной системы, не является фиксированным; при необходимости он может расти и уменьшаться Потоки операционной системы планируются в ее ядре, а у go есть собственный планировщик (m:n) мультиплексирующий (раскидывающий) горутинки (m) по потокам (n). Основной плюс - отсутствие оверхеда на переключение контекста Планировщик Go использует параметр с именем GOMAXPROCS для определения, сколько потоков операционной системы могут одновременно активно выполнять код Go. Его значение по умолчанию равно количеству процессоров (ядер) компьютера, так что на машине с 8 процессорами (ядрами) планировщик будет планировать код Go для выполнения на 8 потоках одновременно. Спящие или заблокированные в процессе коммуникации go-подпрограммы потоков для себя не требуют. Go-подпрограммы, заблокированные в операции ввода-вывода или в других системных вызовах, или при вызове функций, не являющихся функциями Go, нуждаются в потоке операционной системы, но GOMAXPROCS их не учитывает В большинстве операционных систем и языков программирования, поддерживающих многопоточность, текущий поток имеет идентификацию, которая может быть легко получена как обычное значение (обычно - целое число или указатель). У горутин нет идентификации, доступной программисту. Так решено во время проектирования языка, поскольку локальной памятью потока программисты злоупотребляют  Где аллоцируется память для горутин? Так как горутины являются stackful - то и память для них (их состояние) хранится на стеке. Поэтому, теоритически, если очень постараться и сделать милилард вложенных вызовов, то можно сделать себе переполнение стека.\nДля самих же переменных, что используются внутри горутин память берётся с хипа (ограничены только размером \u0026ldquo;физического\u0026rdquo; хипа, т.е. объемом памяти сколько есть на машине).\n Что можно почитать:\n Достучаться до небес - Корутины, Горутины и прочие Рутины Go: как изменяется размер стека горутины?   Как завершить много горутин? Один из вариантов - это пристрелить main (шутка). Работу одной гороутины в принципе нельзя принудительно остановить из другой. Механизмы их завершения необходимо реализовывать отдельно (учить сами горутины завершаться).\nНаиболее часто используются 2 подхода - это использование контекста context.Context:\nimport ( \u0026#34;context\u0026#34; \u0026#34;time\u0026#34; ) func f(ctx context.Context) { loop: for { select { case \u0026lt;-ctx.Done(): println(\u0026#34;break f\u0026#34;) break loop default: println(\u0026#34;do some work\u0026#34;) \u0026lt;-time.After(time.Millisecond * 100) } } } func main() { ctx, cancel := context.WithCancel(context.Background()) for i := 0; i \u0026lt; 3; i++ { go f(ctx) // запускаем 3 горутины \t} \u0026lt;-time.After(time.Millisecond * 50) cancel() // отменяем контекст, на что горутины должны среагировать выходом \t\u0026lt;-time.After(time.Millisecond * 60) // do some work \t// do some work \t// do some work \t// break f \t// break f \t// break f } И отдельного канала для уведомлений о необходимости завершения (часто для уведомлений используется пустая структура struct{}, которая ничего не весит):\nimport ( \u0026#34;time\u0026#34; ) func f(c \u0026lt;-chan struct{}) { loop: for { select { case \u0026lt;-c: println(\u0026#34;break f\u0026#34;) break loop default: println(\u0026#34;do some work\u0026#34;) \u0026lt;-time.After(time.Millisecond * 100) } } } func main() { const workersCount = 3 var c = make(chan struct{}, workersCount) for i := 0; i \u0026lt; workersCount; i++ { go f(c) // запускаем 3 горутины \t} \u0026lt;-time.After(time.Millisecond * 50) for i := 0; i \u0026lt; workersCount; i++ { c \u0026lt;- struct{}{} // отправляем 3 сообщения в канал (по одному для каждой горутины) о выходе \t} // ВООБЩЕ - цикл с отправкой сообщений НЕ является обязательным, и можно просто закрыть канал \tclose(c) \u0026lt;-time.After(time.Millisecond * 60) // do some work \t// do some work \t// do some work \t// break f \t// break f \t// break f } Кейсы использования контекста Пакет context в Go особенно полезен при взаимодействиях с API и медленными процессами, особенно в production-grade системах. С его помощью можно уведомить горутины о необходимости завершить свою работу, \u0026ldquo;пошарить\u0026rdquo; какие-то данные (например, в middleware), или легко организовать работу с таймаутом.\ncontext.WithCancel() Эта функция создает новый контекст из переданного ей родительского, возвращая первым аргуметом функцию \u0026ldquo;отмены контекста\u0026rdquo; (при её вызове родительский контект \u0026ldquo;отменен\u0026rdquo; не будет), а вторым - новый контекст. Важно - вызывать функцию отмены контекста должна только та функция, которая его создает. При вызове функции отмены сам контекст и все котнекты, созданные на основе него получат в ctx.Done() пустую структуру и в ctx.Err() ошибку context.Canceled.\nctx, cancel := context.WithCancel(context.Background()) fmt.Println(ctx.Err()) // nil  cancel() fmt.Println(\u0026lt;-ctx.Done()) // {} fmt.Println(ctx.Err().Error()) // context canceled context.WithDeadline() Так же создает контекст от родительского, который отменится самостоятельно при наступлении переданного ему временной отметке, или при вызове функции отмены. Отмена/таймаут затрагивает только сам контекст и его \u0026ldquo;наследников\u0026rdquo;. ctx.Err() возвращает ошибку context.DeadlineExceeded. Полезно для реализации таймаутов:\nctx, cancel := context.WithDeadline( context.Background(), time.Now().Add(time.Millisecond*100), ) defer cancel() fmt.Println(ctx.Err()) // nil  \u0026lt;-time.After(time.Microsecond * 110) fmt.Println(\u0026lt;-ctx.Done()) // {} fmt.Println(ctx.Err().Error()) // context deadline exceeded context.WithTimeout() Работает аналогично context.WithDeadline() за исключением того, что принимает в качестве значения таймаута длительность (например - time.Second):\nctx, cancel := context.WithTimeout(context.Background(), time.Second*2) context.WithValue() Позволяет \u0026ldquo;пошарить\u0026rdquo; данные через всё контекстное деверо \u0026ldquo;ниже\u0026rdquo;. Часто используют чтоб передать таким образом, например, логгер или HTTP запрос в цепочке middleware (но в 9 из 10 случаев так делать не надо, это можно считать антипаттерном). Лучше всего использовать функции для помещения/извлечения данных из контекста (так как \u0026ldquo;в нём\u0026rdquo; они храняться как interface{}):\nimport ( \u0026#34;context\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) const loggerCtxKey = \u0026#34;logger\u0026#34; // should be unique  func PutLogger(ctx context.Context, logger *log.Logger) context.Context { return context.WithValue(ctx, loggerCtxKey, logger) } func GetLogger(ctx context.Context) *log.Logger { return ctx.Value(loggerCtxKey).(*log.Logger) } func f(ctx context.Context) { logger := GetLogger(ctx) logger.Print(\u0026#34;inside f\u0026#34;) println(logger) } func main() { var ( logger = log.New(os.Stdout, \u0026#34;\u0026#34;, 0) ctxWithLogger = PutLogger(context.Background(), logger) ) logger.Printf(\u0026#34;main\u0026#34;) println(logger) f(ctxWithLogger) // main \t// 0xc0000101e0 \t// inside f \t// 0xc0000101e0 }    Что можно почитать:\n Разбираемся с пакетом Context в Golang   При этом ok == true до того момента, пока в канале есть сообщения (вне зависимости от того, открыт он или закрыт), в противном случае ok == false а val будет нулевым значением в зависимости от типа данных канала. При попытке записи в закрытый канал будет паника (авторы языка так сделали \u0026ldquo;ибо нефиг - канал закрыт значит закрыт\u0026rdquo;).\nКак задетектить гонку? Пишем тесты, и запускаем их с флагом -race (в этом случае рантайм будет в случайном порядке переключаться между горутинами (если не ошибаюсь), и компилятор генерирует дополнительный код, который \u0026ldquo;журналирует\u0026rdquo; обращения к памяти). Этот флаг можно использовать как для go test, так и для go run или go build.\nДетектор гонки основан на библиотеке времени выполнения (runtime library) C/C++ ThreadSanitizer.\nТак же предпочитаю писать тесты, провоцирующие гонку. Код в этом случае будет работать значительно медленнее, но для этапа тестирования это и не так важно. А именно для тестируемоой структуры запускаю (например) 100 горутин которые читают и пишут что-то в случайном порядке.\nВажно и ещё одно высказывание - \u0026ldquo;Если race detector обнаруживает состояние гонки, то оно у вас наверняка есть; если же не обнаруживает - то это не означает что его нет\u0026rdquo;.\nТестирование Для unit-тестирования (aka модульного) используется команда вида go test, которая запускает все функции, что начинаются с префикса Test в файлах, что имеют в своем имени постфикс _test.go - всё довольно просто.\nВажно писать сам код так, чтоб его можно было протестировать (например - не забывать про инвертирование зависимостей и использовать интерфейсы там, где они уместны).\nTDT, Table-driven tests (табличное тестирование) Являются более предпочтительным вариантом для тестирования множества однотипных кейсов перед описанием \u0026ldquo;один кейс - один тест\u0026rdquo;, так как позволяют отделить часть входных данных и ожидаемых данных от всех этапов инициализации и tear-down (не знаю как это будет по-русски). Например, тестируемая функция и её тест могут выглядеть так:\npackage main func Sum(a, b int) int { return a + b } package main import \u0026#34;testing\u0026#34; func TestSum(t *testing.T) { for name, tt := range map[string]struct { // ключ мапы - имя теста \tgiveOne, giveSecond int wantResult int }{ \u0026#34;1 + 1 = 2\u0026#34;: { giveOne: 1, giveSecond: 1, wantResult: 2, }, \u0026#34;140 + 6 = 146\u0026#34;: { giveOne: 140, giveSecond: 6, wantResult: 146, }, } { t.Run(name, func(t *testing.T) { // setup here  if res := Sum(tt.giveOne, tt.giveSecond); res != tt.wantResult { t.Errorf(\u0026#34;Unexpected result. Want %d, got %d\u0026#34;, tt.wantResult, res) } // teardown here \t}) } } Имя пакета с тестами Если имя пакета в файле с тестами (foo_test.go) указывать с постфиксом _test (например - имя пакета, для которого пишутся тесты foo, а имя пакета указанное в самом файле с тестами для него - foo_test), то в тестах не будет доступа в не-экспортируемым свойствам, структурам и функциям, таким образом тестирование пакета будет происходить \u0026ldquo;как из-вне\u0026rdquo;, и не будет соблазна пытаться использовать что-то приватное, что в пакете содержится. По идее, в одной директории не может находиться 2 и более файлов, имена пакетов в которых отличаются, но *_test является исключением из этого правила.\nБолее того, этот подход стимулирует тестировать API, а не внутренние механизмы, т.е. относиться к функциональности как к \u0026ldquo;черному ящику\u0026rdquo;, что очень правильно.\nСтатические анализаторы (линтеры) Уже давно на все случаи жизни существует golangci-lint, который является универсальным решением, объединяющим множество линтеров в \u0026ldquo;одном флаконе\u0026rdquo;. Удобен как для запуска локально, так и на CI.\nОшибка в бенчмарке Про бенчмарки - иногда встречается кейс с написанием бенчмарка который внутри своего цикла выполняет тестируемую функцию, а результат этого действия никуда не присваивается и не передаётся:\nfunc BenchmarkWrong(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { ourFunc() } } Компилятор может принять это во внимание, и будет выполнять её содержимое как inline-последовательность инструкций. После чего, компилятор определит, что вызовы тестируемой функции не имеет никаких побочных эффектов (side-effects), т.е. никак не влияет на среду исполнения. После чего вызов тестируемой функции будет просто удалён. Один из вариантов избежать сценария выше – присваивать результат выполнения функции переменной уровня пакета. Примерно так:\nvar result uint64 func BenchmarkCorrect(b *testing.B) { var r uint64 for i := 0; i \u0026lt; b.N; i++ { r = ourFunc() } result = r } Теперь компилятор не будет знать, есть ли у функции side-effect и бенчмарк будет точен.\nЧто про функциональное тестирование? Тут всё зависит от того, что мы собираемся тестировать, и тянет на отдельную тему для разговора. Для HTTP посоветовать можно postman и его CLI-версию newman. Ещё как вариант \u0026ldquo;быстро и просто\u0026rdquo; - это hurl.\nДля за-mock-ивания стороннего HTTP API - jmartin82/mmock или lamoda/gonkey.\nПрофилирование (pprof) Для профилирования \u0026ldquo;родными\u0026rdquo; средствами в поставке с Go имеется пакет pprof и одноименная консольная утилита go tool pprof. Причинами необходимости в профилировании могут стать:\n Длительная работа различных частей программы Высокое потребление памяти Высокое потребление ресурсов процессора  Профилировщик является семплирующим - с какой-то периодичностью мы прерываем работу программы, берем стек-трейс, записываем его куда-то, а в конце, на основе того, как часто в стек-трейсах встречаются разные функции, мы понимаем, какие из них использовали больше ресурсов процессора, а какие меньше. Работа с ним состоит из двух этапов - сбор статистики по работе сервиса, и её визуализация + анализ. Собирать статистику можно добавив вызовы пакета pprof, либо запустив HTTP сервер.\nПример использования pprof Рассмотрим простой случай, когда у нас есть функция, которая выполняется по какой-то причине очень долго. Обрамим вызовы потенциально-тяжелого кода в startPprof и stopPprof:\nСпойлер (нажми чтоб раскрыть)  package main import ( \u0026#34;os\u0026#34; \u0026#34;runtime/pprof\u0026#34; \u0026#34;time\u0026#34; ) func startPprof() *os.File { // вспомогательная функция начала профилирования \tf, err := os.Create(\u0026#34;profile.pprof\u0026#34;) if err != nil { panic(err) } if err = pprof.StartCPUProfile(f); err != nil { panic(err) } return f } func stopPprof(f *os.File) { // вспомогательная функция завершения профилирования \tpprof.StopCPUProfile() if err := f.Close(); err != nil { panic(err) } } func main() { // наша основания функция \tvar ( slice = make([]int, 0) m = make(map[int]int) ) pprofFile := startPprof() // начинаем профилирование  // тут начинается какая-то \u0026#34;тяжелая\u0026#34; работа \tfor i := 0; i \u0026lt; 10_000_000; i++ { slice = append(slice, i*i) } for i := 0; i \u0026lt; 10_000_000; i++ { m[i] = i * i } \u0026lt;-time.After(time.Second) // а тут она завершается  stopPprof(pprofFile) // завершаем профилирование } После компиляции и запуска приложения (go build -o ./main . \u0026amp;\u0026amp; ./main) в текущей директории появится файл с именем profile.pprof, содержащий профиль работы. \u0026ldquo;Конвертируем\u0026rdquo; его в читаемое представление в виде svg изображения с помощью go tool pprof -svg ./profile.pprof (на Linux для этого понадобится установленный пакет graphviz) и открываем его (имя файла будет в виде profile001.svg):\nПосмотрим на получившийся граф вызовов. Изучая такой граф, в первую очередь нужно обращать внимание на толщину ребер (стрелочек) и на размер узлов графа (квадратиков). На ребрах подписано время - сколько времени данный узел или любой из ниже лежащих узлов находился в стек-трейсе во время профилирования.\nВ нашем профиле можем заметить, что runtime evacuate_fast64 занимает очень много времени. Связано это с тем, что из мапы данным приходиться эвакуироваться, так как размер мапы очень сильно растёт. Исправляем это (а заодно и слайс) всего в двух строчках:\nvar ( slice = make([]int, 0, 10_000_000) // заставляем аллоцировать память в слайсе  m = make(map[int]int, 10_000_000) // и в мапе заранее ) Повторяем все сделанные ранее операции снова, и видим уже совсем другую картину:\nТеперь картина значительно лучше, и следующее место оптимизации (потенциально) это пересмотреть работу с данными, а именно - нужна ли нам работа с мапой в принципе (может заменить её каким-то слайсом), и если нет - то как можно улучшить (оптимизировать) запись в неё.\n  Так как же профилировщик работает в принципе? Go runtime просит ОС посылать сигнал (man setitimer) с определенной периодичностью и назначает на этот сигнал обработчик. Обработчик берет стек-трейс всех горутин, какую-то дополнительную информацию, записывает ее в буфер и выходит.\nКаковы же недостатки данного подхода?\n Каждый сигнал - это изменение контекста, вещь довольно затратная в наше время. В Go сейчас получается получить порядка 100 в секунду. Иногда этого мало Для нестандартных сборок, например, с использованием -buildmode=c-archive или -buildmode=c-shared, профайлер работать по умолчанию не будет. Это связано с тем, что сигнал SIGPROF (который посылает ОС) придет в основной поток программы, который не контролируется Go Процесс user space, которым является программа на Go, не может получить ядерный стек-трейс. Неоптимальности и проблемы иногда кроются и в ядре  Основное преимущество, конечно, в том, что Go runtime обладает полной информацией о своем внутреннем устройстве. Внешние средства, например, по умолчанию ничего не знают о горутинах. Для них существуют только процессы и треды.\n   Что можно почитать:\n Профилирование и оптимизация программ на Go   Компилятор Компиляция - это процесс преобразования вашего (говно)кода в кашу из машинного кода. Первое понятно тебе, второе - машине.\nИз каких этапов состоит компиляция? cmd/compile содержит основные пакеты Go компилятора. Процесс компиляции может быть логически разделен на четыре фазы:\n Parsing (cmd/compile/internal/syntax) - сорец парсится, разбивается на токены, создается синтаксическое дерево Type-checking and AST (Abstract Syntax Tree) transformations (cmd/compile/internal/gc) - дерево переводится в AST, тут же происходит магия по авто-типизации, проверок интерфейсов этапа компиляции, определяется мертвый код и происходит escape-анализ Generic SSA (Static Single Assignment) (cmd/compile/internal/gc, cmd/compile/internal/ssa) - AST переводится в SSA (промежуточное представление более низкого уровня), что упрощает реализацию оптимизаций; так же применяются множественные оптимизации этого уровня (тут, например, циклы range переписываются в обычные for; а copy заменяется перемещением памяти), удаляются ненужные проверки на nil и т.д. Generating machine code (cmd/compile/internal/ssa, cmd/internal/obj) - универсальные штуки перезаписываются на машинно-зависимые (в зависимости от архитектуры и ОС), после чего над SSA снова выполняются оптимизации, удаляется мертвый код, распределяются регистры, размечается стековый фрейм; после - ассемблер превращает всё это добро в машинный код и записывает объектный файл   Что можно почитать:\n Введение в компилятор Go   Статическая компиляция/линковка - что это, и в чем особенности? Линковка (ну или компоновка) последний этап сборки. Статически слинкованный исполняемый файл не зависит от наличия других библиотек в системе во время своей работы.\nДля включения статической компиляции/линковки (при этом все внешние библиотеки, от которых зависит исполнение кода будут встроены в итоговый бинарный файл) необходимо использовать переменную окружения при сборке CGO_ENABLED=0 (т.е. CGO_ENABLED=0 go build ...). Полученный бинарный файл можно безбоязненно использовать, например, в docker-образе, основанном на scratch (т.е. не содержащем абсолютно никаких файлов, кристально чистая файловая система).\nОднако, это накладывает некоторые ограничения и привносит особенности, которые необходимо помнить:\n C-код будет недоступен, совсем (часть модулей из stdlib Go от него зависят, к слову, но не критичных) Не будет использоваться системный DNS-резольвер Не будет работать проверка x.509 сертификатов, которая должна работать на MacOS X  И ещё, если итоговый бинарный файл планируется использовать в docker scratch, то так же следует иметь в виду:\n Для осуществления HTTP запросов по протоколу HTTPS вашим приложением, в образ нужно будет поместить корневые SSL/TLS сертификаты /etc/ssl/certs Файл временной зоны (/etc/timezone) тоже будет необходим, чтоб корректно работать с датой/временем   Что можно почитать:\n Docker scratch \u0026amp; CGO_ENABLED=0 Кросс-компиляция в Go Go dns   Какие директивы компилятора знаешь? Компилятор Go понимает некоторые директивы (пишутся они в виде комментариев, как правило //go:directive), которые влияют на процесс компиляции (оптимизации, проверок, и т.д.) но не являются частью языка. Вот некоторые из них:\n//go:linkname Указывает компилятору реальное местонахождение функции или переменной. Можно использовать для вызова приватных функций из других пакетов. Требует импортирования пакета unsafe (import _ \u0026quot;unsafe\u0026quot;). Формат следующий:\n//go:linkname localname [importpath.name] Пример использования:\nimport ( _ \u0026#34;strings\u0026#34; // for explodeString \t_ \u0026#34;unsafe\u0026#34; // for go:linkname ) //go:linkname foo main.bar func foo() string func bar() string { return \u0026#34;bar\u0026#34; } //go:linkname explodeString strings.explode func explodeString(s string, n int) []string func main() { println(foo()) // bar \tprintln(explodeString(\u0026#34;foo\u0026#34;, -1)) // [3/3]0xc0000a00f0 } //go:nosplit Указывается при объявлении функции, и указывает на то, что вызов функции должен пропускать все обычные проверки на переполнение стека.\n//go:norace Так же указывается при объявлении функции и \u0026ldquo;выключает\u0026rdquo; детектор гонки (race detector) для неё.\n//go:noinline Отключает оптимизацию \u0026ldquo;инлайнига\u0026rdquo; для функции. Обычно используется отладки компилятора, escape-аналитики или бенчаркинга.\n//go:noescape Тоже \u0026ldquo;функциональная\u0026rdquo; директива, смысл которой сводится к тому, что \u0026ldquo;я доверяю этой функции, и ни один указатель, переданных в качестве аргументов (или возвращенных) этой функции не должен быть помещен в кучу (heap)\u0026rdquo;.\n//go:build Эта директива обеспечивает условную сборку. То есть мы можем \u0026ldquo;размечать\u0026rdquo; тегами файлы, и таким образом компилировать только определенные их \u0026ldquo;наборы\u0026rdquo; (тегов может быть несколько, а так же можно использовать ! для указания \u0026ldquo;не\u0026rdquo;). Часто используется для кодогенерации, указывая какой-то специфичный тег (например ignore - //go:build ignore) чтоб файл никогда не учавствовал с борке итогового приложения.\nВ качестве примера создадим 2 файла в одной директории:\n// file: main.go //go:build one  package main func main() { println(\u0026#34;one!\u0026#34;) } // file: main2.go //go:build two  package main func main() { println(\u0026#34;two!\u0026#34;) } И соберем с разными значениями -tags для go build или go run (обрати внимение - какой именно файл собирать не указывается, только тег):\n$ go run -tags one . one! $ go run -tags two . two! //go:generate Позволяет указать какие внешние команды должны вызваться при запуске go generate. Таким образом, мы можем использовать кодогенерацию, к примеру, или выполнять какие-то операции что дожны предшевствовать сборке (например - //go:generate go run gen.go где gen.go это файл, что содержит //go:build ignore т.е. исключён из компиляции, но при этом генерирует для нас какие-то полезные данные и/или целые .go файлы):\npackage main //go:generate echo \u0026#34;my build process\u0026#34; func main() { println(\u0026#34;hello world\u0026#34;) } $ go generate my build process //go:embed Позволяет \u0026ldquo;встраивать\u0026rdquo; внешние файлы в Go приложение. Требует импортирования пакета embed (import _ \u0026quot;embed\u0026quot;). Поддерживает типы string, []byte и embed.FS. Пример использования:\npackage main import _ \u0026#34;embed\u0026#34; //go:embed test.txt var hello string func main() { println(hello) } $ echo \u0026#34;hello world\u0026#34; \u0026gt; test.txt $ go run . hello world  Что можно почитать:\n pkg.go.dev/cmd/compile Go Compiler Directives Генерация кода в Go pkg.go.dev/embed  ","date":"2022-02-02T06:17:19Z","image":"https://blog.hook.sh/interview-section-golang/cover_hu032bd5f7e68e559a642ecef405e28712_26494_120x120_fill_box_smart1_3.png","permalink":"https://blog.hook.sh/interview-section-golang/","title":"Вопросы и ответы для собеседования Go-разработчика"},{"content":"Как пользователь электро-самоката M365 версии Pro со стажем — могу смело заявить, что быть заметным как для участников дорожного движения, так и пешеходного — очень важно. Если передвигаясь днём по обочине дорог и/или тротуару можно считать что твоя заметность достаточна для других участников движения (недостаток с лихвой компенсируется светоотражающим жилетом), то вот в темное время суток картина сильно меняется. Особенно это чувствуется при движении по тротуару со включенной фарой - особенность устройства и расположения фары на самокате таковы, что идущих тебе на встречу ты просто слепишь, а сзади тебя не видно от слова совсем.\nЗадавшись вопросом \u0026ldquo;как это можно исправить\u0026rdquo; было принято решение интегрировать пару led-лент в днище самоката так, что бы они освещали землю под ним (тем самым обозначая твоё местоположение для других) и чтоб при этом надежность примененного решения не вызывала сомнения. Ниже будет в меру подробное описание того, как подсветка была имплементирована, какие комплектующие для этого были выбраны, их цены и с какими сложностями столкнулся.\nСхема Как решение любой задачи в программировании начинается с проработки алгоритма, тут всё началось с принципиальной схемы:\nЕсли словами - то мы:\n Берем 2 светодиодные ленты на 12V, питаем их через понижающий блок Понижающий блок в свою очередь запитываем прямо от батареи самоката (через предохранитель на 1A) Для включения понижающего блока используем твердотельное реле, которое \u0026ldquo;включает\u0026rdquo; в работу нашу схему в тот момент, когда мы включаем фару  Таким образом нам не придется выводить какие-либо дополнительные кнопки для включения подсветки (интуитивность на максимуме), пока не включена фара у нас цепь разомкнута (утечки тока минимальны, только через реле совсем чуть-чуть), да и в целом всё довольно просто.\n Делать RGB подсветку с управлением, например - силами Arduino по BT не стал осознанно.\n Комплектующие Что делать - понятно, теперь разбираемся с элементной базой. Взял следующие штуки:\n   Наименование Цена     LED ленты цвета \u0026ldquo;Cold White\u0026rdquo; 12V (IP67) в защитной тубе по 0.5м, 2 шт. 879,70 ₽   Понижающий преобразователь с 20..72V (DC) до 12V (DC) 5A 60W 1 012,17 ₽   Твердотельное реле SSR-DD2205HK на 5A 296,53 ₽   Малый предохранитель 1A на проводе 16 AWG 54,40 ₽   Провод 16AWG (черный и красный), по метру каждого цвета 179,51 ₽   Провод 28AWG двужильный, 5 метров 348,15 ₽   Разъемы XT30 с проводом 16AWG, 3 шт. 378,46 ₽   Разъемы двух-контактные на проводе 22AWG 122,09 ₽    Итого вышло на ~3 300 ₽, и самое дорогое - это понижающий блок. Взял его осознанно \u0026ldquo;подороже\u0026rdquo;, так как и его форм-фактор в виде залитого эпоксидной смолой блока подкупил, и положительные отзывы.\nЖелезо Первое, что было сделано - это \u0026ldquo;закладные\u0026rdquo; для лент на днище деки (по её бокам) самоката. Их цель - защитить ленты от каких-либо механических воздействий (неудачных \u0026ldquo;соскоков\u0026rdquo; с бордюров) и скрыть сам факт присутствия какой-либо кастомизации от любопытных глаз. Для этого в Leroy Merlin приобрел уголок алюминиевый 15х10х2 мм и болты потайные M3x10 мм. (лучше было бы 5 мм.). Далее дело было за малым:\n Примерить (у меня длинна каждого составила 32.5 см.), отрезать, обработать края алюминиевого уголка Просверлить по 4 отверстия и за-зенковать их Нарезать резьбу под M3 в отверстиях деки Загрунтовать и покрасить заготовки На фиксатор резьбы (анаэробный клей) вкрутить винты (прикрутить уголки к деке)  Ленты Ленты были безжалостно распотрошены и укорочены под длину получившихся закладных. Кроме того провод был заменен на более мощный с толстой изоляцией, так как он будет находиться во внешней среде, и тут я решил заложиться с некоторым запасом. После всех манипуляций с заменой провода края защитной \u0026ldquo;тубы\u0026rdquo; залил бесцветным герметиком Fix All Crystal (к слову - именно его буду использовать и дальше для герметизации стыков и заполнения пустот). Кроме того - края лент были упакованы в термо-усадку, и получилась такая красота:\nДалее монтируем ленты в закладные, попутно сверля необходимые отверстия (по 2 штуки на каждую сторону) и выводим провода лент через \u0026ldquo;родное\u0026rdquo; уплотнительное кольцо стоп-сигнала внутрь деки самоката:\nДалее приклеиваем ленты на двухсторонний скотч к закладным, а свободное пространство между защитным кожухом лент и корпусом деки/закладных заполняем всё тем же прозрачным герметиком (не дадим грязи повода скапливаться в образовывавшихся пустотах). Если надо будет ленту заменить - просто срежем всё это добро ножом и зачистим растворителем.\nЭлектроника Вооружившись паяльником и поглядывая на нашу схему собираем все части схемы воедино:\nДлину проводов подгоняем \u0026ldquo;по месту\u0026rdquo;, а на концы LED-лент припаиваем двойные разъемы так, чтоб всё это добро соединялось без натяжки, но и без сильных излишков.\n Небольшое отступление не по теме сабжа - во время этого этапа ещё и дорожки мосфетов на контроллере усилил, и клеммы подключения мотор-колеса к контроллеру пропаял. Последние, к слову - уже начали отгарать, и их обслуживание пришлось как раз вовремя - через несколько месяцев \u0026ldquo;покатушек\u0026rdquo; они наверняка отгорели бы окончательно.\n Теперь дело за подключением фары самоката к твердотельному реле (чтоб когда мы включили фару - у нас загорелись LED-ленты). Для этого разбираем \u0026ldquo;голову\u0026rdquo; самоката, и разрезав провод питания фары (желто/белый) припаиваем к нему дополнительный разъем (к которому в дальнейшем подключим провод, что потянется до деки). И тут я должен рассказать одну тонкость - на фару подается следующее напряжение:\n   Самокат включен? Фара включена? Фара подключена? Напряжение     Нет Нет Да -   Да Нет Не важно 3.7V (\u0026ldquo;дежурное\u0026rdquo; напряжение)   Да Да Да 4.1V   Да Да Нет 36.3V    Простыми словами - разница между состояниями \u0026ldquo;фара включена\u0026rdquo; и \u0026ldquo;фара выключена\u0026rdquo; (когда фара исправно светится) в напряжении составляет всего 0.4V, а наше твердотельное реле открывается при напряжении от 3V на управляющем вводе. То есть нам нужно понизить значение \u0026ldquo;дежурного\u0026rdquo; напряжения ниже 3V но так, чтоб при включении фары оно было выше этих самых 3V. Сделал это при помощи потециометра (BAOTER 3296 - W 103), что был безжалостно выпаян из какого-то другого регулятора напряжения, что попался под руку. Итоговое сопротивление замерить забыл, каюсь, так что подобрать его придется самостоятельно.\n Ещё одно важное замечание - верхний предел напряжения на управляющем вводе нашего твердотельного реле составляет 32V, и в случае если фара выйдет из строя (не будет потребителя на выводе контроллера, к которому подключена фара) на него будет подаваться 36.6V, что не есть хорошо. Да, у нас стоит сопротивление для понижения напряжения, но долго ли проработает в этом случае реле - предсказать сложно. Надо просто это помнить и в случае выхода фары из строя - заменить её, либо повысить сопротивление.\n Проверив работоспособность схемы собираем всё \u0026ldquo;как было\u0026rdquo;, выводя с фары дополнительный коннектор рядом с родным (потенциометр я \u0026ldquo;посадил\u0026rdquo; прямо на новый вывод в термо-усадке, чтоб была возможность при необходимости подстроить его с минимальными усилиями):\nТеперь финишная прямая - аккуратно укладываем все новые компоненты в деке (прокладывая их чем-либо мягким чтоб сидели плотно):\nИ через \u0026ldquo;гуся\u0026rdquo; да рулевую стойку протягиваем провод, соединяющий вывод фары (после потенциометра) и выводы управления твердотельного реле. Герметизируем деку, закручиваем всё, герметизируем резиновые уплотнители на \u0026ldquo;гусе\u0026rdquo; и рулевой стойке (чтоб там пролез дополнительный провод - их придется немного подрезать) герметиком и наслаждаемся результатом!\nПотребляемая мощность в моем конфиге составляет 1.1 Вт при выключенном свете, и 12.3 Вт когда включена фара + подсветка из LED-лент. За 1 час работы аккумулятор самоката разряжается примерно на 100 мА/ч (из 12800 в стоке), что составляет менее процента от общего объема (замерял при помощи родного приложения, вкладка информации о батарее). Компоненты не греются, совсем (исключением является лишь led-ленты, но даже их повышение температуры еле-еле ощутимо рукой).\n  Ссылки  Комментарий с рекомендацией использовать 4ю ногу драйвера фары или Arduino 1wire ","date":"2021-02-26T10:01:21Z","image":"https://blog.hook.sh/mi-m365-pro-led-backlight/cover_hu00ae8f25842f0e41405e0f3599f8aa5f_12552_120x120_fill_q75_box_smart1.jpg","permalink":"https://blog.hook.sh/mi-m365-pro-led-backlight/","title":"Led-подсветка для Xiaomi Mi M365 Pro своими руками"},{"content":"Однажды я решил поднять свой крохотный кластер для приложений, запускаемых в docker-контейнерах. Выбор был между nomad (уже не один комрад его настоятельно рекомендовал - обязательно попробую, но позже), K8S (слишком сложно и дорого по ресурсам для pet-проекта) и Docker Swarm (никакого дополнительного софта не потребуется, поставляется вместе с самим докером). Как ты понимаешь - выбор пал именно на последний.\nПо тому как его поднять и базово настроить - материалов полно, но когда дело дошло до настройки огненной стены - вот тут начались некоторые трудности. Известно, что docker активно эксплуатирует сетевые интерфейсы и iptables для управления трафиком между сетями и контейнерами. Как настроить ограничения доступа к master и worker-нодам кластерам ниже мы и поговорим.\nИтак, мы имеем:\n internal-сеть 10.10.10.0/24, к которой подключены все наши серверы - она используется как внутренняя (без ограничений) для общения сервером между собой (при создании swarm был указан сетевой интерфейс, \u0026ldquo;смотрящий\u0026rdquo; в этй сеть docker swarm init --advertise-addr ens11) Каждый сервер имеет белый \u0026ldquo;внешний\u0026rdquo; IP адрес (на сетевом интерфейсе eth0) Один сервер в роли master-ноды swarm-а - он же выполняет роль точки входа (ingress) в ресурсы кластера, т.е. весь трафик (http(s), tcp, udp) приходит на него и дальше уже перенаправляется в нужные контейнеры балансируя нагрузку (на этом сервере открываются все необходимые порты, что должны \u0026ldquo;светиться\u0026rdquo; наружу, естественно, и ssh для административного доступа). Сами контейнеры, что будут обрабатывать трафик находятся на worker-нодах Два сервера в роли worker-ов - на них то и запускаются приложения в контейнерах, что обрабатывают наши запросы (tcp/udp пакеты)  Нам нужно:\n Не ограничивать исходящий трафик на серверах на eth0 интерфейсе - любой процесс должен без ограничений ходить в глобальную сеть Закрыть входящие на всех портах eth0, кроме явно разрешенных (в нашем случае это будет только ssh на worker-нодах и http\\https\\ssh на master) Для internal-сети на интерфейсе ens11 не вводить никаких ограничений При запуске docker-контейнера, даже с публикацией порта в хост (network: host) - не открывать этот порт \u0026ldquo;наружу\u0026rdquo; (для этого нужно будет явно добавить правило исключения и только на master-ноде)  worker Аналогична для всех worker-нод в кластере. Перед выполнением каких-либо манипуляций c iptables настоятельно рекомендую (читай - обязательно) вывести ноду из работы, для чего на master выполни (подставляя имя или ID нужной ноды):\n$ docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION m0au96xa2pfiwxhdhweux5b92 * ingress-1 Ready Active Leader 19.03.12 sweebuhuzfnr2bygrwg4jxddn node-1 Ready Active 19.03.12 5ikrj3ugkdiublkfe70j9upad node-2 Ready Active 19.03.12 $ docker node update node-1 --availability drain А по завершению работ обратно вводи ноду в строй:\n$ docker node update node-1 --availability active Итак, ставим iptables-persistent (все, что ниже выполняется уже на самой worker-ноде):\n$ apt install iptables-persistent $ cd /etc/iptables И приводим файлы rules.v4 и rules.v6 к следующему состоянию (правим только filter, оставил только нужные изменения):\n$ cat ./rules.v4 # ... *filter :INPUT ACCEPT [0:0] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [0:0] :CHECKS - [0:0] # added # ... -A INPUT -i eth0 -j CHECKS -A FORWARD ... -A CHECKS -p tcp -m tcp --dport 22 -m comment --comment SSH -j ACCEPT -A CHECKS -m state --state RELATED,ESTABLISHED -j ACCEPT -A CHECKS -p icmp -m icmp --icmp-type 3 -j ACCEPT -A CHECKS -p icmp -m icmp --icmp-type 11 -j ACCEPT -A CHECKS -p icmp -m icmp --icmp-type 8 -m limit --limit 8/sec -j ACCEPT -A CHECKS -j DROP -A DOCKER ... -A DOCKER-ISOLATION-STAGE-1 ... -A DOCKER-ISOLATION-STAGE-2 ... -A DOCKER-USER -i eth0 -m state --state RELATED,ESTABLISHED -j ACCEPT -A DOCKER-USER -i eth0 -j DROP COMMIT # ...  Для IPv6 пример взят отсюда\n $ cat ./rules.v6 #... *filter :INPUT DROP [0:0] :FORWARD DROP [0:0] :OUTPUT DROP [0:0] :WCFW-ICMP - [0:0] :WCFW-Local - [0:0] :WCFW-Services - [0:0] :WCFW-State - [0:0] -A INPUT -j WCFW-Local -A INPUT -j WCFW-State -A INPUT -p ipv6-icmp -j WCFW-ICMP -A INPUT -j WCFW-Services -A OUTPUT -j WCFW-Local -A OUTPUT -j WCFW-State -A OUTPUT -j ACCEPT -A WCFW-ICMP -p ipv6-icmp -m icmp6 --icmpv6-type 1 -j ACCEPT -A WCFW-ICMP -p ipv6-icmp -m icmp6 --icmpv6-type 2 -j ACCEPT -A WCFW-ICMP -p ipv6-icmp -m icmp6 --icmpv6-type 3 -j ACCEPT -A WCFW-ICMP -p ipv6-icmp -m icmp6 --icmpv6-type 4 -j ACCEPT -A WCFW-ICMP -p ipv6-icmp -m icmp6 --icmpv6-type 133 -j ACCEPT -A WCFW-ICMP -p ipv6-icmp -m icmp6 --icmpv6-type 134 -j ACCEPT -A WCFW-ICMP -p ipv6-icmp -m icmp6 --icmpv6-type 135 -j ACCEPT -A WCFW-ICMP -p ipv6-icmp -m icmp6 --icmpv6-type 136 -j ACCEPT -A WCFW-ICMP -p ipv6-icmp -m icmp6 --icmpv6-type 128 -m limit --limit 8/sec -j ACCEPT -A WCFW-Local -i lo -j ACCEPT -A WCFW-Services -i eth0 -p tcp -m tcp --dport 22 -m comment --comment SSH -j ACCEPT -A WCFW-State -m conntrack --ctstate INVALID -j DROP -A WCFW-State -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT COMMIT # ... После чего заставляем iptables использовать наши правила:\n$ iptables-restore ./rules.v4 $ ip6tables-restore ./rules.v6 master Аналогично с worker-ами ставим iptables-persistent и приводим к виду:\n$ cat ./rules.v4 # ... *filter :INPUT ACCEPT [0:0] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [0:0] :CHECKS - [0:0] # added # ... -A INPUT -i eth0 -j CHECKS -A FORWARD ... -A CHECKS -p tcp -m tcp --dport 22 -m comment --comment SSH -j ACCEPT -A CHECKS -p tcp -m tcp --dport 80 -m comment --comment HTTP -j ACCEPT -A CHECKS -p tcp -m tcp --dport 443 -m comment --comment HTTPS -j ACCEPT -A CHECKS -m state --state RELATED,ESTABLISHED -j ACCEPT -A CHECKS -p icmp -m icmp --icmp-type 3 -j ACCEPT -A CHECKS -p icmp -m icmp --icmp-type 11 -j ACCEPT -A CHECKS -p icmp -m icmp --icmp-type 8 -m limit --limit 8/sec -j ACCEPT -A CHECKS -j DROP -A DOCKER ... -A DOCKER-ISOLATION-STAGE-1 ... -A DOCKER-ISOLATION-STAGE-2 ... -A DOCKER-USER -i eth0 -p tcp -m tcp -m conntrack --ctorigdstport 80 -m comment --comment HTTP -j ACCEPT -A DOCKER-USER -i eth0 -p tcp -m tcp -m conntrack --ctorigdstport 443 -m comment --comment HTTPS -j ACCEPT -A DOCKER-USER -i eth0 -m state --state RELATED,ESTABLISHED -j ACCEPT -A DOCKER-USER -i eth0 -j DROP COMMIT # ... Для IPv6 настройки оставил аналогичными с worker-нодами. Теперь так выполняем:\n$ iptables-restore ./rules.v4 $ ip6tables-restore ./rules.v6 И проверяем извне на предмет \u0026ldquo;осталось ли что-нибудь лишнее\u0026rdquo;:\n$ nmap -v -A -p1-65535 -Pn 11.22.22.11 Где 11.22.22.11 наш белый IP сервера (производим такие манипуляции с каждым сервером) - должны остаться открытые только нужные нам порты. Проверяем и корректность работы приложений, запущенных в кластере (те, что ходят в глобальную сеть - должны успешно в неё ходить). Так же проверяем и с самих севреров (как master, так и worker):\n$ ping 1.1.1.1 PING 1.1.1.1 (1.1.1.1) 56(84) bytes of data. 64 bytes from 1.1.1.1: icmp_seq=1 ttl=57 time=20.2 ms 64 bytes from 1.1.1.1: icmp_seq=2 ttl=57 time=20.3 ms $ ping6 2606:4700:4700::1111 PING 2606:4700:4700::1111(2606:4700:4700::1111) 56 data bytes 64 bytes from 2606:4700:4700::1111: icmp_seq=1 ttl=56 time=21.1 ms 64 bytes from 2606:4700:4700::1111: icmp_seq=2 ttl=56 time=21.3 ms $ docker run --rm alpine:latest ping 1.1.1.1 PING 1.1.1.1 (1.1.1.1): 56 data bytes 64 bytes from 1.1.1.1: seq=0 ttl=56 time=20.531 ms 64 bytes from 1.1.1.1: seq=1 ttl=56 time=20.386 ms $ docker run --rm curlimages/curl -s ipinfo.io/ip 11.22.22.11 $ curl -s ipinfo.io/ip 11.22.22.11 Ссылки по теме  Limiting outside connections to docker container with iptables Docker and iptables Сети Docker изнутри: как Docker использует iptables и интерфейсы Linux Пользовательские правила iptables для docker на примере zabbix Install Docker CE on Debian 10 with Dual stack IPv6-NAT and Firewall Support  ","date":"2020-07-06T15:11:47Z","image":"https://blog.hook.sh/iptables-for-docker-swarm/cover_huca17b364cb926e2346fafd474740dcec_161710_120x120_fill_q75_box_smart1.jpg","permalink":"https://blog.hook.sh/iptables-for-docker-swarm/","title":"Настройка iptables для swarm кластера"},{"content":"Хочу рассказать про мужика-медоеда. Этот отморозок вызывает во мне искреннее восхищение.\nЖил-был Адриан Картон ди Виарт. Родился он в 1880 году в Бельгии, в аристократической семье. Чуть ли не с самого рождения он проявил хуевый характер: был вспыльчивым до бешенства, несдержанным, и все споры предпочитал разрешать, уебав противника без предупреждения.\nКогда Адриану исполнилось 17 лет, аристократический папа спихнул его в Оксфорд, и вздохнул с облегчением. Но в университете блистательный отпрыск не успевал по всем предметам. Кроме спорта. Там он был первым. Ну и еще бухать умел.\n— Хуйня какая-то эти ваши науки, — решил Адриан. — Вам не сделать из меня офисного хомячка.\nКогда ему стукнуло 19, на его радость началась англо-бурская война. Ди Виарт понятия не имел, кто с кем воюет, и ему было похуй. Он нашел ближайший рекрутерский пункт — это оказался пункт британской армии. Отправился туда, прибавил себе 6 лет, назвался другим именем, и умотал в Африку.\n— Ишь ты, как заебись! — обрадовался он, оказавшись впервые в настоящем бою. — Пули свищут, народ мрет — красота ж!\nНо тут Адриан был ранен в пах и живот, и его отправили на лечение в Англию. Аристократический папа, счастливый, что сынок наконец нашелся, заявил:\n— Ну все, повыёбывался, и хватит. Возвращайся в Оксфорд. — Да хуй-то там! — захохотал ди Виарт. — Я ж только начал развлекаться!\nПапа убедить его не смог, и похлопотал, чтобы отморозка взяли хотя бы в офицерский корпус. Чтоб фамилию не позорил. Адриан в составе корпуса отправился в Индию, где радостно охотился на кабанов. А в 1904 году снова попал на Бурскую войну, адъютантом командующего.\nТут уж он развернулся с неебической силой. Рвался во всякий бой, хуячил противника так, что аж свои боялись, и говорили:\n— Держитесь подальше от этого распиздяя, он когда в азарте, кого угодно уебет, и не вспомнит.\nХотели ему вручить медаль, но тут выяснилось, что он 7 лет уж воюет за Англию, а сам гражданин Бельгии.\n— Как же так получилось? — спросили Адриана. — Да не похуй ли, за кого воевать? — рассудительно ответил тот.\nНо все же ему дали британское подданство и звание капитана.\nВ 1908 году ди Виарт вдруг лихо выебнулся, женившись на аристократке, у которой родословная была круче, чем у любого породистого спаниеля. Звали ее Фредерика Мария Каролина Генриетта Роза Сабина Франциска Фуггер фон Бабенхаузен.\n— Ну, теперь-то уж он остепенится, — радовался аристократический папа. У пары родились две дочери, но Адриан заскучал, и собрался на войну.\n— Куда ты, Андрюша? — плакала жена, утирая слезы родословной. — Я старый, блядь, солдат, и не знаю слов любви, — сурово отвечал ди Виарт. — Быть женатым мне не понравилось. Все твои имена пока в койке выговоришь, хуй падает. А на самом деле ты какой-то просто Бабенхаузен. Я разочарован. Ухожу.\nИ отвалил на Первую Мировую. Начал он в Сомали, помощником командующего Верблюжьим Корпусом. Во время осады крепости дервишей, ему пулей выбило глаз и оторвало часть уха.\n— Врете, суки, не убьете, — орал ди Виарт, и продолжал штурмовать укрепления, хуяча на верблюде. Под его командованием вражеская крепость была взята. Только тогда ди Виарт соизволил обратиться в госпиталь.\nЕго наградили орденом, и вернули в Британию. Подлечившись, ди Виарт попросился на западный фронт.\n— Вы ж калека, у вас глаза нет, — сказали комиссии. — Все остальное, блядь, есть, — оскалился Адриан. — Отправляйте.\nОн для красоты вставил себе стеклянный глаз. И его отправили. Сразу после комиссии ди Виарт выкинул глаз, натянул черную повязку, и сказал:\n— Буду как Нельсон. Ну или как Кутузов. Похуй, пляшем. — Ну все, пиздец, — сказали немцы, узнав об этом. — Можно сразу сдаваться.\nИ были правы. Ди Виарт херачил их только так. Командовал он пехотной бригадой. Когда убивали командиров других подразделений, принимал командование на себя. И никогда не отступал.\nПод Соммой его ранили в голову и в плечо, под Пашендалем в бедро.\nПодлечившись, он отправлялся снова воевать. В бою на Ипре ему рего не отъебаться, и он будет служить еще лет сто или двести. Его произвели в генерал-лейтенанты, и отправили в Китай, личным представителем Черчилля.\nВ Китае случилась гражданская война, и ди Виарт очень хотел в ней поучаствовать, чтоб кого-нибудь замочить. Но Англия ему запретила. Тогда ди Виарт познакомился с Мао Дзе Дуном, и говорит:\n— А давайте Японию отпиздим? Чо они такие суки? — Нет, лучше давайте вступайте в Китайскую армию, такие люди нам нужны. — Ну на хуй, у вас тут скучно, — заявил ди Виарт. — Вы какие-то слишком мирные.\nИ в 1947 году наконец вышел в отставку. Супруга с труднопроизносимым именем померла. А в 1951 году ди Виарт женился на бабе, которая была на 23 года младше.\n— Вы ж старик уже, да еще и отполовиненный, как же вы с молодой женой справитесь? — охуевали знакомые. — А чего с ней справляться? — браво отвечал ди Виарт. — Хуй мне не оторвало.\n«Честно говоря, я наслаждался войной, — писал он в своих мемуарах. — Конечно, были плохие моменты, но хороших куда больше, не говоря уже о приятном волнении». Умер он в 1963 году, в возрасте 83 лет. Человек-медоед, не иначе.\n (с) Diana Udovichenko\n","date":"2019-01-20T07:52:56Z","image":"https://blog.hook.sh/adrian-karton-di-viart/cover_hue93400e0290949f7e2f718449ca8f3c5_59234_120x120_fill_q75_box_smart1.jpg","permalink":"https://blog.hook.sh/adrian-karton-di-viart/","title":"Пули свищут, народ мрет — красота!"},{"content":" Данный пост является переводом части документации, посвященной секции deploy в docker-compose\n deploy  Начиная с версии 3.\n Группа настроек, посвященная деплою и запуску сервисов. Указанные в данной группе настройки используются только при деплое на swarm используя docker stack deploy, и игнорируется при использовании команд docker-compose up и docker-compose run.\nversion:\u0026#39;3\u0026#39;services:redis:image:redis:alpinedeploy:replicas:6update_config:parallelism:2delay:10srestart_policy:condition:on-failureДоступны следующие дополнительные опции:\nendpoint_mode Используемый метод обнаружения (\u0026ldquo;service discovery\u0026rdquo;) для внешних запросов от клиентов.\n Начиная с версии 3.3.\n  endpoint_mode: vip - Докер присваивает сервису виртуальный IP адрес (VIP), который выступает в роли \u0026ldquo;внешнего\u0026rdquo; для получения доступа к сервису. Докер сам занимается маршрутизацией запросов между клиентом и доступным воркером (на котором крутится сервис), при этом клиент ничего не знает ни о количестве нод, ни о их IP и портах (используется по умолчанию). endpoint_mode: dnsrr - DNS \u0026ldquo;round-robin\u0026rdquo; (DNSRR) не использует одиночный виртуальный IP адрес. Докер устанавливает DNS записи для сервиса таким образом, что когда клиент его запрашивает - ему возвращается список из IP адресов, и клиент сам подключается к одному из них. DNS \u0026ldquo;round-robin\u0026rdquo; полезен в случаях использования своего собственного балансировщика нагрузки, или для гибридных Windows \u0026amp; Linux приложений.  version:\u0026#34;3.3\u0026#34;services:wordpress:image:wordpressports:- \u0026#34;8080:80\u0026#34;networks:- overlaydeploy:mode:replicatedreplicas:2endpoint_mode:vipmysql:image:mysqlvolumes:- db-data:/var/lib/mysql/datanetworks:- overlaydeploy:mode:replicatedreplicas:2endpoint_mode:dnsrrvolumes:db-data:networks:overlay:endpoint_mode так же можно использовать как флаг запуска при использовании консоли docker service create. Список всех связанных swarm-команд доступен по этой ссылке.\nЕсли вы хотите узнать больше о \u0026ldquo;service discovery\u0026rdquo; и сетях в swarm-режиме, перейдите в раздел настройки service discovery.\nlabels Установка ярлыков (labels) сервиса. Эти ярлыки присваиваются только самому сервису, а не какому-либо контейнеру этого сервиса.\nversion:\u0026#34;3\u0026#34;services:web:image:webdeploy:labels:com.example.description:\u0026#34;This label will appear on the web service\u0026#34;Для установки ярлыков (labels) для контейнеров (а не сервиса), используйте ключ labels вне секции deploy:\nversion:\u0026#34;3\u0026#34;services:web:image:weblabels:com.example.description:\u0026#34;This label will appear on all containers for the web service\u0026#34;mode Может быть глобальным (global, строго один контейнер на swarm-ноде) или реплицированным (replicated, с указанием количества контейнеров). По умолчанию используется replicated. Подробнее можно прочитать в разделе Реплицированные и глобальные сервисы.\nversion:\u0026#39;3\u0026#39;services:worker:image:dockersamples/examplevotingapp_workerdeploy:mode:globalplacement Указание мест размещения контейнеров и их \u0026ldquo;предпочтений\u0026rdquo;. Наиболее полное описание допустимых опций вы сможете найти в разделах \u0026ldquo;constraints\u0026rdquo; и \u0026ldquo;preferences\u0026rdquo; соответственно.\nversion:\u0026#39;3.3\u0026#39;services:db:image:postgresdeploy:placement:constraints:- node.role == manager- engine.labels.operatingsystem == ubuntu 14.04preferences:- spread:node.labels.zonereplicas Если у сервиса выбран режим репликации (replicated, используется по умолчанию) - вы можете указать количество запускаемых контейнеров у данного сервиса.\nversion:\u0026#39;3\u0026#39;services:worker:image:dockersamples/examplevotingapp_workernetworks:- frontend- backenddeploy:mode:replicatedreplicas:6resources Настройка ограничений используемых ресурсов.\n Примечание: Указанные в данной секции опции перекрывают более старые ограничения и опции, что указаны в Compose-файле для не-swarm режима до версии 3 (cpu_shares, cpu_quota, cpuset, mem_limit, memswap_limit, mem_swappiness), как описано в разделе обновление с версии 2.x до 3.x.\n Каждое значение, указанное в данной секции, является аналогом опций для docker service create.\nВ приведенном ниже примере сервис redis может использовать не более 50 Мб памяти и 0.50 (50%) доступного процессорного времени (CPU), а так же имеет зарезервированные 20 Мб памяти и 0.25 CPU (всегда доступные для него).\nversion:\u0026#39;3\u0026#39;services:redis:image:redis:alpinedeploy:resources:limits:cpus:\u0026#39;0.50\u0026#39;memory:50Mreservations:cpus:\u0026#39;0.25\u0026#39;memory:20M Настройка ограничений ресурсов для не-swarm режима доступна в этом разделе. Если у вас возникнут дополнительные вопросы - обратите внимание на этот топик на github.com.\n Исключения класса \u0026ldquo;Out Of Memory\u0026rdquo; (OOME) Если ваши сервисы или контейнеры попытаются использовать объём памяти больше, чем доступен на используемой системе, вы рискуете \u0026ldquo;поймать\u0026rdquo; исключение класса \u0026ldquo;Out Of Memory Exception\u0026rdquo; (OOME) и контейнер, или сам докер-демон может быть прибит демоном ядра системы (\u0026ldquo;kernel OOM killer\u0026rdquo;). Во избежание этого убедитесь в наличии доступных ресурсов на целевой системе и ознакомтесь с разделом понимание рисков недостатка доступной памяти.\nrestart_policy Указывает как и в каких случаях необходимо перезапускать контейнеры когда они останавливаются. Замена секции restart.\n condition (условие): одно из возможных значений - none (никогда), on-failure (при ошибке) или any (всегда) (по умолчанию: any). delay (задержка): Задержка между попытками перезапуска, указывается в формате \u0026ldquo;продолжительность\u0026rdquo; (по умолчанию: 0). max_attempts: Количество предпринимаемых попыток перезапуска перед тем, как прекратить пытаться запустить контейнер (по умолчанию: количество попыток не ограничено). Если контейнер не запустился в пределах указанного \u0026ldquo;окна\u0026rdquo; (window), эта попытка не учитывается при расчете значения max_attempts. Например, если max_attempts установлен равным 2, и перезапуск завершился ошибкой при первой попытке, может быть предпринято более двух попыток перезапуска. window: Задержка перед принятием решения о том, что перезапуск успешно завершился. Указывается в формате \u0026ldquo;продолжительность\u0026rdquo; (по умолчанию: задержка отсутствует).   Для лучшего понимания лучше прочитать первоисточник.\n version:\u0026#39;3\u0026#39;services:redis:image:redis:alpinedeploy:restart_policy:condition:on-failuredelay:5smax_attempts:3window:120supdate_config Настройка обновления сервисов.\n parallelism: Количество одновременно обновляемых контейнеров. Если установить 0, то будет происходить одновременное обновление всех контейнеров. delay: Задержка между обновлениями группы контейнеров (по умолчанию: 0s). failure_action: Действие при ошибке обновления. Может принимать значения: continue, rollback, или pause (по умолчанию: pause). monitor: Продолжительность мониторинга на сбой после каждого обновления (ns|us|ms|s|m|h) (по умолчанию: 0s). max_failure_ratio: Допустимая частота сбоев при обновлении (по умолчанию: 0). order: Порядок операций при обновлении. Может принимать значения: stop-first (старая задача останавливается перед тем, как запускать новую), или start-first (сначала запускается новая задача, а выполняемые задачи ненадолго \u0026ldquo;перекрываются\u0026rdquo;) (по умолчанию: stop-first).   Заметка: Порядок операций при обновлении доступен начиная с версии v3.4 и выше.\n version:\u0026#39;3.4\u0026#39;services:vote:image:dockersamples/examplevotingapp_vote:beforedepends_on:- redisdeploy:replicas:2update_config:parallelism:2delay:10sorder:stop-firstrollback_config  Версия 3.7 и выше\n Настройка откатов сервисов в случае ошибки обновления.\n parallelism: Количество одновременно откатываемых контейнеров. Если установить 0, то будет происходить одновременный откат всех контейнеров. delay: Задержка между откатами группы контейнеров (по умолчанию: 0s). failure_action: Действие при провале отката. Может принимать значения: continue или pause (по умолчанию: pause) monitor: Продолжительность мониторинга на сбой после каждого обновления (ns|us|ms|s|m|h) (по умолчанию: 0s). max_failure_ratio: Допустимая частота сбоев при откате (по умолчанию: 0). order: Порядок операций при откате. Может принимать значения: stop-first (старая задача останавливается перед тем, как запускать новую), или start-first (сначала запускается новая задача, а выполняемые задачи ненадолго \u0026ldquo;перекрываются\u0026rdquo;) (по умолчанию: stop-first).  Не поддерживается в контексте docker stack deploy Следующие настройки не поддерживаются командой docker stack deploy или настройками в группе deploy.\n build cgroup_parent container_name devices tmpfs external_links links network_mode restart security_opt stop_signal sysctls userns_mode   Заметка: Смотри раздел как настраивать тома для сервисов, swarm-ов и docker-stack.yml файлов. Использование томов поддерживается, но они должны быть сконфигурированы как как именованные тома или связаны с сервисами, которые в свою очередь предоставляют доступ к необходимым томам.\n","date":"2018-10-15T13:35:50Z","image":"https://blog.hook.sh/compose-deploy/cover_hu65abd86000f73060febdb2dd524fa8aa_21589_120x120_fill_box_smart1_3.png","permalink":"https://blog.hook.sh/compose-deploy/","title":"Деплой на Docker Swarm"},{"content":"msmtp - это простой консольный клиент для отправки сообщений электронной почты по протоколу SMTP.\nМожно, конечно, пойти сложным путем и поставить полноценный почтовый сервер, но зачем? Нам ведь требуется просто позволить скриптам и демонам отправлять почту, а заморачиваться с DKIM, SPF, заголовками и прочим - крайне лень. Поэтому мы будем отправлять почту с помощью почтового ящика на yandex.ru, и поможет нам в этом приложение под названием msmtp.\n Важное замечание - в моем случае домен уже делегирован на яндекс, в DNS имеются все необходимые записи, почтовый ящик создан на странице pdd.yandex.ru, к нему прописаны алиасы вида no-reply, noreply, donotreply, do-not-reply для того, что бы была возможность иметь почтовый ящик с именем info@domail.ru, но успешно отправлять письма от имени, например, no-reply@domail.ru.\n Единственное \u0026ldquo;но\u0026rdquo; - в репозиториях находится старая и бажная версия. Самый критичный для нас баг - это неизменяемое поле Sender, т.е. мы не можем указать имя (или адрес? не помню) отправителя. Смотрим что есть в репозиториях:\n$ yum info msmtp # ... Name : msmtp Version : 1.4.32 Release : 1.el7 Size : 120 k # ... Смотрим информацию о релизах на официальном сайте - на момент написания этих строк это версия 1.6.5 (уже без описанного выше бага).\n Все манипуляции производились на \u0026ldquo;чистой\u0026rdquo; системе CentOS 7.2.\n Скачаем исходники и соберем приложение ручками.\n$ cd ~ $ yum install git $ git clone git://git.code.sf.net/p/msmtp/code msmtp $ cd msmtp Ставим все необходимые для сборки пакеты:\n$ yum install automake gcc gettext-devel gnutls-devel openssl-devel texinfo Запускаем autoreconf:\n$ autoreconf -i autoreconf: configure.ac: AM_GNU_GETTEXT is used, but not AM_GNU_GETTEXT_VERSION configure.ac:31: installing \u0026#39;build-aux/config.guess\u0026#39; configure.ac:31: installing \u0026#39;build-aux/config.sub\u0026#39; configure.ac:34: installing \u0026#39;build-aux/install-sh\u0026#39; configure.ac:34: installing \u0026#39;build-aux/missing\u0026#39; Makefile.am: installing \u0026#39;./INSTALL\u0026#39; doc/Makefile.am:3: installing \u0026#39;build-aux/mdate-sh\u0026#39; src/Makefile.am: installing \u0026#39;build-aux/depcomp\u0026#39; Конфигуряем:\n$ ./configure # ... Install prefix ......... : /usr/local TLS/SSL support ........ : yes (Library: GnuTLS) # \u0026lt;-- ВАЖНО GNU SASL support ....... : no IDN support ............ : no NLS support ............ : yes Libsecret support (GNOME): no MacOS X Keychain support : no И если предыдущая операция завершилась успешно (наличие поддержки TLS/SSL для нас критично), то собираем:\n$ make  Если во время сборки вылезла ошибка вида:\n *** error: gettext infrastructure mismatch: using a Makefile.in.in from gettext version 0.19 but the autoconf macros are from gettext version 0.18 make[2]: *** [stamp-po] Error 1 make[2]: Leaving directory `/root/msmtp/po\u0026#39; make[1]: *** [all-recursive] Error 1 make[1]: Leaving directory `/root/msmtp\u0026#39; make: *** [all] Error 2  То правим один файл:\n $ nano ./po/Makefile.in.in  Где заменяем строку GETTEXT_MACRO_VERSION = 0.19 на GETTEXT_MACRO_VERSION = 0.18. После этого повторяем:\n $ make Выполняем установку только при успешной сборке (отсутствии каких-либо ошибок):\n$ make install Проверяем:\n$ /usr/local/bin/msmtp --version msmtp version 1.6.5 Platform: x86_64-unknown-linux-gnu TLS/SSL library: GnuTLS # \u0026lt;-- ВАЖНО Authentication library: built-in Supported authentication methods: plain external cram-md5 login IDN support: disabled NLS: enabled, LOCALEDIR is /usr/local/share/locale Keyring support: none System configuration file name: /usr/local/etc/msmtprc User configuration file name: /root/.msmtprc Copyright (C) 2016 Martin Lambers and others. This is free software. You may redistribute copies of it under the terms of the GNU General Public License \u0026lt;http: //www.gnu.org/licenses/gpl.html\u0026gt;. There is NO WARRANTY, to the extent permitted by law.\u0026lt;/http:\u0026gt; Создаем симлинки и заменяем \u0026ldquo;стандартный\u0026rdquo; sendmail (убедись предварительно что он удален/не установлен):\n$ ln -s /usr/local/bin/msmtp /etc/alternatives/mta $ ln -s /usr/local/bin/msmtp /usr/bin/msmtp $ ln -s /etc/alternatives/mta /usr/lib/mail $ ln -s /etc/alternatives/mta /usr/bin/mail $ ln -s /etc/alternatives/mta /usr/sbin/mail $ ln -s /etc/alternatives/mta /usr/lib/sendmail $ ln -s /etc/alternatives/mta /usr/bin/sendmail $ ln -s /etc/alternatives/mta /usr/sbin/sendmail Создаем системный конфиг и симлинк на него в /etc:\n$ touch /usr/local/etc/msmtprc $ ln -s /usr/local/etc/msmtprc /etc/msmtprc Выставляем права на файл и меняем группу файла для того, чтобы php-fpm (и другие члены этой группы) смогли читать его:\n$ chmod 640 /usr/local/etc/msmtprc $ chown :www-data /usr/local/etc/msmtprc После этого переходим непосредственно к настройке:\n$ nano /etc/msmtprc defaults tls on auth on tls_starttls on tls_certcheck off logfile /var/log/msmtp.log timeout 20 account yandex host smtp.yandex.ru port 587 maildomain your_domain_name.ru from no-reply@your_domain_name.ru keepbcc on user your_mailbox_name@your_domain_name.ru password MAILBOX_PASSWORD account default : yandex И проверяем работу запуская как из консоли, так и из php-скрипта:\n$ echo -e \u0026#34;\\nSome test 1\u0026#34; | msmtp -d your_another_email@gmail.com $ php -r \u0026#34;mail(\u0026#39;your_another_email@gmail.com\u0026#39;,\u0026#39;Subject\u0026#39;,\u0026#39;Some test 2\u0026#39;);\u0026#34; Письма должны успешно приходить на your_another_email@gmail.com. Так же стоит проверить работу непосредственно из-под php-fpm, например, таким скриптом:\n\u0026lt;?php set_time_limit(15); error_reporting(E_ALL); ini_set(\u0026#39;display_errors\u0026#39;, 1); $result = mail(\u0026#39;your_another_email@gmail.com\u0026#39;, \u0026#39;Subject\u0026#39;, \u0026#39;Some test 3\u0026#39;); echo \u0026#39;\u0026lt;pre\u0026gt;\u0026#39;; var_dump($result); echo \u0026#39;\u0026lt;/pre\u0026gt;\u0026#39;; if ($result) { echo \u0026#39;все путем\u0026#39;; } else { echo \u0026#39;что-то не так\u0026#39;; } И обратившись к нему из web. Если необходимо позволить какому-либо локальному пользователю так же из консоли отправлять письма, то необходимо создать новую группу, и добавить в неё необходимых пользователей, не забыв так же добавить в неё и php-fpm.\nНесколько почтовых ящиков и nginx Так как на одном сервере могут располагаться несколько сайтов - наверняка возникнет потребность отправлять письма с разных сайтов от разных отправителей. Поясню - на одном сервере расположены сайты с доменными именами site1.ru и site2.ru. Соответственно, отправитель в исходящих письмах с сайта site1.ru должен быть вида robot@site1.ru, а в исходящих письмах с сайта site2.ru - вида robot@site2.ru. Для того что бы этого добиться нам необходимо прописать требуемые аккаунты в файле настроек msmtp:\ndefaults tls on auth on tls_starttls on tls_certcheck off logfile /var/log/msmtp.log timeout 20 account site1 host smtp.yandex.ru port 587 maildomain site1.ru from robot@site1.ru user robot@site1.ru password password_here account site2 host smtp.yandex.ru port 587 maildomain site2.ru from robot@site2.ru user robot@site2.ru password password_here account default : site1 Теперь по умолчанию письма будут уходить от имени аккаунта site1, так как он у нас указан как аккаунт по умолчанию. Для того что бы сообщить скриптам на сайте site2.ru использовать аккаунт site2 необходимо добавить следующую строку в конфигурацию сервера site2.ru nginx:\nlocation ~ \\.php$ { # ...  fastcgi_param PHP_VALUE \u0026#34;sendmail_path = /usr/sbin/sendmail -t -i -a site2\u0026#34;; # ...  } И после этого всё начнет работать так как надо.\n","date":"2016-06-28T22:24:10Z","image":"https://blog.hook.sh/compile-and-config-msmtp/cover_hub577c79af8463c924351e5a1445741f0_93501_120x120_fill_q75_box_smart1.jpg","permalink":"https://blog.hook.sh/compile-and-config-msmtp/","title":"Собираем и настраиваем msmtp"},{"content":"При прошивки данной железки возникают некоторые вопросы, ответы на которые найти порой не так просто. Сейчас постараюсь ответить на основные:\n Можно ли установить на него dd-wrt или open-wrt? - Нет, не заведется, к сожалению Можно ли установить wive-ng? - Да, но \u0026ldquo;глючит\u0026rdquo; на столько, что работать с железкой в итоге не представляется возможным Можно ли после экспериментов \u0026ldquo;откатиться\u0026rdquo; на официальную версию? - Да, и это делается очень просто  Итак, если у тебя появится желание экспериментировать с железкой, то имей в виду следующие моменты:\n  Для того, чтоб выполнять манипуляции с прошивкой роутера необходимо его запустить в Recovery mode. Для этого:\n Вынимаем штекер питания роутера Нажимаем и удерживаем клавишу Reset роутера Вставляем штекер питания роутера, продолжая удерживать нажатой клавишу Reset Когда диод WPS начнет медленно мигать (через ~5 секунд) - отпускаем клавишу Reset Последующее простое выключение/включение роутера заставит его запуститься в стандартном режиме    Для прошивки роутера лучше всего его подключать патч-кордом напрямую к сетевой карте машины с которой будет производиться его прошивка. Оставлять включенным только одно сетевое подключение, всё лишнее - выключать\n  IP адрес выставлять 192.168.1.2 и только. Маска подсети 255.255.255.0. Использование любого другого адреса приводит к тому, что железка не обнаруживается и не прошивается\n  То что 192.168.1.1 (роутер) в Recovery mode не пингуется - нормально, не стоит переживать\n  Для прошивки можно использовать как tftpd, так и утилиту от Asus Firmware Restoration. Вторая проще, и выполняет по видимому всё тот же tftp put %файл%\n  Все основные файлы, которые тебе могут понадобиться как для экспериментов, так и восстановления на сток находятся по ссылкам ниже (прошивки openwrt, Wive-WR и сток находятся в директории ./firmware):\n Скачать  Ссылки по теме  Openwrt wiki касательно этой железки Прошивка роутера Asus RT-G32 C1 на Wive-NG-RTNL ","date":"2015-07-18T10:10:13Z","image":"https://blog.hook.sh/firmware-rt-g32/cover_hufd73581b96404e67b5185b9cf7a13a3b_10015_120x120_fill_q75_box_smart1.jpg","permalink":"https://blog.hook.sh/firmware-rt-g32/","title":"Прошивка роутера Asus RT-G32 ver. C1"},{"content":"Где их использовать? Фоновые изображения страниц авторизации, ошибок, анимация. Врубай своё воображение ;) Осторожно - трафик!\n","date":"2015-05-18T15:45:35Z","permalink":"https://blog.hook.sh/little-gifs-collection-part1/","title":"Небольшая коллекция интересных гифок (часть 1)"},{"content":"В самом аппарате есть программное обеспечение (ПО), которое отвечает за все действия. При помощи этого ПО производится отсчет распечатанных страниц с чипа картриджа. Когда допустимое количество листов будет отпечатано, устройство блокируется. И заправкой картриджа, как вы понимаете здесь не обойтись.\nРешением сложившейся ситуации служит прошивка новым программным обеспечением ваш принтер. В обновленном ПО отсутствует счетчик страниц и уровень тонера всегда 100%.\nВ сети можно обнаружить великое множество ресурсов, на которых предлагают бесплатные и якобы рабочие прошивки. Может где-то оно и так, но тут публикую действительно рабочий способ и проверенный на себе способ.\n  Произведем печать отчета о конфигурации - вставляем в лоток 1 лист бумаги, зажимаем и удерживаем клавишу стоп (находится над кнопкой включения принтера) на 5..10 секунд - когда диод начинает медленно мигать зеленым цветом - отпускаем, после чего и распечатывается лист с отчетом. В отчете должны обнаружить версию прошивки v1.01.00.18 или v1.01.00.19. Если версия в отчете о конфигурации вашего принтера выше, то к сожалению этот способ не для вас;\n  Далее нужно скачать архив с генератором (ML1860GEN.zip, пароль на архив ML1860GEN) и извлечь из него файлы в удобное для вас место на компьютере. Данный офф-лайн генератор работает без подключения к сети интернет;\n  Приступаем к генерации файла прошивки для данного принтера. Для этого нужно найти в папке с распакованным архивом файл с именем ml-1860_19nu_gen.exe и делаем его запуск. В окне программа предложит вам ввести серийный номер;\n  Производим ввод серийного номера принтера, он как и версия прошивки находится в отчете о конфигурации. Состоит серийник из пятнадцати (15) знаков, например: Z5MBBKDB803345L, делаем запуск нажав на кнопку Generate. Далее вас проинформируют что генерация успешно завершилась - можно закрывать приложение. В папке, где расположен генератор, обнаружиться новый файл FIX_Z5MBBKDB803345L_ML1860_19NU.hd;\n  Мышью перетаскиваем полученный в предыдущем шаге файл (например, FIX_Z5MBBKDB803345L_ML1860_19NU.hd) на приложение usbprns2.exe. Затем откроется окно консоли Windows, которое по завершению процесса (3..10 секунд) закроется само. Принтер при этом немного пошумит механикой и произведет перезагрузку;\n  Выключаем принтер, достаем картридж, заклеиваем его контакты (например изолентой):\n   Вставляем картридж обратно, включаем принтер. Наблюдаем как диод теперь не мигает красным, а горит дружелюбным зеленым цветом :)  Так же распечатываем отчет (как в первом пункте). Проверяем чтоб после цифры версии появилась буква F (было V1.01.00.19 12-03-2010, стало V1.01.00.19F12-03-2010). Теперь для того чтоб картридж виделся как полный достаточно просто выключить и включить питание.\n","date":"2015-05-18T15:20:41Z","image":"https://blog.hook.sh/hack-printer-samsung-ml-1860/cover_hu20c3f0b842daba4ef0d24b51a21ac24b_26547_120x120_fill_q75_box_smart1.jpg","permalink":"https://blog.hook.sh/hack-printer-samsung-ml-1860/","title":"Прошивка принтера Samsung ML-1860"}]